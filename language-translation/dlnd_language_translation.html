<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, you’re going to take a peek into the realm of neural network machine translation.  You’ll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#index range of sentences to view, e.g. (0,10) means 0th to 9th for 10 total</span>
<span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="sd">&#39;&#39;&#39; TEMP</span>
<span class="sd">print(&#39;Dataset Stats&#39;)</span>
<span class="sd">word_list = source_text.split()</span>
<span class="sd">print(word_list[:50])</span>
<span class="sd">word_set = set(word_list) </span>
<span class="sd">print(&#39;Roughly the number of unique words (incl. punctuation): {}&#39;.format(len(word_set)))</span>

<span class="sd">sentences = source_text.split(&#39;\n&#39;)</span>
<span class="sd">word_counts = [len(sentence.split()) for sentence in sentences]</span>
<span class="sd">print(&#39;Number of sentences: {}&#39;.format(len(sentences)))</span>
<span class="sd">print(&#39;Average number of words in a sentence: {}&#39;.format(np.average(word_counts)))</span>

<span class="sd">print()</span>
<span class="sd">print(&#39;English sentences {} to {}:&#39;.format(*view_sentence_range))</span>
<span class="sd">print(&#39;\n&#39;.join(source_text.split(&#39;\n&#39;)[view_sentence_range[0]:view_sentence_range[1]]))</span>
<span class="sd">print()</span>
<span class="sd">print(&#39;French sentences {} to {}:&#39;.format(*view_sentence_range))</span>
<span class="sd">print(&#39;\n&#39;.join(target_text.split(&#39;\n&#39;)[view_sentence_range[0]:view_sentence_range[1]]))</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[2]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>&#34; TEMP\nprint(&#39;Dataset Stats&#39;)\nword_list = source_text.split()\nprint(word_list[:50])\nword_set = set(word_list) \nprint(&#39;Roughly the number of unique words (incl. punctuation): {}&#39;.format(len(word_set)))\n\nsentences = source_text.split(&#39;\n&#39;)\nword_counts = [len(sentence.split()) for sentence in sentences]\nprint(&#39;Number of sentences: {}&#39;.format(len(sentences)))\nprint(&#39;Average number of words in a sentence: {}&#39;.format(np.average(word_counts)))\n\nprint()\nprint(&#39;English sentences {} to {}:&#39;.format(*view_sentence_range))\nprint(&#39;\n&#39;.join(source_text.split(&#39;\n&#39;)[view_sentence_range[0]:view_sentence_range[1]]))\nprint()\nprint(&#39;French sentences {} to {}:&#39;.format(*view_sentence_range))\nprint(&#39;\n&#39;.join(target_text.split(&#39;\n&#39;)[view_sentence_range[0]:view_sentence_range[1]]))\n&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of each sentence from <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">src_sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>    
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">src_sentences</span><span class="p">:</span>
        <span class="n">source_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()])</span>
    <span class="n">targ_sentences</span> <span class="o">=</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>    
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">targ_sentences</span><span class="p">:</span>
        <span class="c1">#Note that we only add the End-of-sentence flag at the end of the *target* sentences.</span>
        <span class="n">sentence</span> <span class="o">+=</span> <span class="s1">&#39; &lt;EOS&gt;&#39;</span>
        <span class="n">target_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()])</span>

    <span class="c1">#source_id_text is a list of sentences (lists) after conversion to integer IDs. Same for target_id_text.</span>
    <span class="k">return</span> <span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">path</span>
<span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s1">&#39;preprocess.p&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;preprocess_and_save_data&#39;</span><span class="p">)</span>
    <span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;skip preprocess_and_save_data() because preprocessed file exists.&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>skip preprocess_and_save_data() because preprocessed file exists.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0.0&#39;</span><span class="p">),</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0.1&#39;</span><span class="p">)],</span> <span class="s1">&#39;This project requires TensorFlow version 1.0  You are using </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.0.0
Default GPU Device: /gpu:0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoding_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
</ul>
<p>Return the placeholders in the following the tuple (Input, Targets, Learing Rate, Keep Probability)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, and learning rate.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;targets&quot;</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoding-Input">Process Decoding Input<a class="anchor-link" href="#Process-Decoding-Input">&#182;</a></h3><p>Implement <code>process_decoding_input</code> using TensorFlow to remove the last word id from each batch in <code>target_data</code> and concat the GO ID to the beginning of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoding_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for dencoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">ending</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]),</span> <span class="n">ending</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">dec_input</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_decoding_input</span><span class="p">(</span><span class="n">process_decoding_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer using <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: RNN state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># Encoder</span>
    <span class="c1"># apply dropout with probability keep_prob to the basic LSTM cell.</span>
    <span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">),</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
    <span class="c1"># Stack up this cell in layers of depth num_layers.</span>
    <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">lstm_cell</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">enc_cell</span><span class="p">,</span> <span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">enc_state</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create training logits using <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train"><code>tf.contrib.seq2seq.simple_decoder_fn_train()</code></a> and <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a>.  Apply the <code>output_fn</code> to the <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a> outputs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">decoding_scope</span><span class="p">,</span>
                         <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param sequence_length: Sequence Length</span>
<span class="sd">    :param decoding_scope: TensorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_fn: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Train Logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># #### Decoder During Training</span>
    <span class="c1"># - Build the training decoder using [`tf.contrib.seq2seq.simple_decoder_fn_train`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).</span>
    <span class="c1"># - Apply the output layer to the output of the training decoder</span>

    <span class="c1"># Training Decoder</span>
    <span class="n">train_decoder_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">simple_decoder_fn_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">)</span>
    <span class="c1">#apply droput to decoder cell</span>
    <span class="n">drop_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">train_pred</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_rnn_decoder</span><span class="p">(</span>
        <span class="n">drop_cell</span><span class="p">,</span> <span class="n">train_decoder_fn</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">decoding_scope</span><span class="p">)</span>

    <span class="c1"># Apply output function</span>
    <span class="n">train_logits</span> <span class="o">=</span> <span class="n">output_fn</span><span class="p">(</span><span class="n">train_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference logits using <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference"><code>tf.contrib.seq2seq.simple_decoder_fn_inference()</code></a> and <a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">,</span>
                         <span class="n">maximum_length</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">decoding_scope</span><span class="p">,</span> <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param maximum_length: The maximum allowed time steps to decode</span>
<span class="sd">    :param vocab_size: Size of vocabulary</span>
<span class="sd">    :param decoding_scope: TensorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_fn: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Inference Logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># #### Decoder During Inference</span>
    <span class="c1"># - Reuse the weights the biases from the training decoder using [`tf.variable_scope(&quot;decoding&quot;, reuse=True)`](https://www.tensorflow.org/api_docs/python/tf/variable_scope)</span>
    <span class="c1"># - Build the inference decoder using [`tf.contrib.seq2seq.simple_decoder_fn_inference`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).</span>
    <span class="c1">#  - The output function is applied to the output in this step </span>
    <span class="n">infer_decoder_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">simple_decoder_fn_inference</span><span class="p">(</span>
        <span class="n">output_fn</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">,</span> 
        <span class="n">maximum_length</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="c1">#apply droput to decoder cell</span>
    <span class="n">drop_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">inference_logits</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_rnn_decoder</span><span class="p">(</span><span class="n">drop_cell</span><span class="p">,</span> <span class="n">infer_decoder_fn</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">decoding_scope</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">inference_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Create RNN cell for decoding using <code>rnn_size</code> and <code>num_layers</code>.</li>
<li>Create the output fuction using <a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions"><code>lambda</code></a> to transform it's input, logits, to class logits.</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param encoder_state: The encoded state</span>
<span class="sd">    :param vocab_size: Size of vocabulary (target)</span>
<span class="sd">    :param sequence_length: Sequence Length</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Tuple of (Training Logits, Inference Logits)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="c1"># Decoder RNNs</span>
    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
    <span class="n">drop_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">train_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">drop_cell</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decoding&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">decoding_scope</span><span class="p">:</span>
        <span class="c1"># Output Layer</span>
        <span class="n">output_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">decoding_scope</span><span class="p">)</span>
        <span class="c1"># Training Decoder</span>
        <span class="n">train_logits</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">train_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">decoding_scope</span><span class="p">,</span>
            <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="c1">#reuse=True means we reuse the weights and biases from the training for the inference.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decoding&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">decoding_scope</span><span class="p">:</span>
        <span class="c1"># Inference Decoder</span>
        <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">train_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span>
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> <span class="n">sequence_length</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">decoding_scope</span><span class="p">,</span> <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to the input data for the encoder.</li>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)</code>.</li>
<li>Process target data using your <code>process_decoding_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Apply embedding to the target data for the decoder.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param sequence_length: Sequence Length</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training Logits, Inference Logits)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># ### Encoding</span>
    <span class="c1"># - Embed the input data using [`tf.contrib.layers.embed_sequence`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence)</span>
    <span class="c1"># - Pass the embedded input into a stack of RNNs.  Save the RNN state and ignore the output.</span>

    <span class="c1"># Encoder embedding</span>
    <span class="n">enc_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">enc_embedding_size</span><span class="p">)</span>
    <span class="c1"># Encoder</span>
    <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">enc_embed_input</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="c1"># Process the input we&#39;ll feed to the decoder</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoding_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="c1"># Decoder Embedding</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    <span class="c1"># Decoder RNN layer</span>
    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">enc_state</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
                   <span class="n">sequence_length</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1">#BEST 128. 1024 was worse</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1">#BEST 512. 128 was worse</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1">#BEST 4</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">25</span> <span class="c1">#BEST 25. 100 was worse</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">25</span> <span class="c1">#same</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#BEST 0.001.  0.01 was worse</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1">#BEST 0.75. 0.5 may be worse</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_source_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span><span class="n">max_source_sentence_length</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sequence_length&#39;</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
    
    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">targets</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
        <span class="n">encoding_embedding_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">)</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="p">,</span> <span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">train_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sequence_length</span><span class="p">]))</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>

<span class="n">valid_source</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">])</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">])</span>

<span class="c1">#lists that will be used to plot the training metrics</span>
<span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">helper</span><span class="o">.</span><span class="n">batch_data</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)):</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            
            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">sequence_length</span><span class="p">:</span> <span class="n">target_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>
            
            <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">inference_logits</span><span class="p">,</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">inference_logits</span><span class="p">,</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_source</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
                
            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>
            <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_target</span><span class="p">),</span> <span class="n">batch_valid_logits</span><span class="p">)</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="c1">#Update lists used for plotting the training metrics</span>
            <span class="n">train_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
            <span class="n">valid_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_acc</span><span class="p">)</span>
            <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.3f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.3f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.3f}</span><span class="s1">&#39;</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    0/1077 - Train Accuracy:  0.294, Validation Accuracy:  0.305, Loss:  5.885
Epoch   0 Batch    1/1077 - Train Accuracy:  0.221, Validation Accuracy:  0.305, Loss:  5.699
Epoch   0 Batch    2/1077 - Train Accuracy:  0.206, Validation Accuracy:  0.305, Loss:  4.772
Epoch   0 Batch    3/1077 - Train Accuracy:  0.270, Validation Accuracy:  0.335, Loss:  5.175
Epoch   0 Batch    4/1077 - Train Accuracy:  0.263, Validation Accuracy:  0.337, Loss:  4.299
Epoch   0 Batch    5/1077 - Train Accuracy:  0.296, Validation Accuracy:  0.338, Loss:  4.333
Epoch   0 Batch    6/1077 - Train Accuracy:  0.280, Validation Accuracy:  0.338, Loss:  4.218
Epoch   0 Batch    7/1077 - Train Accuracy:  0.262, Validation Accuracy:  0.337, Loss:  3.951
Epoch   0 Batch    8/1077 - Train Accuracy:  0.269, Validation Accuracy:  0.337, Loss:  3.724
Epoch   0 Batch    9/1077 - Train Accuracy:  0.307, Validation Accuracy:  0.366, Loss:  3.564
Epoch   0 Batch   10/1077 - Train Accuracy:  0.260, Validation Accuracy:  0.365, Loss:  3.658
Epoch   0 Batch   11/1077 - Train Accuracy:  0.326, Validation Accuracy:  0.366, Loss:  3.346
Epoch   0 Batch   12/1077 - Train Accuracy:  0.302, Validation Accuracy:  0.365, Loss:  3.416
Epoch   0 Batch   13/1077 - Train Accuracy:  0.340, Validation Accuracy:  0.362, Loss:  3.200
Epoch   0 Batch   14/1077 - Train Accuracy:  0.321, Validation Accuracy:  0.362, Loss:  3.148
Epoch   0 Batch   15/1077 - Train Accuracy:  0.303, Validation Accuracy:  0.367, Loss:  3.263
Epoch   0 Batch   16/1077 - Train Accuracy:  0.320, Validation Accuracy:  0.365, Loss:  3.211
Epoch   0 Batch   17/1077 - Train Accuracy:  0.327, Validation Accuracy:  0.372, Loss:  3.153
Epoch   0 Batch   18/1077 - Train Accuracy:  0.305, Validation Accuracy:  0.373, Loss:  3.180
Epoch   0 Batch   19/1077 - Train Accuracy:  0.343, Validation Accuracy:  0.385, Loss:  3.061
Epoch   0 Batch   20/1077 - Train Accuracy:  0.330, Validation Accuracy:  0.391, Loss:  3.072
Epoch   0 Batch   21/1077 - Train Accuracy:  0.323, Validation Accuracy:  0.393, Loss:  3.119
Epoch   0 Batch   22/1077 - Train Accuracy:  0.342, Validation Accuracy:  0.402, Loss:  3.078
Epoch   0 Batch   23/1077 - Train Accuracy:  0.335, Validation Accuracy:  0.400, Loss:  3.079
Epoch   0 Batch   24/1077 - Train Accuracy:  0.353, Validation Accuracy:  0.403, Loss:  2.969
Epoch   0 Batch   25/1077 - Train Accuracy:  0.321, Validation Accuracy:  0.379, Loss:  3.048
Epoch   0 Batch   26/1077 - Train Accuracy:  0.330, Validation Accuracy:  0.401, Loss:  3.099
Epoch   0 Batch   27/1077 - Train Accuracy:  0.375, Validation Accuracy:  0.401, Loss:  2.785
Epoch   0 Batch   28/1077 - Train Accuracy:  0.357, Validation Accuracy:  0.407, Loss:  2.905
Epoch   0 Batch   29/1077 - Train Accuracy:  0.356, Validation Accuracy:  0.408, Loss:  2.848
Epoch   0 Batch   30/1077 - Train Accuracy:  0.358, Validation Accuracy:  0.412, Loss:  2.830
Epoch   0 Batch   31/1077 - Train Accuracy:  0.356, Validation Accuracy:  0.417, Loss:  2.859
Epoch   0 Batch   32/1077 - Train Accuracy:  0.424, Validation Accuracy:  0.438, Loss:  2.652
Epoch   0 Batch   33/1077 - Train Accuracy:  0.419, Validation Accuracy:  0.433, Loss:  2.623
Epoch   0 Batch   34/1077 - Train Accuracy:  0.389, Validation Accuracy:  0.440, Loss:  2.726
Epoch   0 Batch   35/1077 - Train Accuracy:  0.378, Validation Accuracy:  0.431, Loss:  2.693
Epoch   0 Batch   36/1077 - Train Accuracy:  0.397, Validation Accuracy:  0.447, Loss:  2.673
Epoch   0 Batch   37/1077 - Train Accuracy:  0.398, Validation Accuracy:  0.448, Loss:  2.662
Epoch   0 Batch   38/1077 - Train Accuracy:  0.362, Validation Accuracy:  0.450, Loss:  2.852
Epoch   0 Batch   39/1077 - Train Accuracy:  0.391, Validation Accuracy:  0.451, Loss:  2.676
Epoch   0 Batch   40/1077 - Train Accuracy:  0.398, Validation Accuracy:  0.458, Loss:  2.626
Epoch   0 Batch   41/1077 - Train Accuracy:  0.434, Validation Accuracy:  0.452, Loss:  2.518
Epoch   0 Batch   42/1077 - Train Accuracy:  0.408, Validation Accuracy:  0.461, Loss:  2.582
Epoch   0 Batch   43/1077 - Train Accuracy:  0.375, Validation Accuracy:  0.451, Loss:  2.568
Epoch   0 Batch   44/1077 - Train Accuracy:  0.363, Validation Accuracy:  0.466, Loss:  2.731
Epoch   0 Batch   45/1077 - Train Accuracy:  0.389, Validation Accuracy:  0.450, Loss:  2.566
Epoch   0 Batch   46/1077 - Train Accuracy:  0.398, Validation Accuracy:  0.469, Loss:  2.643
Epoch   0 Batch   47/1077 - Train Accuracy:  0.410, Validation Accuracy:  0.461, Loss:  2.452
Epoch   0 Batch   48/1077 - Train Accuracy:  0.415, Validation Accuracy:  0.461, Loss:  2.526
Epoch   0 Batch   49/1077 - Train Accuracy:  0.393, Validation Accuracy:  0.443, Loss:  2.482
Epoch   0 Batch   50/1077 - Train Accuracy:  0.398, Validation Accuracy:  0.457, Loss:  2.592
Epoch   0 Batch   51/1077 - Train Accuracy:  0.418, Validation Accuracy:  0.453, Loss:  2.403
Epoch   0 Batch   52/1077 - Train Accuracy:  0.392, Validation Accuracy:  0.465, Loss:  2.547
Epoch   0 Batch   53/1077 - Train Accuracy:  0.407, Validation Accuracy:  0.458, Loss:  2.424
Epoch   0 Batch   54/1077 - Train Accuracy:  0.389, Validation Accuracy:  0.457, Loss:  2.583
Epoch   0 Batch   55/1077 - Train Accuracy:  0.448, Validation Accuracy:  0.473, Loss:  2.399
Epoch   0 Batch   56/1077 - Train Accuracy:  0.412, Validation Accuracy:  0.474, Loss:  2.437
Epoch   0 Batch   57/1077 - Train Accuracy:  0.485, Validation Accuracy:  0.478, Loss:  2.186
Epoch   0 Batch   58/1077 - Train Accuracy:  0.414, Validation Accuracy:  0.463, Loss:  2.402
Epoch   0 Batch   59/1077 - Train Accuracy:  0.387, Validation Accuracy:  0.476, Loss:  2.539
Epoch   0 Batch   60/1077 - Train Accuracy:  0.434, Validation Accuracy:  0.475, Loss:  2.342
Epoch   0 Batch   61/1077 - Train Accuracy:  0.413, Validation Accuracy:  0.473, Loss:  2.400
Epoch   0 Batch   62/1077 - Train Accuracy:  0.401, Validation Accuracy:  0.473, Loss:  2.495
Epoch   0 Batch   63/1077 - Train Accuracy:  0.452, Validation Accuracy:  0.478, Loss:  2.259
Epoch   0 Batch   64/1077 - Train Accuracy:  0.409, Validation Accuracy:  0.479, Loss:  2.362
Epoch   0 Batch   65/1077 - Train Accuracy:  0.400, Validation Accuracy:  0.478, Loss:  2.493
Epoch   0 Batch   66/1077 - Train Accuracy:  0.410, Validation Accuracy:  0.449, Loss:  2.332
Epoch   0 Batch   67/1077 - Train Accuracy:  0.455, Validation Accuracy:  0.479, Loss:  2.320
Epoch   0 Batch   68/1077 - Train Accuracy:  0.402, Validation Accuracy:  0.478, Loss:  2.402
Epoch   0 Batch   69/1077 - Train Accuracy:  0.438, Validation Accuracy:  0.474, Loss:  2.339
Epoch   0 Batch   70/1077 - Train Accuracy:  0.387, Validation Accuracy:  0.473, Loss:  2.415
Epoch   0 Batch   71/1077 - Train Accuracy:  0.426, Validation Accuracy:  0.483, Loss:  2.295
Epoch   0 Batch   72/1077 - Train Accuracy:  0.430, Validation Accuracy:  0.478, Loss:  2.291
Epoch   0 Batch   73/1077 - Train Accuracy:  0.425, Validation Accuracy:  0.484, Loss:  2.350
Epoch   0 Batch   74/1077 - Train Accuracy:  0.447, Validation Accuracy:  0.482, Loss:  2.193
Epoch   0 Batch   75/1077 - Train Accuracy:  0.457, Validation Accuracy:  0.480, Loss:  2.214
Epoch   0 Batch   76/1077 - Train Accuracy:  0.441, Validation Accuracy:  0.480, Loss:  2.272
Epoch   0 Batch   77/1077 - Train Accuracy:  0.415, Validation Accuracy:  0.465, Loss:  2.311
Epoch   0 Batch   78/1077 - Train Accuracy:  0.396, Validation Accuracy:  0.483, Loss:  2.429
Epoch   0 Batch   79/1077 - Train Accuracy:  0.441, Validation Accuracy:  0.489, Loss:  2.316
Epoch   0 Batch   80/1077 - Train Accuracy:  0.422, Validation Accuracy:  0.471, Loss:  2.276
Epoch   0 Batch   81/1077 - Train Accuracy:  0.450, Validation Accuracy:  0.485, Loss:  2.291
Epoch   0 Batch   82/1077 - Train Accuracy:  0.483, Validation Accuracy:  0.484, Loss:  2.126
Epoch   0 Batch   83/1077 - Train Accuracy:  0.397, Validation Accuracy:  0.469, Loss:  2.399
Epoch   0 Batch   84/1077 - Train Accuracy:  0.432, Validation Accuracy:  0.482, Loss:  2.312
Epoch   0 Batch   85/1077 - Train Accuracy:  0.432, Validation Accuracy:  0.475, Loss:  2.172
Epoch   0 Batch   86/1077 - Train Accuracy:  0.436, Validation Accuracy:  0.488, Loss:  2.330
Epoch   0 Batch   87/1077 - Train Accuracy:  0.436, Validation Accuracy:  0.479, Loss:  2.311
Epoch   0 Batch   88/1077 - Train Accuracy:  0.451, Validation Accuracy:  0.476, Loss:  2.258
Epoch   0 Batch   89/1077 - Train Accuracy:  0.449, Validation Accuracy:  0.491, Loss:  2.288
Epoch   0 Batch   90/1077 - Train Accuracy:  0.437, Validation Accuracy:  0.488, Loss:  2.335
Epoch   0 Batch   91/1077 - Train Accuracy:  0.493, Validation Accuracy:  0.481, Loss:  2.039
Epoch   0 Batch   92/1077 - Train Accuracy:  0.453, Validation Accuracy:  0.472, Loss:  2.227
Epoch   0 Batch   93/1077 - Train Accuracy:  0.447, Validation Accuracy:  0.482, Loss:  2.265
Epoch   0 Batch   94/1077 - Train Accuracy:  0.464, Validation Accuracy:  0.493, Loss:  2.194
Epoch   0 Batch   95/1077 - Train Accuracy:  0.473, Validation Accuracy:  0.487, Loss:  2.178
Epoch   0 Batch   96/1077 - Train Accuracy:  0.433, Validation Accuracy:  0.474, Loss:  2.216
Epoch   0 Batch   97/1077 - Train Accuracy:  0.452, Validation Accuracy:  0.481, Loss:  2.209
Epoch   0 Batch   98/1077 - Train Accuracy:  0.496, Validation Accuracy:  0.503, Loss:  2.078
Epoch   0 Batch   99/1077 - Train Accuracy:  0.425, Validation Accuracy:  0.493, Loss:  2.299
Epoch   0 Batch  100/1077 - Train Accuracy:  0.465, Validation Accuracy:  0.499, Loss:  2.213
Epoch   0 Batch  101/1077 - Train Accuracy:  0.468, Validation Accuracy:  0.486, Loss:  2.158
Epoch   0 Batch  102/1077 - Train Accuracy:  0.441, Validation Accuracy:  0.473, Loss:  2.160
Epoch   0 Batch  103/1077 - Train Accuracy:  0.400, Validation Accuracy:  0.480, Loss:  2.349
Epoch   0 Batch  104/1077 - Train Accuracy:  0.375, Validation Accuracy:  0.494, Loss:  2.497
Epoch   0 Batch  105/1077 - Train Accuracy:  0.454, Validation Accuracy:  0.497, Loss:  2.228
Epoch   0 Batch  106/1077 - Train Accuracy:  0.427, Validation Accuracy:  0.479, Loss:  2.283
Epoch   0 Batch  107/1077 - Train Accuracy:  0.447, Validation Accuracy:  0.474, Loss:  2.220
Epoch   0 Batch  108/1077 - Train Accuracy:  0.467, Validation Accuracy:  0.475, Loss:  2.095
Epoch   0 Batch  109/1077 - Train Accuracy:  0.411, Validation Accuracy:  0.463, Loss:  2.301
Epoch   0 Batch  110/1077 - Train Accuracy:  0.438, Validation Accuracy:  0.469, Loss:  2.188
Epoch   0 Batch  111/1077 - Train Accuracy:  0.419, Validation Accuracy:  0.487, Loss:  2.298
Epoch   0 Batch  112/1077 - Train Accuracy:  0.402, Validation Accuracy:  0.463, Loss:  2.251
Epoch   0 Batch  113/1077 - Train Accuracy:  0.440, Validation Accuracy:  0.488, Loss:  2.299
Epoch   0 Batch  114/1077 - Train Accuracy:  0.472, Validation Accuracy:  0.500, Loss:  2.205
Epoch   0 Batch  115/1077 - Train Accuracy:  0.433, Validation Accuracy:  0.502, Loss:  2.259
Epoch   0 Batch  116/1077 - Train Accuracy:  0.414, Validation Accuracy:  0.498, Loss:  2.253
Epoch   0 Batch  117/1077 - Train Accuracy:  0.405, Validation Accuracy:  0.490, Loss:  2.295
Epoch   0 Batch  118/1077 - Train Accuracy:  0.419, Validation Accuracy:  0.510, Loss:  2.303
Epoch   0 Batch  119/1077 - Train Accuracy:  0.453, Validation Accuracy:  0.506, Loss:  2.202
Epoch   0 Batch  120/1077 - Train Accuracy:  0.448, Validation Accuracy:  0.507, Loss:  2.169
Epoch   0 Batch  121/1077 - Train Accuracy:  0.474, Validation Accuracy:  0.510, Loss:  2.088
Epoch   0 Batch  122/1077 - Train Accuracy:  0.453, Validation Accuracy:  0.498, Loss:  2.157
Epoch   0 Batch  123/1077 - Train Accuracy:  0.486, Validation Accuracy:  0.512, Loss:  2.127
Epoch   0 Batch  124/1077 - Train Accuracy:  0.472, Validation Accuracy:  0.525, Loss:  2.144
Epoch   0 Batch  125/1077 - Train Accuracy:  0.487, Validation Accuracy:  0.517, Loss:  2.061
Epoch   0 Batch  126/1077 - Train Accuracy:  0.488, Validation Accuracy:  0.513, Loss:  2.036
Epoch   0 Batch  127/1077 - Train Accuracy:  0.460, Validation Accuracy:  0.517, Loss:  2.124
Epoch   0 Batch  128/1077 - Train Accuracy:  0.496, Validation Accuracy:  0.501, Loss:  1.966
Epoch   0 Batch  129/1077 - Train Accuracy:  0.477, Validation Accuracy:  0.514, Loss:  2.139
Epoch   0 Batch  130/1077 - Train Accuracy:  0.472, Validation Accuracy:  0.510, Loss:  2.038
Epoch   0 Batch  131/1077 - Train Accuracy:  0.436, Validation Accuracy:  0.503, Loss:  2.147
Epoch   0 Batch  132/1077 - Train Accuracy:  0.445, Validation Accuracy:  0.522, Loss:  2.200
Epoch   0 Batch  133/1077 - Train Accuracy:  0.454, Validation Accuracy:  0.508, Loss:  2.153
Epoch   0 Batch  134/1077 - Train Accuracy:  0.457, Validation Accuracy:  0.462, Loss:  1.980
Epoch   0 Batch  135/1077 - Train Accuracy:  0.460, Validation Accuracy:  0.513, Loss:  2.245
Epoch   0 Batch  136/1077 - Train Accuracy:  0.453, Validation Accuracy:  0.498, Loss:  2.080
Epoch   0 Batch  137/1077 - Train Accuracy:  0.494, Validation Accuracy:  0.513, Loss:  2.022
Epoch   0 Batch  138/1077 - Train Accuracy:  0.454, Validation Accuracy:  0.499, Loss:  2.041
Epoch   0 Batch  139/1077 - Train Accuracy:  0.477, Validation Accuracy:  0.515, Loss:  2.060
Epoch   0 Batch  140/1077 - Train Accuracy:  0.435, Validation Accuracy:  0.504, Loss:  2.158
Epoch   0 Batch  141/1077 - Train Accuracy:  0.478, Validation Accuracy:  0.520, Loss:  2.125
Epoch   0 Batch  142/1077 - Train Accuracy:  0.496, Validation Accuracy:  0.516, Loss:  1.942
Epoch   0 Batch  143/1077 - Train Accuracy:  0.471, Validation Accuracy:  0.516, Loss:  2.047
Epoch   0 Batch  144/1077 - Train Accuracy:  0.443, Validation Accuracy:  0.524, Loss:  2.092
Epoch   0 Batch  145/1077 - Train Accuracy:  0.504, Validation Accuracy:  0.524, Loss:  1.975
Epoch   0 Batch  146/1077 - Train Accuracy:  0.484, Validation Accuracy:  0.503, Loss:  1.981
Epoch   0 Batch  147/1077 - Train Accuracy:  0.456, Validation Accuracy:  0.526, Loss:  2.067
Epoch   0 Batch  148/1077 - Train Accuracy:  0.498, Validation Accuracy:  0.528, Loss:  1.899
Epoch   0 Batch  149/1077 - Train Accuracy:  0.472, Validation Accuracy:  0.520, Loss:  2.022
Epoch   0 Batch  150/1077 - Train Accuracy:  0.506, Validation Accuracy:  0.520, Loss:  1.922
Epoch   0 Batch  151/1077 - Train Accuracy:  0.506, Validation Accuracy:  0.533, Loss:  1.907
Epoch   0 Batch  152/1077 - Train Accuracy:  0.483, Validation Accuracy:  0.526, Loss:  1.993
Epoch   0 Batch  153/1077 - Train Accuracy:  0.479, Validation Accuracy:  0.531, Loss:  2.000
Epoch   0 Batch  154/1077 - Train Accuracy:  0.456, Validation Accuracy:  0.534, Loss:  2.069
Epoch   0 Batch  155/1077 - Train Accuracy:  0.480, Validation Accuracy:  0.530, Loss:  1.968
Epoch   0 Batch  156/1077 - Train Accuracy:  0.475, Validation Accuracy:  0.523, Loss:  1.938
Epoch   0 Batch  157/1077 - Train Accuracy:  0.502, Validation Accuracy:  0.540, Loss:  1.923
Epoch   0 Batch  158/1077 - Train Accuracy:  0.520, Validation Accuracy:  0.509, Loss:  1.877
Epoch   0 Batch  159/1077 - Train Accuracy:  0.508, Validation Accuracy:  0.529, Loss:  1.852
Epoch   0 Batch  160/1077 - Train Accuracy:  0.505, Validation Accuracy:  0.537, Loss:  1.841
Epoch   0 Batch  161/1077 - Train Accuracy:  0.495, Validation Accuracy:  0.540, Loss:  1.926
Epoch   0 Batch  162/1077 - Train Accuracy:  0.493, Validation Accuracy:  0.542, Loss:  1.927
Epoch   0 Batch  163/1077 - Train Accuracy:  0.488, Validation Accuracy:  0.555, Loss:  1.950
Epoch   0 Batch  164/1077 - Train Accuracy:  0.496, Validation Accuracy:  0.531, Loss:  1.842
Epoch   0 Batch  165/1077 - Train Accuracy:  0.476, Validation Accuracy:  0.538, Loss:  1.896
Epoch   0 Batch  166/1077 - Train Accuracy:  0.532, Validation Accuracy:  0.531, Loss:  1.780
Epoch   0 Batch  167/1077 - Train Accuracy:  0.468, Validation Accuracy:  0.522, Loss:  1.963
Epoch   0 Batch  168/1077 - Train Accuracy:  0.484, Validation Accuracy:  0.539, Loss:  1.904
Epoch   0 Batch  169/1077 - Train Accuracy:  0.526, Validation Accuracy:  0.545, Loss:  1.768
Epoch   0 Batch  170/1077 - Train Accuracy:  0.468, Validation Accuracy:  0.531, Loss:  1.954
Epoch   0 Batch  171/1077 - Train Accuracy:  0.525, Validation Accuracy:  0.543, Loss:  1.788
Epoch   0 Batch  172/1077 - Train Accuracy:  0.512, Validation Accuracy:  0.544, Loss:  1.703
Epoch   0 Batch  173/1077 - Train Accuracy:  0.459, Validation Accuracy:  0.529, Loss:  1.975
Epoch   0 Batch  174/1077 - Train Accuracy:  0.514, Validation Accuracy:  0.550, Loss:  1.821
Epoch   0 Batch  175/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.551, Loss:  1.785
Epoch   0 Batch  176/1077 - Train Accuracy:  0.484, Validation Accuracy:  0.541, Loss:  1.857
Epoch   0 Batch  177/1077 - Train Accuracy:  0.452, Validation Accuracy:  0.519, Loss:  1.959
Epoch   0 Batch  178/1077 - Train Accuracy:  0.491, Validation Accuracy:  0.524, Loss:  1.913
Epoch   0 Batch  179/1077 - Train Accuracy:  0.439, Validation Accuracy:  0.496, Loss:  1.923
Epoch   0 Batch  180/1077 - Train Accuracy:  0.505, Validation Accuracy:  0.553, Loss:  1.992
Epoch   0 Batch  181/1077 - Train Accuracy:  0.488, Validation Accuracy:  0.527, Loss:  1.778
Epoch   0 Batch  182/1077 - Train Accuracy:  0.515, Validation Accuracy:  0.533, Loss:  1.855
Epoch   0 Batch  183/1077 - Train Accuracy:  0.479, Validation Accuracy:  0.545, Loss:  1.913
Epoch   0 Batch  184/1077 - Train Accuracy:  0.532, Validation Accuracy:  0.550, Loss:  1.809
Epoch   0 Batch  185/1077 - Train Accuracy:  0.489, Validation Accuracy:  0.532, Loss:  1.838
Epoch   0 Batch  186/1077 - Train Accuracy:  0.487, Validation Accuracy:  0.526, Loss:  1.827
Epoch   0 Batch  187/1077 - Train Accuracy:  0.496, Validation Accuracy:  0.533, Loss:  1.839
Epoch   0 Batch  188/1077 - Train Accuracy:  0.512, Validation Accuracy:  0.543, Loss:  1.783
Epoch   0 Batch  189/1077 - Train Accuracy:  0.510, Validation Accuracy:  0.547, Loss:  1.794
Epoch   0 Batch  190/1077 - Train Accuracy:  0.525, Validation Accuracy:  0.545, Loss:  1.727
Epoch   0 Batch  191/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.549, Loss:  1.642
Epoch   0 Batch  192/1077 - Train Accuracy:  0.524, Validation Accuracy:  0.539, Loss:  1.738
Epoch   0 Batch  193/1077 - Train Accuracy:  0.513, Validation Accuracy:  0.529, Loss:  1.706
Epoch   0 Batch  194/1077 - Train Accuracy:  0.521, Validation Accuracy:  0.557, Loss:  1.681
Epoch   0 Batch  195/1077 - Train Accuracy:  0.490, Validation Accuracy:  0.557, Loss:  1.826
Epoch   0 Batch  196/1077 - Train Accuracy:  0.529, Validation Accuracy:  0.555, Loss:  1.671
Epoch   0 Batch  197/1077 - Train Accuracy:  0.520, Validation Accuracy:  0.556, Loss:  1.718
Epoch   0 Batch  198/1077 - Train Accuracy:  0.544, Validation Accuracy:  0.555, Loss:  1.577
Epoch   0 Batch  199/1077 - Train Accuracy:  0.524, Validation Accuracy:  0.560, Loss:  1.757
Epoch   0 Batch  200/1077 - Train Accuracy:  0.498, Validation Accuracy:  0.552, Loss:  1.782
Epoch   0 Batch  201/1077 - Train Accuracy:  0.511, Validation Accuracy:  0.534, Loss:  1.661
Epoch   0 Batch  202/1077 - Train Accuracy:  0.524, Validation Accuracy:  0.549, Loss:  1.749
Epoch   0 Batch  203/1077 - Train Accuracy:  0.517, Validation Accuracy:  0.547, Loss:  1.799
Epoch   0 Batch  204/1077 - Train Accuracy:  0.507, Validation Accuracy:  0.550, Loss:  1.733
Epoch   0 Batch  205/1077 - Train Accuracy:  0.529, Validation Accuracy:  0.545, Loss:  1.709
Epoch   0 Batch  206/1077 - Train Accuracy:  0.514, Validation Accuracy:  0.551, Loss:  1.787
Epoch   0 Batch  207/1077 - Train Accuracy:  0.509, Validation Accuracy:  0.549, Loss:  1.740
Epoch   0 Batch  208/1077 - Train Accuracy:  0.526, Validation Accuracy:  0.553, Loss:  1.707
Epoch   0 Batch  209/1077 - Train Accuracy:  0.552, Validation Accuracy:  0.553, Loss:  1.587
Epoch   0 Batch  210/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.557, Loss:  1.742
Epoch   0 Batch  211/1077 - Train Accuracy:  0.504, Validation Accuracy:  0.558, Loss:  1.705
Epoch   0 Batch  212/1077 - Train Accuracy:  0.543, Validation Accuracy:  0.555, Loss:  1.636
Epoch   0 Batch  213/1077 - Train Accuracy:  0.538, Validation Accuracy:  0.545, Loss:  1.622
Epoch   0 Batch  214/1077 - Train Accuracy:  0.480, Validation Accuracy:  0.545, Loss:  1.850
Epoch   0 Batch  215/1077 - Train Accuracy:  0.505, Validation Accuracy:  0.558, Loss:  1.773
Epoch   0 Batch  216/1077 - Train Accuracy:  0.483, Validation Accuracy:  0.499, Loss:  1.717
Epoch   0 Batch  217/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.562, Loss:  1.776
Epoch   0 Batch  218/1077 - Train Accuracy:  0.506, Validation Accuracy:  0.561, Loss:  1.797
Epoch   0 Batch  219/1077 - Train Accuracy:  0.542, Validation Accuracy:  0.542, Loss:  1.690
Epoch   0 Batch  220/1077 - Train Accuracy:  0.486, Validation Accuracy:  0.523, Loss:  1.703
Epoch   0 Batch  221/1077 - Train Accuracy:  0.511, Validation Accuracy:  0.555, Loss:  1.797
Epoch   0 Batch  222/1077 - Train Accuracy:  0.468, Validation Accuracy:  0.554, Loss:  1.875
Epoch   0 Batch  223/1077 - Train Accuracy:  0.524, Validation Accuracy:  0.535, Loss:  1.649
Epoch   0 Batch  224/1077 - Train Accuracy:  0.527, Validation Accuracy:  0.549, Loss:  1.723
Epoch   0 Batch  225/1077 - Train Accuracy:  0.487, Validation Accuracy:  0.550, Loss:  1.765
Epoch   0 Batch  226/1077 - Train Accuracy:  0.523, Validation Accuracy:  0.553, Loss:  1.703
Epoch   0 Batch  227/1077 - Train Accuracy:  0.489, Validation Accuracy:  0.535, Loss:  1.834
Epoch   0 Batch  228/1077 - Train Accuracy:  0.551, Validation Accuracy:  0.553, Loss:  1.646
Epoch   0 Batch  229/1077 - Train Accuracy:  0.543, Validation Accuracy:  0.550, Loss:  1.637
Epoch   0 Batch  230/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.559, Loss:  1.655
Epoch   0 Batch  231/1077 - Train Accuracy:  0.516, Validation Accuracy:  0.541, Loss:  1.640
Epoch   0 Batch  232/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.561, Loss:  1.764
Epoch   0 Batch  233/1077 - Train Accuracy:  0.516, Validation Accuracy:  0.558, Loss:  1.706
Epoch   0 Batch  234/1077 - Train Accuracy:  0.545, Validation Accuracy:  0.556, Loss:  1.591
Epoch   0 Batch  235/1077 - Train Accuracy:  0.557, Validation Accuracy:  0.562, Loss:  1.548
Epoch   0 Batch  236/1077 - Train Accuracy:  0.512, Validation Accuracy:  0.547, Loss:  1.676
Epoch   0 Batch  237/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.564, Loss:  1.605
Epoch   0 Batch  238/1077 - Train Accuracy:  0.539, Validation Accuracy:  0.565, Loss:  1.622
Epoch   0 Batch  239/1077 - Train Accuracy:  0.539, Validation Accuracy:  0.566, Loss:  1.565
Epoch   0 Batch  240/1077 - Train Accuracy:  0.521, Validation Accuracy:  0.573, Loss:  1.623
Epoch   0 Batch  241/1077 - Train Accuracy:  0.556, Validation Accuracy:  0.567, Loss:  1.518
Epoch   0 Batch  242/1077 - Train Accuracy:  0.515, Validation Accuracy:  0.566, Loss:  1.670
Epoch   0 Batch  243/1077 - Train Accuracy:  0.499, Validation Accuracy:  0.565, Loss:  1.709
Epoch   0 Batch  244/1077 - Train Accuracy:  0.558, Validation Accuracy:  0.577, Loss:  1.578
Epoch   0 Batch  245/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.571, Loss:  1.570
Epoch   0 Batch  246/1077 - Train Accuracy:  0.529, Validation Accuracy:  0.562, Loss:  1.652
Epoch   0 Batch  247/1077 - Train Accuracy:  0.563, Validation Accuracy:  0.555, Loss:  1.489
Epoch   0 Batch  248/1077 - Train Accuracy:  0.534, Validation Accuracy:  0.544, Loss:  1.584
Epoch   0 Batch  249/1077 - Train Accuracy:  0.532, Validation Accuracy:  0.554, Loss:  1.605
Epoch   0 Batch  250/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.558, Loss:  1.536
Epoch   0 Batch  251/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.565, Loss:  1.589
Epoch   0 Batch  252/1077 - Train Accuracy:  0.542, Validation Accuracy:  0.561, Loss:  1.543
Epoch   0 Batch  253/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.563, Loss:  1.531
Epoch   0 Batch  254/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.565, Loss:  1.623
Epoch   0 Batch  255/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.571, Loss:  1.632
Epoch   0 Batch  256/1077 - Train Accuracy:  0.487, Validation Accuracy:  0.542, Loss:  1.652
Epoch   0 Batch  257/1077 - Train Accuracy:  0.568, Validation Accuracy:  0.569, Loss:  1.553
Epoch   0 Batch  258/1077 - Train Accuracy:  0.547, Validation Accuracy:  0.564, Loss:  1.539
Epoch   0 Batch  259/1077 - Train Accuracy:  0.525, Validation Accuracy:  0.566, Loss:  1.628
Epoch   0 Batch  260/1077 - Train Accuracy:  0.541, Validation Accuracy:  0.541, Loss:  1.469
Epoch   0 Batch  261/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.576, Loss:  1.584
Epoch   0 Batch  262/1077 - Train Accuracy:  0.532, Validation Accuracy:  0.565, Loss:  1.537
Epoch   0 Batch  263/1077 - Train Accuracy:  0.560, Validation Accuracy:  0.572, Loss:  1.549
Epoch   0 Batch  264/1077 - Train Accuracy:  0.505, Validation Accuracy:  0.555, Loss:  1.607
Epoch   0 Batch  265/1077 - Train Accuracy:  0.541, Validation Accuracy:  0.576, Loss:  1.675
Epoch   0 Batch  266/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.561, Loss:  1.553
Epoch   0 Batch  267/1077 - Train Accuracy:  0.558, Validation Accuracy:  0.580, Loss:  1.486
Epoch   0 Batch  268/1077 - Train Accuracy:  0.564, Validation Accuracy:  0.570, Loss:  1.495
Epoch   0 Batch  269/1077 - Train Accuracy:  0.528, Validation Accuracy:  0.579, Loss:  1.696
Epoch   0 Batch  270/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.571, Loss:  1.593
Epoch   0 Batch  271/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.571, Loss:  1.530
Epoch   0 Batch  272/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.569, Loss:  1.480
Epoch   0 Batch  273/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.557, Loss:  1.547
Epoch   0 Batch  274/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.575, Loss:  1.568
Epoch   0 Batch  275/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.573, Loss:  1.506
Epoch   0 Batch  276/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.577, Loss:  1.644
Epoch   0 Batch  277/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.571, Loss:  1.464
Epoch   0 Batch  278/1077 - Train Accuracy:  0.550, Validation Accuracy:  0.578, Loss:  1.581
Epoch   0 Batch  279/1077 - Train Accuracy:  0.533, Validation Accuracy:  0.567, Loss:  1.584
Epoch   0 Batch  280/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.565, Loss:  1.560
Epoch   0 Batch  281/1077 - Train Accuracy:  0.524, Validation Accuracy:  0.555, Loss:  1.601
Epoch   0 Batch  282/1077 - Train Accuracy:  0.514, Validation Accuracy:  0.549, Loss:  1.657
Epoch   0 Batch  283/1077 - Train Accuracy:  0.557, Validation Accuracy:  0.565, Loss:  1.521
Epoch   0 Batch  284/1077 - Train Accuracy:  0.536, Validation Accuracy:  0.570, Loss:  1.551
Epoch   0 Batch  285/1077 - Train Accuracy:  0.577, Validation Accuracy:  0.571, Loss:  1.476
Epoch   0 Batch  286/1077 - Train Accuracy:  0.590, Validation Accuracy:  0.578, Loss:  1.406
Epoch   0 Batch  287/1077 - Train Accuracy:  0.551, Validation Accuracy:  0.580, Loss:  1.481
Epoch   0 Batch  288/1077 - Train Accuracy:  0.537, Validation Accuracy:  0.580, Loss:  1.534
Epoch   0 Batch  289/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.581, Loss:  1.442
Epoch   0 Batch  290/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.590, Loss:  1.539
Epoch   0 Batch  291/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.586, Loss:  1.547
Epoch   0 Batch  292/1077 - Train Accuracy:  0.588, Validation Accuracy:  0.579, Loss:  1.459
Epoch   0 Batch  293/1077 - Train Accuracy:  0.511, Validation Accuracy:  0.577, Loss:  1.604
Epoch   0 Batch  294/1077 - Train Accuracy:  0.571, Validation Accuracy:  0.571, Loss:  1.369
Epoch   0 Batch  295/1077 - Train Accuracy:  0.526, Validation Accuracy:  0.566, Loss:  1.590
Epoch   0 Batch  296/1077 - Train Accuracy:  0.566, Validation Accuracy:  0.561, Loss:  1.369
Epoch   0 Batch  297/1077 - Train Accuracy:  0.522, Validation Accuracy:  0.571, Loss:  1.572
Epoch   0 Batch  298/1077 - Train Accuracy:  0.552, Validation Accuracy:  0.578, Loss:  1.577
Epoch   0 Batch  299/1077 - Train Accuracy:  0.564, Validation Accuracy:  0.579, Loss:  1.435
Epoch   0 Batch  300/1077 - Train Accuracy:  0.539, Validation Accuracy:  0.578, Loss:  1.513
Epoch   0 Batch  301/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.578, Loss:  1.460
Epoch   0 Batch  302/1077 - Train Accuracy:  0.585, Validation Accuracy:  0.581, Loss:  1.416
Epoch   0 Batch  303/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.583, Loss:  1.487
Epoch   0 Batch  304/1077 - Train Accuracy:  0.562, Validation Accuracy:  0.588, Loss:  1.427
Epoch   0 Batch  305/1077 - Train Accuracy:  0.570, Validation Accuracy:  0.582, Loss:  1.429
Epoch   0 Batch  306/1077 - Train Accuracy:  0.570, Validation Accuracy:  0.585, Loss:  1.380
Epoch   0 Batch  307/1077 - Train Accuracy:  0.531, Validation Accuracy:  0.577, Loss:  1.490
Epoch   0 Batch  308/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.591, Loss:  1.570
Epoch   0 Batch  309/1077 - Train Accuracy:  0.568, Validation Accuracy:  0.578, Loss:  1.406
Epoch   0 Batch  310/1077 - Train Accuracy:  0.541, Validation Accuracy:  0.571, Loss:  1.492
Epoch   0 Batch  311/1077 - Train Accuracy:  0.588, Validation Accuracy:  0.580, Loss:  1.399
Epoch   0 Batch  312/1077 - Train Accuracy:  0.543, Validation Accuracy:  0.576, Loss:  1.530
Epoch   0 Batch  313/1077 - Train Accuracy:  0.544, Validation Accuracy:  0.575, Loss:  1.465
Epoch   0 Batch  314/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.590, Loss:  1.402
Epoch   0 Batch  315/1077 - Train Accuracy:  0.578, Validation Accuracy:  0.586, Loss:  1.386
Epoch   0 Batch  316/1077 - Train Accuracy:  0.571, Validation Accuracy:  0.569, Loss:  1.390
Epoch   0 Batch  317/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.574, Loss:  1.505
Epoch   0 Batch  318/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.575, Loss:  1.491
Epoch   0 Batch  319/1077 - Train Accuracy:  0.554, Validation Accuracy:  0.555, Loss:  1.424
Epoch   0 Batch  320/1077 - Train Accuracy:  0.584, Validation Accuracy:  0.581, Loss:  1.461
Epoch   0 Batch  321/1077 - Train Accuracy:  0.532, Validation Accuracy:  0.554, Loss:  1.357
Epoch   0 Batch  322/1077 - Train Accuracy:  0.553, Validation Accuracy:  0.586, Loss:  1.532
Epoch   0 Batch  323/1077 - Train Accuracy:  0.564, Validation Accuracy:  0.565, Loss:  1.424
Epoch   0 Batch  324/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.582, Loss:  1.506
Epoch   0 Batch  325/1077 - Train Accuracy:  0.562, Validation Accuracy:  0.561, Loss:  1.341
Epoch   0 Batch  326/1077 - Train Accuracy:  0.589, Validation Accuracy:  0.577, Loss:  1.431
Epoch   0 Batch  327/1077 - Train Accuracy:  0.538, Validation Accuracy:  0.564, Loss:  1.469
Epoch   0 Batch  328/1077 - Train Accuracy:  0.583, Validation Accuracy:  0.572, Loss:  1.448
Epoch   0 Batch  329/1077 - Train Accuracy:  0.541, Validation Accuracy:  0.569, Loss:  1.483
Epoch   0 Batch  330/1077 - Train Accuracy:  0.572, Validation Accuracy:  0.576, Loss:  1.447
Epoch   0 Batch  331/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.582, Loss:  1.443
Epoch   0 Batch  332/1077 - Train Accuracy:  0.565, Validation Accuracy:  0.571, Loss:  1.373
Epoch   0 Batch  333/1077 - Train Accuracy:  0.577, Validation Accuracy:  0.576, Loss:  1.420
Epoch   0 Batch  334/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.567, Loss:  1.422
Epoch   0 Batch  335/1077 - Train Accuracy:  0.585, Validation Accuracy:  0.572, Loss:  1.335
Epoch   0 Batch  336/1077 - Train Accuracy:  0.573, Validation Accuracy:  0.571, Loss:  1.437
Epoch   0 Batch  337/1077 - Train Accuracy:  0.529, Validation Accuracy:  0.573, Loss:  1.498
Epoch   0 Batch  338/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.577, Loss:  1.449
Epoch   0 Batch  339/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.564, Loss:  1.415
Epoch   0 Batch  340/1077 - Train Accuracy:  0.538, Validation Accuracy:  0.583, Loss:  1.475
Epoch   0 Batch  341/1077 - Train Accuracy:  0.534, Validation Accuracy:  0.574, Loss:  1.436
Epoch   0 Batch  342/1077 - Train Accuracy:  0.551, Validation Accuracy:  0.586, Loss:  1.447
Epoch   0 Batch  343/1077 - Train Accuracy:  0.557, Validation Accuracy:  0.588, Loss:  1.379
Epoch   0 Batch  344/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.586, Loss:  1.451
Epoch   0 Batch  345/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.562, Loss:  1.344
Epoch   0 Batch  346/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.563, Loss:  1.433
Epoch   0 Batch  347/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.561, Loss:  1.389
Epoch   0 Batch  348/1077 - Train Accuracy:  0.560, Validation Accuracy:  0.547, Loss:  1.354
Epoch   0 Batch  349/1077 - Train Accuracy:  0.542, Validation Accuracy:  0.573, Loss:  1.437
Epoch   0 Batch  350/1077 - Train Accuracy:  0.540, Validation Accuracy:  0.584, Loss:  1.544
Epoch   0 Batch  351/1077 - Train Accuracy:  0.509, Validation Accuracy:  0.549, Loss:  1.529
Epoch   0 Batch  352/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.573, Loss:  1.498
Epoch   0 Batch  353/1077 - Train Accuracy:  0.538, Validation Accuracy:  0.576, Loss:  1.476
Epoch   0 Batch  354/1077 - Train Accuracy:  0.559, Validation Accuracy:  0.576, Loss:  1.443
Epoch   0 Batch  355/1077 - Train Accuracy:  0.553, Validation Accuracy:  0.567, Loss:  1.445
Epoch   0 Batch  356/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.574, Loss:  1.432
Epoch   0 Batch  357/1077 - Train Accuracy:  0.575, Validation Accuracy:  0.569, Loss:  1.372
Epoch   0 Batch  358/1077 - Train Accuracy:  0.545, Validation Accuracy:  0.576, Loss:  1.420
Epoch   0 Batch  359/1077 - Train Accuracy:  0.563, Validation Accuracy:  0.570, Loss:  1.336
Epoch   0 Batch  360/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.572, Loss:  1.339
Epoch   0 Batch  361/1077 - Train Accuracy:  0.576, Validation Accuracy:  0.576, Loss:  1.427
Epoch   0 Batch  362/1077 - Train Accuracy:  0.581, Validation Accuracy:  0.579, Loss:  1.393
Epoch   0 Batch  363/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.581, Loss:  1.429
Epoch   0 Batch  364/1077 - Train Accuracy:  0.557, Validation Accuracy:  0.581, Loss:  1.411
Epoch   0 Batch  365/1077 - Train Accuracy:  0.552, Validation Accuracy:  0.578, Loss:  1.374
Epoch   0 Batch  366/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.576, Loss:  1.329
Epoch   0 Batch  367/1077 - Train Accuracy:  0.587, Validation Accuracy:  0.575, Loss:  1.298
Epoch   0 Batch  368/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.580, Loss:  1.341
Epoch   0 Batch  369/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.566, Loss:  1.381
Epoch   0 Batch  370/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.582, Loss:  1.285
Epoch   0 Batch  371/1077 - Train Accuracy:  0.585, Validation Accuracy:  0.583, Loss:  1.328
Epoch   0 Batch  372/1077 - Train Accuracy:  0.574, Validation Accuracy:  0.582, Loss:  1.401
Epoch   0 Batch  373/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.569, Loss:  1.278
Epoch   0 Batch  374/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.580, Loss:  1.437
Epoch   0 Batch  375/1077 - Train Accuracy:  0.607, Validation Accuracy:  0.590, Loss:  1.269
Epoch   0 Batch  376/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.581, Loss:  1.287
Epoch   0 Batch  377/1077 - Train Accuracy:  0.571, Validation Accuracy:  0.584, Loss:  1.376
Epoch   0 Batch  378/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.582, Loss:  1.261
Epoch   0 Batch  379/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.577, Loss:  1.318
Epoch   0 Batch  380/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.579, Loss:  1.285
Epoch   0 Batch  381/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.578, Loss:  1.349
Epoch   0 Batch  382/1077 - Train Accuracy:  0.581, Validation Accuracy:  0.578, Loss:  1.365
Epoch   0 Batch  383/1077 - Train Accuracy:  0.583, Validation Accuracy:  0.563, Loss:  1.317
Epoch   0 Batch  384/1077 - Train Accuracy:  0.560, Validation Accuracy:  0.554, Loss:  1.293
Epoch   0 Batch  385/1077 - Train Accuracy:  0.535, Validation Accuracy:  0.538, Loss:  1.381
Epoch   0 Batch  386/1077 - Train Accuracy:  0.553, Validation Accuracy:  0.554, Loss:  1.403
Epoch   0 Batch  387/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.582, Loss:  1.279
Epoch   0 Batch  388/1077 - Train Accuracy:  0.575, Validation Accuracy:  0.586, Loss:  1.319
Epoch   0 Batch  389/1077 - Train Accuracy:  0.576, Validation Accuracy:  0.577, Loss:  1.317
Epoch   0 Batch  390/1077 - Train Accuracy:  0.541, Validation Accuracy:  0.566, Loss:  1.378
Epoch   0 Batch  391/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.579, Loss:  1.269
Epoch   0 Batch  392/1077 - Train Accuracy:  0.541, Validation Accuracy:  0.583, Loss:  1.401
Epoch   0 Batch  393/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.584, Loss:  1.333
Epoch   0 Batch  394/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.582, Loss:  1.387
Epoch   0 Batch  395/1077 - Train Accuracy:  0.587, Validation Accuracy:  0.589, Loss:  1.268
Epoch   0 Batch  396/1077 - Train Accuracy:  0.550, Validation Accuracy:  0.591, Loss:  1.356
Epoch   0 Batch  397/1077 - Train Accuracy:  0.604, Validation Accuracy:  0.594, Loss:  1.302
Epoch   0 Batch  398/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.571, Loss:  1.440
Epoch   0 Batch  399/1077 - Train Accuracy:  0.510, Validation Accuracy:  0.589, Loss:  1.585
Epoch   0 Batch  400/1077 - Train Accuracy:  0.573, Validation Accuracy:  0.577, Loss:  1.360
Epoch   0 Batch  401/1077 - Train Accuracy:  0.550, Validation Accuracy:  0.581, Loss:  1.392
Epoch   0 Batch  402/1077 - Train Accuracy:  0.582, Validation Accuracy:  0.586, Loss:  1.245
Epoch   0 Batch  403/1077 - Train Accuracy:  0.538, Validation Accuracy:  0.568, Loss:  1.409
Epoch   0 Batch  404/1077 - Train Accuracy:  0.591, Validation Accuracy:  0.565, Loss:  1.261
Epoch   0 Batch  405/1077 - Train Accuracy:  0.542, Validation Accuracy:  0.576, Loss:  1.421
Epoch   0 Batch  406/1077 - Train Accuracy:  0.583, Validation Accuracy:  0.582, Loss:  1.269
Epoch   0 Batch  407/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.589, Loss:  1.387
Epoch   0 Batch  408/1077 - Train Accuracy:  0.564, Validation Accuracy:  0.589, Loss:  1.331
Epoch   0 Batch  409/1077 - Train Accuracy:  0.552, Validation Accuracy:  0.595, Loss:  1.349
Epoch   0 Batch  410/1077 - Train Accuracy:  0.553, Validation Accuracy:  0.590, Loss:  1.367
Epoch   0 Batch  411/1077 - Train Accuracy:  0.593, Validation Accuracy:  0.583, Loss:  1.297
Epoch   0 Batch  412/1077 - Train Accuracy:  0.579, Validation Accuracy:  0.578, Loss:  1.291
Epoch   0 Batch  413/1077 - Train Accuracy:  0.570, Validation Accuracy:  0.581, Loss:  1.294
Epoch   0 Batch  414/1077 - Train Accuracy:  0.546, Validation Accuracy:  0.575, Loss:  1.345
Epoch   0 Batch  415/1077 - Train Accuracy:  0.581, Validation Accuracy:  0.567, Loss:  1.276
Epoch   0 Batch  416/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.574, Loss:  1.314
Epoch   0 Batch  417/1077 - Train Accuracy:  0.565, Validation Accuracy:  0.575, Loss:  1.321
Epoch   0 Batch  418/1077 - Train Accuracy:  0.563, Validation Accuracy:  0.578, Loss:  1.279
Epoch   0 Batch  419/1077 - Train Accuracy:  0.557, Validation Accuracy:  0.580, Loss:  1.302
Epoch   0 Batch  420/1077 - Train Accuracy:  0.581, Validation Accuracy:  0.592, Loss:  1.270
Epoch   0 Batch  421/1077 - Train Accuracy:  0.552, Validation Accuracy:  0.589, Loss:  1.302
Epoch   0 Batch  422/1077 - Train Accuracy:  0.569, Validation Accuracy:  0.595, Loss:  1.316
Epoch   0 Batch  423/1077 - Train Accuracy:  0.566, Validation Accuracy:  0.567, Loss:  1.341
Epoch   0 Batch  424/1077 - Train Accuracy:  0.560, Validation Accuracy:  0.584, Loss:  1.377
Epoch   0 Batch  425/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.582, Loss:  1.241
Epoch   0 Batch  426/1077 - Train Accuracy:  0.551, Validation Accuracy:  0.581, Loss:  1.379
Epoch   0 Batch  427/1077 - Train Accuracy:  0.556, Validation Accuracy:  0.581, Loss:  1.324
Epoch   0 Batch  428/1077 - Train Accuracy:  0.606, Validation Accuracy:  0.589, Loss:  1.236
Epoch   0 Batch  429/1077 - Train Accuracy:  0.598, Validation Accuracy:  0.579, Loss:  1.247
Epoch   0 Batch  430/1077 - Train Accuracy:  0.555, Validation Accuracy:  0.578, Loss:  1.308
Epoch   0 Batch  431/1077 - Train Accuracy:  0.569, Validation Accuracy:  0.566, Loss:  1.283
Epoch   0 Batch  432/1077 - Train Accuracy:  0.604, Validation Accuracy:  0.564, Loss:  1.285
Epoch   0 Batch  433/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.581, Loss:  1.340
Epoch   0 Batch  434/1077 - Train Accuracy:  0.575, Validation Accuracy:  0.595, Loss:  1.222
Epoch   0 Batch  435/1077 - Train Accuracy:  0.581, Validation Accuracy:  0.588, Loss:  1.243
Epoch   0 Batch  436/1077 - Train Accuracy:  0.594, Validation Accuracy:  0.587, Loss:  1.246
Epoch   0 Batch  437/1077 - Train Accuracy:  0.548, Validation Accuracy:  0.572, Loss:  1.303
Epoch   0 Batch  438/1077 - Train Accuracy:  0.570, Validation Accuracy:  0.581, Loss:  1.254
Epoch   0 Batch  439/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.585, Loss:  1.281
Epoch   0 Batch  440/1077 - Train Accuracy:  0.584, Validation Accuracy:  0.597, Loss:  1.274
Epoch   0 Batch  441/1077 - Train Accuracy:  0.549, Validation Accuracy:  0.598, Loss:  1.334
Epoch   0 Batch  442/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.584, Loss:  1.239
Epoch   0 Batch  443/1077 - Train Accuracy:  0.602, Validation Accuracy:  0.584, Loss:  1.196
Epoch   0 Batch  444/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.594, Loss:  1.281
Epoch   0 Batch  445/1077 - Train Accuracy:  0.550, Validation Accuracy:  0.594, Loss:  1.305
Epoch   0 Batch  446/1077 - Train Accuracy:  0.589, Validation Accuracy:  0.585, Loss:  1.139
Epoch   0 Batch  447/1077 - Train Accuracy:  0.582, Validation Accuracy:  0.584, Loss:  1.249
Epoch   0 Batch  448/1077 - Train Accuracy:  0.573, Validation Accuracy:  0.585, Loss:  1.285
Epoch   0 Batch  449/1077 - Train Accuracy:  0.553, Validation Accuracy:  0.588, Loss:  1.259
Epoch   0 Batch  450/1077 - Train Accuracy:  0.583, Validation Accuracy:  0.583, Loss:  1.186
Epoch   0 Batch  451/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.593, Loss:  1.194
Epoch   0 Batch  452/1077 - Train Accuracy:  0.597, Validation Accuracy:  0.586, Loss:  1.205
Epoch   0 Batch  453/1077 - Train Accuracy:  0.587, Validation Accuracy:  0.582, Loss:  1.174
Epoch   0 Batch  454/1077 - Train Accuracy:  0.596, Validation Accuracy:  0.596, Loss:  1.252
Epoch   0 Batch  455/1077 - Train Accuracy:  0.599, Validation Accuracy:  0.605, Loss:  1.141
Epoch   0 Batch  456/1077 - Train Accuracy:  0.591, Validation Accuracy:  0.607, Loss:  1.267
Epoch   0 Batch  457/1077 - Train Accuracy:  0.598, Validation Accuracy:  0.594, Loss:  1.175
Epoch   0 Batch  458/1077 - Train Accuracy:  0.556, Validation Accuracy:  0.599, Loss:  1.247
Epoch   0 Batch  459/1077 - Train Accuracy:  0.599, Validation Accuracy:  0.596, Loss:  1.166
Epoch   0 Batch  460/1077 - Train Accuracy:  0.596, Validation Accuracy:  0.589, Loss:  1.197
Epoch   0 Batch  461/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.585, Loss:  1.191
Epoch   0 Batch  462/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.586, Loss:  1.160
Epoch   0 Batch  463/1077 - Train Accuracy:  0.576, Validation Accuracy:  0.589, Loss:  1.251
Epoch   0 Batch  464/1077 - Train Accuracy:  0.601, Validation Accuracy:  0.593, Loss:  1.088
Epoch   0 Batch  465/1077 - Train Accuracy:  0.563, Validation Accuracy:  0.597, Loss:  1.223
Epoch   0 Batch  466/1077 - Train Accuracy:  0.569, Validation Accuracy:  0.597, Loss:  1.174
Epoch   0 Batch  467/1077 - Train Accuracy:  0.637, Validation Accuracy:  0.590, Loss:  1.097
Epoch   0 Batch  468/1077 - Train Accuracy:  0.606, Validation Accuracy:  0.590, Loss:  1.179
Epoch   0 Batch  469/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.600, Loss:  1.175
Epoch   0 Batch  470/1077 - Train Accuracy:  0.565, Validation Accuracy:  0.596, Loss:  1.243
Epoch   0 Batch  471/1077 - Train Accuracy:  0.591, Validation Accuracy:  0.596, Loss:  1.119
Epoch   0 Batch  472/1077 - Train Accuracy:  0.608, Validation Accuracy:  0.585, Loss:  1.181
Epoch   0 Batch  473/1077 - Train Accuracy:  0.586, Validation Accuracy:  0.597, Loss:  1.220
Epoch   0 Batch  474/1077 - Train Accuracy:  0.575, Validation Accuracy:  0.591, Loss:  1.167
Epoch   0 Batch  475/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.598, Loss:  1.151
Epoch   0 Batch  476/1077 - Train Accuracy:  0.587, Validation Accuracy:  0.587, Loss:  1.165
Epoch   0 Batch  477/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.586, Loss:  1.060
Epoch   0 Batch  478/1077 - Train Accuracy:  0.597, Validation Accuracy:  0.585, Loss:  1.205
Epoch   0 Batch  479/1077 - Train Accuracy:  0.579, Validation Accuracy:  0.584, Loss:  1.260
Epoch   0 Batch  480/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.583, Loss:  1.153
Epoch   0 Batch  481/1077 - Train Accuracy:  0.579, Validation Accuracy:  0.590, Loss:  1.182
Epoch   0 Batch  482/1077 - Train Accuracy:  0.577, Validation Accuracy:  0.590, Loss:  1.262
Epoch   0 Batch  483/1077 - Train Accuracy:  0.577, Validation Accuracy:  0.597, Loss:  1.139
Epoch   0 Batch  484/1077 - Train Accuracy:  0.588, Validation Accuracy:  0.596, Loss:  1.153
Epoch   0 Batch  485/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.607, Loss:  1.101
Epoch   0 Batch  486/1077 - Train Accuracy:  0.600, Validation Accuracy:  0.614, Loss:  1.163
Epoch   0 Batch  487/1077 - Train Accuracy:  0.579, Validation Accuracy:  0.612, Loss:  1.176
Epoch   0 Batch  488/1077 - Train Accuracy:  0.573, Validation Accuracy:  0.608, Loss:  1.198
Epoch   0 Batch  489/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.604, Loss:  1.084
Epoch   0 Batch  490/1077 - Train Accuracy:  0.572, Validation Accuracy:  0.589, Loss:  1.175
Epoch   0 Batch  491/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.602, Loss:  1.124
Epoch   0 Batch  492/1077 - Train Accuracy:  0.591, Validation Accuracy:  0.605, Loss:  1.198
Epoch   0 Batch  493/1077 - Train Accuracy:  0.621, Validation Accuracy:  0.599, Loss:  1.064
Epoch   0 Batch  494/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.602, Loss:  1.130
Epoch   0 Batch  495/1077 - Train Accuracy:  0.574, Validation Accuracy:  0.593, Loss:  1.129
Epoch   0 Batch  496/1077 - Train Accuracy:  0.584, Validation Accuracy:  0.591, Loss:  1.142
Epoch   0 Batch  497/1077 - Train Accuracy:  0.568, Validation Accuracy:  0.593, Loss:  1.254
Epoch   0 Batch  498/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.587, Loss:  1.099
Epoch   0 Batch  499/1077 - Train Accuracy:  0.602, Validation Accuracy:  0.593, Loss:  1.059
Epoch   0 Batch  500/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.594, Loss:  1.137
Epoch   0 Batch  501/1077 - Train Accuracy:  0.597, Validation Accuracy:  0.592, Loss:  1.126
Epoch   0 Batch  502/1077 - Train Accuracy:  0.610, Validation Accuracy:  0.592, Loss:  1.076
Epoch   0 Batch  503/1077 - Train Accuracy:  0.614, Validation Accuracy:  0.593, Loss:  1.124
Epoch   0 Batch  504/1077 - Train Accuracy:  0.586, Validation Accuracy:  0.593, Loss:  1.095
Epoch   0 Batch  505/1077 - Train Accuracy:  0.625, Validation Accuracy:  0.592, Loss:  0.991
Epoch   0 Batch  506/1077 - Train Accuracy:  0.571, Validation Accuracy:  0.597, Loss:  1.156
Epoch   0 Batch  507/1077 - Train Accuracy:  0.596, Validation Accuracy:  0.599, Loss:  1.097
Epoch   0 Batch  508/1077 - Train Accuracy:  0.606, Validation Accuracy:  0.610, Loss:  1.068
Epoch   0 Batch  509/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.604, Loss:  1.119
Epoch   0 Batch  510/1077 - Train Accuracy:  0.613, Validation Accuracy:  0.604, Loss:  1.056
Epoch   0 Batch  511/1077 - Train Accuracy:  0.588, Validation Accuracy:  0.612, Loss:  1.105
Epoch   0 Batch  512/1077 - Train Accuracy:  0.624, Validation Accuracy:  0.609, Loss:  1.075
Epoch   0 Batch  513/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.622, Loss:  1.123
Epoch   0 Batch  514/1077 - Train Accuracy:  0.608, Validation Accuracy:  0.633, Loss:  1.079
Epoch   0 Batch  515/1077 - Train Accuracy:  0.590, Validation Accuracy:  0.622, Loss:  1.134
Epoch   0 Batch  516/1077 - Train Accuracy:  0.634, Validation Accuracy:  0.615, Loss:  1.008
Epoch   0 Batch  517/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.616, Loss:  1.040
Epoch   0 Batch  518/1077 - Train Accuracy:  0.613, Validation Accuracy:  0.621, Loss:  1.047
Epoch   0 Batch  519/1077 - Train Accuracy:  0.610, Validation Accuracy:  0.625, Loss:  1.096
Epoch   0 Batch  520/1077 - Train Accuracy:  0.631, Validation Accuracy:  0.625, Loss:  0.990
Epoch   0 Batch  521/1077 - Train Accuracy:  0.610, Validation Accuracy:  0.602, Loss:  1.009
Epoch   0 Batch  522/1077 - Train Accuracy:  0.579, Validation Accuracy:  0.597, Loss:  1.163
Epoch   0 Batch  523/1077 - Train Accuracy:  0.587, Validation Accuracy:  0.603, Loss:  1.093
Epoch   0 Batch  524/1077 - Train Accuracy:  0.590, Validation Accuracy:  0.609, Loss:  1.101
Epoch   0 Batch  525/1077 - Train Accuracy:  0.623, Validation Accuracy:  0.606, Loss:  1.067
Epoch   0 Batch  526/1077 - Train Accuracy:  0.608, Validation Accuracy:  0.608, Loss:  1.030
Epoch   0 Batch  527/1077 - Train Accuracy:  0.586, Validation Accuracy:  0.613, Loss:  1.130
Epoch   0 Batch  528/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.600, Loss:  1.084
Epoch   0 Batch  529/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.598, Loss:  1.020
Epoch   0 Batch  530/1077 - Train Accuracy:  0.592, Validation Accuracy:  0.589, Loss:  1.070
Epoch   0 Batch  531/1077 - Train Accuracy:  0.597, Validation Accuracy:  0.588, Loss:  1.087
Epoch   0 Batch  532/1077 - Train Accuracy:  0.580, Validation Accuracy:  0.600, Loss:  1.108
Epoch   0 Batch  533/1077 - Train Accuracy:  0.617, Validation Accuracy:  0.599, Loss:  1.081
Epoch   0 Batch  534/1077 - Train Accuracy:  0.638, Validation Accuracy:  0.597, Loss:  1.028
Epoch   0 Batch  535/1077 - Train Accuracy:  0.597, Validation Accuracy:  0.596, Loss:  1.010
Epoch   0 Batch  536/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.600, Loss:  1.021
Epoch   0 Batch  537/1077 - Train Accuracy:  0.598, Validation Accuracy:  0.599, Loss:  1.076
Epoch   0 Batch  538/1077 - Train Accuracy:  0.622, Validation Accuracy:  0.600, Loss:  0.917
Epoch   0 Batch  539/1077 - Train Accuracy:  0.600, Validation Accuracy:  0.598, Loss:  1.118
Epoch   0 Batch  540/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.600, Loss:  1.022
Epoch   0 Batch  541/1077 - Train Accuracy:  0.593, Validation Accuracy:  0.599, Loss:  1.032
Epoch   0 Batch  542/1077 - Train Accuracy:  0.613, Validation Accuracy:  0.602, Loss:  1.010
Epoch   0 Batch  543/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.598, Loss:  1.064
Epoch   0 Batch  544/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.610, Loss:  0.967
Epoch   0 Batch  545/1077 - Train Accuracy:  0.621, Validation Accuracy:  0.603, Loss:  1.130
Epoch   0 Batch  546/1077 - Train Accuracy:  0.572, Validation Accuracy:  0.599, Loss:  1.115
Epoch   0 Batch  547/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.603, Loss:  1.000
Epoch   0 Batch  548/1077 - Train Accuracy:  0.614, Validation Accuracy:  0.609, Loss:  1.068
Epoch   0 Batch  549/1077 - Train Accuracy:  0.588, Validation Accuracy:  0.626, Loss:  1.108
Epoch   0 Batch  550/1077 - Train Accuracy:  0.586, Validation Accuracy:  0.645, Loss:  1.047
Epoch   0 Batch  551/1077 - Train Accuracy:  0.594, Validation Accuracy:  0.619, Loss:  1.070
Epoch   0 Batch  552/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.632, Loss:  1.043
Epoch   0 Batch  553/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.638, Loss:  1.014
Epoch   0 Batch  554/1077 - Train Accuracy:  0.631, Validation Accuracy:  0.625, Loss:  1.036
Epoch   0 Batch  555/1077 - Train Accuracy:  0.612, Validation Accuracy:  0.606, Loss:  0.974
Epoch   0 Batch  556/1077 - Train Accuracy:  0.594, Validation Accuracy:  0.616, Loss:  1.020
Epoch   0 Batch  557/1077 - Train Accuracy:  0.621, Validation Accuracy:  0.605, Loss:  1.039
Epoch   0 Batch  558/1077 - Train Accuracy:  0.610, Validation Accuracy:  0.609, Loss:  0.992
Epoch   0 Batch  559/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.608, Loss:  0.956
Epoch   0 Batch  560/1077 - Train Accuracy:  0.593, Validation Accuracy:  0.607, Loss:  0.990
Epoch   0 Batch  561/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.607, Loss:  0.959
Epoch   0 Batch  562/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.611, Loss:  0.913
Epoch   0 Batch  563/1077 - Train Accuracy:  0.589, Validation Accuracy:  0.613, Loss:  1.086
Epoch   0 Batch  564/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.627, Loss:  1.047
Epoch   0 Batch  565/1077 - Train Accuracy:  0.627, Validation Accuracy:  0.620, Loss:  1.008
Epoch   0 Batch  566/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.616, Loss:  1.026
Epoch   0 Batch  567/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.619, Loss:  0.975
Epoch   0 Batch  568/1077 - Train Accuracy:  0.621, Validation Accuracy:  0.613, Loss:  0.999
Epoch   0 Batch  569/1077 - Train Accuracy:  0.636, Validation Accuracy:  0.615, Loss:  1.007
Epoch   0 Batch  570/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.611, Loss:  1.021
Epoch   0 Batch  571/1077 - Train Accuracy:  0.638, Validation Accuracy:  0.625, Loss:  0.954
Epoch   0 Batch  572/1077 - Train Accuracy:  0.628, Validation Accuracy:  0.641, Loss:  0.942
Epoch   0 Batch  573/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.631, Loss:  1.010
Epoch   0 Batch  574/1077 - Train Accuracy:  0.588, Validation Accuracy:  0.627, Loss:  1.022
Epoch   0 Batch  575/1077 - Train Accuracy:  0.635, Validation Accuracy:  0.625, Loss:  0.987
Epoch   0 Batch  576/1077 - Train Accuracy:  0.630, Validation Accuracy:  0.632, Loss:  1.007
Epoch   0 Batch  577/1077 - Train Accuracy:  0.606, Validation Accuracy:  0.633, Loss:  1.050
Epoch   0 Batch  578/1077 - Train Accuracy:  0.582, Validation Accuracy:  0.623, Loss:  1.017
Epoch   0 Batch  579/1077 - Train Accuracy:  0.634, Validation Accuracy:  0.631, Loss:  0.970
Epoch   0 Batch  580/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.624, Loss:  0.852
Epoch   0 Batch  581/1077 - Train Accuracy:  0.613, Validation Accuracy:  0.632, Loss:  1.016
Epoch   0 Batch  582/1077 - Train Accuracy:  0.609, Validation Accuracy:  0.635, Loss:  0.969
Epoch   0 Batch  583/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.652, Loss:  1.000
Epoch   0 Batch  584/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.638, Loss:  1.001
Epoch   0 Batch  585/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.637, Loss:  0.912
Epoch   0 Batch  586/1077 - Train Accuracy:  0.614, Validation Accuracy:  0.632, Loss:  1.071
Epoch   0 Batch  587/1077 - Train Accuracy:  0.639, Validation Accuracy:  0.623, Loss:  0.885
Epoch   0 Batch  588/1077 - Train Accuracy:  0.609, Validation Accuracy:  0.612, Loss:  0.996
Epoch   0 Batch  589/1077 - Train Accuracy:  0.608, Validation Accuracy:  0.615, Loss:  1.013
Epoch   0 Batch  590/1077 - Train Accuracy:  0.613, Validation Accuracy:  0.623, Loss:  0.959
Epoch   0 Batch  591/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.622, Loss:  0.897
Epoch   0 Batch  592/1077 - Train Accuracy:  0.638, Validation Accuracy:  0.614, Loss:  0.971
Epoch   0 Batch  593/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.611, Loss:  0.925
Epoch   0 Batch  594/1077 - Train Accuracy:  0.596, Validation Accuracy:  0.615, Loss:  0.980
Epoch   0 Batch  595/1077 - Train Accuracy:  0.593, Validation Accuracy:  0.632, Loss:  1.030
Epoch   0 Batch  596/1077 - Train Accuracy:  0.623, Validation Accuracy:  0.631, Loss:  0.945
Epoch   0 Batch  597/1077 - Train Accuracy:  0.601, Validation Accuracy:  0.644, Loss:  1.005
Epoch   0 Batch  598/1077 - Train Accuracy:  0.635, Validation Accuracy:  0.630, Loss:  0.928
Epoch   0 Batch  599/1077 - Train Accuracy:  0.585, Validation Accuracy:  0.628, Loss:  1.074
Epoch   0 Batch  600/1077 - Train Accuracy:  0.650, Validation Accuracy:  0.625, Loss:  0.928
Epoch   0 Batch  601/1077 - Train Accuracy:  0.634, Validation Accuracy:  0.619, Loss:  0.938
Epoch   0 Batch  602/1077 - Train Accuracy:  0.625, Validation Accuracy:  0.616, Loss:  0.949
Epoch   0 Batch  603/1077 - Train Accuracy:  0.622, Validation Accuracy:  0.612, Loss:  0.994
Epoch   0 Batch  604/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.622, Loss:  1.039
Epoch   0 Batch  605/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.616, Loss:  1.004
Epoch   0 Batch  606/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.608, Loss:  0.927
Epoch   0 Batch  607/1077 - Train Accuracy:  0.668, Validation Accuracy:  0.612, Loss:  0.861
Epoch   0 Batch  608/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.617, Loss:  1.015
Epoch   0 Batch  609/1077 - Train Accuracy:  0.606, Validation Accuracy:  0.622, Loss:  0.892
Epoch   0 Batch  610/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.627, Loss:  0.979
Epoch   0 Batch  611/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.620, Loss:  0.914
Epoch   0 Batch  612/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.622, Loss:  0.893
Epoch   0 Batch  613/1077 - Train Accuracy:  0.600, Validation Accuracy:  0.619, Loss:  0.997
Epoch   0 Batch  614/1077 - Train Accuracy:  0.631, Validation Accuracy:  0.609, Loss:  0.879
Epoch   0 Batch  615/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.611, Loss:  0.921
Epoch   0 Batch  616/1077 - Train Accuracy:  0.590, Validation Accuracy:  0.613, Loss:  0.947
Epoch   0 Batch  617/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.620, Loss:  0.947
Epoch   0 Batch  618/1077 - Train Accuracy:  0.647, Validation Accuracy:  0.627, Loss:  0.858
Epoch   0 Batch  619/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.631, Loss:  0.963
Epoch   0 Batch  620/1077 - Train Accuracy:  0.628, Validation Accuracy:  0.632, Loss:  0.903
Epoch   0 Batch  621/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.635, Loss:  0.853
Epoch   0 Batch  622/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.619, Loss:  0.911
Epoch   0 Batch  623/1077 - Train Accuracy:  0.492, Validation Accuracy:  0.512, Loss:  1.112
Epoch   0 Batch  624/1077 - Train Accuracy:  0.566, Validation Accuracy:  0.544, Loss:  1.687
Epoch   0 Batch  625/1077 - Train Accuracy:  0.532, Validation Accuracy:  0.536, Loss:  1.647
Epoch   0 Batch  626/1077 - Train Accuracy:  0.558, Validation Accuracy:  0.528, Loss:  1.184
Epoch   0 Batch  627/1077 - Train Accuracy:  0.577, Validation Accuracy:  0.577, Loss:  1.485
Epoch   0 Batch  628/1077 - Train Accuracy:  0.526, Validation Accuracy:  0.537, Loss:  1.314
Epoch   0 Batch  629/1077 - Train Accuracy:  0.520, Validation Accuracy:  0.555, Loss:  1.442
Epoch   0 Batch  630/1077 - Train Accuracy:  0.507, Validation Accuracy:  0.545, Loss:  1.189
Epoch   0 Batch  631/1077 - Train Accuracy:  0.557, Validation Accuracy:  0.574, Loss:  1.283
Epoch   0 Batch  632/1077 - Train Accuracy:  0.582, Validation Accuracy:  0.603, Loss:  1.232
Epoch   0 Batch  633/1077 - Train Accuracy:  0.581, Validation Accuracy:  0.585, Loss:  1.114
Epoch   0 Batch  634/1077 - Train Accuracy:  0.566, Validation Accuracy:  0.578, Loss:  1.153
Epoch   0 Batch  635/1077 - Train Accuracy:  0.563, Validation Accuracy:  0.583, Loss:  1.152
Epoch   0 Batch  636/1077 - Train Accuracy:  0.599, Validation Accuracy:  0.598, Loss:  1.077
Epoch   0 Batch  637/1077 - Train Accuracy:  0.568, Validation Accuracy:  0.582, Loss:  1.065
Epoch   0 Batch  638/1077 - Train Accuracy:  0.561, Validation Accuracy:  0.553, Loss:  1.098
Epoch   0 Batch  639/1077 - Train Accuracy:  0.568, Validation Accuracy:  0.546, Loss:  1.057
Epoch   0 Batch  640/1077 - Train Accuracy:  0.551, Validation Accuracy:  0.547, Loss:  1.057
Epoch   0 Batch  641/1077 - Train Accuracy:  0.594, Validation Accuracy:  0.585, Loss:  1.045
Epoch   0 Batch  642/1077 - Train Accuracy:  0.606, Validation Accuracy:  0.598, Loss:  1.024
Epoch   0 Batch  643/1077 - Train Accuracy:  0.607, Validation Accuracy:  0.605, Loss:  0.930
Epoch   0 Batch  644/1077 - Train Accuracy:  0.608, Validation Accuracy:  0.605, Loss:  0.996
Epoch   0 Batch  645/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.599, Loss:  1.019
Epoch   0 Batch  646/1077 - Train Accuracy:  0.615, Validation Accuracy:  0.598, Loss:  0.989
Epoch   0 Batch  647/1077 - Train Accuracy:  0.609, Validation Accuracy:  0.603, Loss:  0.992
Epoch   0 Batch  648/1077 - Train Accuracy:  0.607, Validation Accuracy:  0.591, Loss:  0.926
Epoch   0 Batch  649/1077 - Train Accuracy:  0.579, Validation Accuracy:  0.589, Loss:  1.039
Epoch   0 Batch  650/1077 - Train Accuracy:  0.565, Validation Accuracy:  0.596, Loss:  0.998
Epoch   0 Batch  651/1077 - Train Accuracy:  0.609, Validation Accuracy:  0.604, Loss:  0.935
Epoch   0 Batch  652/1077 - Train Accuracy:  0.584, Validation Accuracy:  0.608, Loss:  1.005
Epoch   0 Batch  653/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.614, Loss:  0.956
Epoch   0 Batch  654/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.625, Loss:  0.898
Epoch   0 Batch  655/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.621, Loss:  0.936
Epoch   0 Batch  656/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.616, Loss:  0.927
Epoch   0 Batch  657/1077 - Train Accuracy:  0.632, Validation Accuracy:  0.616, Loss:  0.912
Epoch   0 Batch  658/1077 - Train Accuracy:  0.596, Validation Accuracy:  0.614, Loss:  0.873
Epoch   0 Batch  659/1077 - Train Accuracy:  0.655, Validation Accuracy:  0.614, Loss:  0.879
Epoch   0 Batch  660/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.611, Loss:  0.916
Epoch   0 Batch  661/1077 - Train Accuracy:  0.632, Validation Accuracy:  0.610, Loss:  0.856
Epoch   0 Batch  662/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.612, Loss:  0.886
Epoch   0 Batch  663/1077 - Train Accuracy:  0.625, Validation Accuracy:  0.612, Loss:  0.870
Epoch   0 Batch  664/1077 - Train Accuracy:  0.628, Validation Accuracy:  0.608, Loss:  0.867
Epoch   0 Batch  665/1077 - Train Accuracy:  0.602, Validation Accuracy:  0.613, Loss:  0.876
Epoch   0 Batch  666/1077 - Train Accuracy:  0.594, Validation Accuracy:  0.612, Loss:  0.993
Epoch   0 Batch  667/1077 - Train Accuracy:  0.603, Validation Accuracy:  0.622, Loss:  0.972
Epoch   0 Batch  668/1077 - Train Accuracy:  0.601, Validation Accuracy:  0.621, Loss:  0.862
Epoch   0 Batch  669/1077 - Train Accuracy:  0.612, Validation Accuracy:  0.625, Loss:  0.874
Epoch   0 Batch  670/1077 - Train Accuracy:  0.676, Validation Accuracy:  0.632, Loss:  0.806
Epoch   0 Batch  671/1077 - Train Accuracy:  0.609, Validation Accuracy:  0.623, Loss:  0.961
Epoch   0 Batch  672/1077 - Train Accuracy:  0.662, Validation Accuracy:  0.628, Loss:  0.885
Epoch   0 Batch  673/1077 - Train Accuracy:  0.630, Validation Accuracy:  0.623, Loss:  0.887
Epoch   0 Batch  674/1077 - Train Accuracy:  0.638, Validation Accuracy:  0.631, Loss:  0.890
Epoch   0 Batch  675/1077 - Train Accuracy:  0.625, Validation Accuracy:  0.640, Loss:  0.918
Epoch   0 Batch  676/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.645, Loss:  0.855
Epoch   0 Batch  677/1077 - Train Accuracy:  0.600, Validation Accuracy:  0.642, Loss:  0.958
Epoch   0 Batch  678/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.639, Loss:  0.865
Epoch   0 Batch  679/1077 - Train Accuracy:  0.610, Validation Accuracy:  0.651, Loss:  0.912
Epoch   0 Batch  680/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.647, Loss:  0.877
Epoch   0 Batch  681/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.622, Loss:  0.865
Epoch   0 Batch  682/1077 - Train Accuracy:  0.624, Validation Accuracy:  0.629, Loss:  0.867
Epoch   0 Batch  683/1077 - Train Accuracy:  0.602, Validation Accuracy:  0.624, Loss:  0.872
Epoch   0 Batch  684/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.579, Loss:  0.840
Epoch   0 Batch  685/1077 - Train Accuracy:  0.593, Validation Accuracy:  0.584, Loss:  0.920
Epoch   0 Batch  686/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.625, Loss:  0.852
Epoch   0 Batch  687/1077 - Train Accuracy:  0.625, Validation Accuracy:  0.623, Loss:  0.923
Epoch   0 Batch  688/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.626, Loss:  0.886
Epoch   0 Batch  689/1077 - Train Accuracy:  0.621, Validation Accuracy:  0.630, Loss:  0.868
Epoch   0 Batch  690/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.622, Loss:  0.849
Epoch   0 Batch  691/1077 - Train Accuracy:  0.610, Validation Accuracy:  0.614, Loss:  0.896
Epoch   0 Batch  692/1077 - Train Accuracy:  0.647, Validation Accuracy:  0.599, Loss:  0.837
Epoch   0 Batch  693/1077 - Train Accuracy:  0.567, Validation Accuracy:  0.607, Loss:  1.018
Epoch   0 Batch  694/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.634, Loss:  0.840
Epoch   0 Batch  695/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.641, Loss:  0.850
Epoch   0 Batch  696/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.640, Loss:  0.958
Epoch   0 Batch  697/1077 - Train Accuracy:  0.634, Validation Accuracy:  0.643, Loss:  0.852
Epoch   0 Batch  698/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.646, Loss:  0.839
Epoch   0 Batch  699/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.638, Loss:  0.916
Epoch   0 Batch  700/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.640, Loss:  0.825
Epoch   0 Batch  701/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.638, Loss:  0.915
Epoch   0 Batch  702/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.637, Loss:  0.882
Epoch   0 Batch  703/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.636, Loss:  0.873
Epoch   0 Batch  704/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.633, Loss:  0.901
Epoch   0 Batch  705/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.630, Loss:  0.910
Epoch   0 Batch  706/1077 - Train Accuracy:  0.624, Validation Accuracy:  0.628, Loss:  0.861
Epoch   0 Batch  707/1077 - Train Accuracy:  0.628, Validation Accuracy:  0.635, Loss:  0.854
Epoch   0 Batch  708/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.619, Loss:  0.860
Epoch   0 Batch  709/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.634, Loss:  0.878
Epoch   0 Batch  710/1077 - Train Accuracy:  0.617, Validation Accuracy:  0.630, Loss:  0.864
Epoch   0 Batch  711/1077 - Train Accuracy:  0.626, Validation Accuracy:  0.642, Loss:  0.867
Epoch   0 Batch  712/1077 - Train Accuracy:  0.646, Validation Accuracy:  0.643, Loss:  0.863
Epoch   0 Batch  713/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.645, Loss:  0.800
Epoch   0 Batch  714/1077 - Train Accuracy:  0.619, Validation Accuracy:  0.631, Loss:  1.009
Epoch   0 Batch  715/1077 - Train Accuracy:  0.590, Validation Accuracy:  0.616, Loss:  0.967
Epoch   0 Batch  716/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.626, Loss:  0.912
Epoch   0 Batch  717/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.637, Loss:  0.855
Epoch   0 Batch  718/1077 - Train Accuracy:  0.624, Validation Accuracy:  0.636, Loss:  0.871
Epoch   0 Batch  719/1077 - Train Accuracy:  0.619, Validation Accuracy:  0.627, Loss:  0.849
Epoch   0 Batch  720/1077 - Train Accuracy:  0.600, Validation Accuracy:  0.629, Loss:  0.938
Epoch   0 Batch  721/1077 - Train Accuracy:  0.615, Validation Accuracy:  0.634, Loss:  0.895
Epoch   0 Batch  722/1077 - Train Accuracy:  0.627, Validation Accuracy:  0.635, Loss:  0.856
Epoch   0 Batch  723/1077 - Train Accuracy:  0.665, Validation Accuracy:  0.632, Loss:  0.835
Epoch   0 Batch  724/1077 - Train Accuracy:  0.638, Validation Accuracy:  0.627, Loss:  0.874
Epoch   0 Batch  725/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.632, Loss:  0.804
Epoch   0 Batch  726/1077 - Train Accuracy:  0.670, Validation Accuracy:  0.636, Loss:  0.817
Epoch   0 Batch  727/1077 - Train Accuracy:  0.655, Validation Accuracy:  0.638, Loss:  0.819
Epoch   0 Batch  728/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.634, Loss:  0.853
Epoch   0 Batch  729/1077 - Train Accuracy:  0.595, Validation Accuracy:  0.630, Loss:  0.888
Epoch   0 Batch  730/1077 - Train Accuracy:  0.621, Validation Accuracy:  0.607, Loss:  0.833
Epoch   0 Batch  731/1077 - Train Accuracy:  0.617, Validation Accuracy:  0.603, Loss:  0.887
Epoch   0 Batch  732/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.616, Loss:  0.908
Epoch   0 Batch  733/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.625, Loss:  0.849
Epoch   0 Batch  734/1077 - Train Accuracy:  0.630, Validation Accuracy:  0.627, Loss:  0.892
Epoch   0 Batch  735/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.624, Loss:  0.820
Epoch   0 Batch  736/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.629, Loss:  0.806
Epoch   0 Batch  737/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.631, Loss:  0.870
Epoch   0 Batch  738/1077 - Train Accuracy:  0.666, Validation Accuracy:  0.634, Loss:  0.759
Epoch   0 Batch  739/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.645, Loss:  0.828
Epoch   0 Batch  740/1077 - Train Accuracy:  0.659, Validation Accuracy:  0.654, Loss:  0.822
Epoch   0 Batch  741/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.654, Loss:  0.849
Epoch   0 Batch  742/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.661, Loss:  0.815
Epoch   0 Batch  743/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.665, Loss:  0.856
Epoch   0 Batch  744/1077 - Train Accuracy:  0.655, Validation Accuracy:  0.654, Loss:  0.805
Epoch   0 Batch  745/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.648, Loss:  0.843
Epoch   0 Batch  746/1077 - Train Accuracy:  0.665, Validation Accuracy:  0.652, Loss:  0.789
Epoch   0 Batch  747/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.652, Loss:  0.795
Epoch   0 Batch  748/1077 - Train Accuracy:  0.634, Validation Accuracy:  0.658, Loss:  0.837
Epoch   0 Batch  749/1077 - Train Accuracy:  0.615, Validation Accuracy:  0.654, Loss:  0.867
Epoch   0 Batch  750/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.659, Loss:  0.802
Epoch   0 Batch  751/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.645, Loss:  0.821
Epoch   0 Batch  752/1077 - Train Accuracy:  0.632, Validation Accuracy:  0.647, Loss:  0.795
Epoch   0 Batch  753/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.645, Loss:  0.819
Epoch   0 Batch  754/1077 - Train Accuracy:  0.636, Validation Accuracy:  0.645, Loss:  0.810
Epoch   0 Batch  755/1077 - Train Accuracy:  0.636, Validation Accuracy:  0.642, Loss:  0.818
Epoch   0 Batch  756/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.639, Loss:  0.791
Epoch   0 Batch  757/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.638, Loss:  0.869
Epoch   0 Batch  758/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.631, Loss:  0.760
Epoch   0 Batch  759/1077 - Train Accuracy:  0.664, Validation Accuracy:  0.636, Loss:  0.750
Epoch   0 Batch  760/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.644, Loss:  0.830
Epoch   0 Batch  761/1077 - Train Accuracy:  0.601, Validation Accuracy:  0.645, Loss:  0.860
Epoch   0 Batch  762/1077 - Train Accuracy:  0.674, Validation Accuracy:  0.638, Loss:  0.785
Epoch   0 Batch  763/1077 - Train Accuracy:  0.654, Validation Accuracy:  0.646, Loss:  0.763
Epoch   0 Batch  764/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.654, Loss:  0.813
Epoch   0 Batch  765/1077 - Train Accuracy:  0.672, Validation Accuracy:  0.660, Loss:  0.767
Epoch   0 Batch  766/1077 - Train Accuracy:  0.634, Validation Accuracy:  0.674, Loss:  0.849
Epoch   0 Batch  767/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.667, Loss:  0.783
Epoch   0 Batch  768/1077 - Train Accuracy:  0.616, Validation Accuracy:  0.674, Loss:  0.862
Epoch   0 Batch  769/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.673, Loss:  0.822
Epoch   0 Batch  770/1077 - Train Accuracy:  0.635, Validation Accuracy:  0.663, Loss:  0.813
Epoch   0 Batch  771/1077 - Train Accuracy:  0.675, Validation Accuracy:  0.663, Loss:  0.795
Epoch   0 Batch  772/1077 - Train Accuracy:  0.670, Validation Accuracy:  0.656, Loss:  0.777
Epoch   0 Batch  773/1077 - Train Accuracy:  0.664, Validation Accuracy:  0.655, Loss:  0.780
Epoch   0 Batch  774/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.652, Loss:  0.801
Epoch   0 Batch  775/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.645, Loss:  0.796
Epoch   0 Batch  776/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.634, Loss:  0.789
Epoch   0 Batch  777/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.629, Loss:  0.823
Epoch   0 Batch  778/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.635, Loss:  0.789
Epoch   0 Batch  779/1077 - Train Accuracy:  0.630, Validation Accuracy:  0.640, Loss:  0.837
Epoch   0 Batch  780/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.654, Loss:  0.850
Epoch   0 Batch  781/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.647, Loss:  0.698
Epoch   0 Batch  782/1077 - Train Accuracy:  0.642, Validation Accuracy:  0.656, Loss:  0.778
Epoch   0 Batch  783/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.642, Loss:  0.816
Epoch   0 Batch  784/1077 - Train Accuracy:  0.674, Validation Accuracy:  0.645, Loss:  0.778
Epoch   0 Batch  785/1077 - Train Accuracy:  0.676, Validation Accuracy:  0.646, Loss:  0.734
Epoch   0 Batch  786/1077 - Train Accuracy:  0.613, Validation Accuracy:  0.642, Loss:  0.824
Epoch   0 Batch  787/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.643, Loss:  0.754
Epoch   0 Batch  788/1077 - Train Accuracy:  0.647, Validation Accuracy:  0.637, Loss:  0.782
Epoch   0 Batch  789/1077 - Train Accuracy:  0.624, Validation Accuracy:  0.652, Loss:  0.841
Epoch   0 Batch  790/1077 - Train Accuracy:  0.601, Validation Accuracy:  0.654, Loss:  0.856
Epoch   0 Batch  791/1077 - Train Accuracy:  0.646, Validation Accuracy:  0.650, Loss:  0.820
Epoch   0 Batch  792/1077 - Train Accuracy:  0.650, Validation Accuracy:  0.661, Loss:  0.822
Epoch   0 Batch  793/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.658, Loss:  0.776
Epoch   0 Batch  794/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.657, Loss:  0.782
Epoch   0 Batch  795/1077 - Train Accuracy:  0.659, Validation Accuracy:  0.659, Loss:  0.822
Epoch   0 Batch  796/1077 - Train Accuracy:  0.649, Validation Accuracy:  0.657, Loss:  0.801
Epoch   0 Batch  797/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.657, Loss:  0.768
Epoch   0 Batch  798/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.658, Loss:  0.798
Epoch   0 Batch  799/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.642, Loss:  0.847
Epoch   0 Batch  800/1077 - Train Accuracy:  0.636, Validation Accuracy:  0.636, Loss:  0.770
Epoch   0 Batch  801/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.647, Loss:  0.822
Epoch   0 Batch  802/1077 - Train Accuracy:  0.667, Validation Accuracy:  0.655, Loss:  0.739
Epoch   0 Batch  803/1077 - Train Accuracy:  0.642, Validation Accuracy:  0.654, Loss:  0.793
Epoch   0 Batch  804/1077 - Train Accuracy:  0.647, Validation Accuracy:  0.652, Loss:  0.771
Epoch   0 Batch  805/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.653, Loss:  0.784
Epoch   0 Batch  806/1077 - Train Accuracy:  0.653, Validation Accuracy:  0.657, Loss:  0.788
Epoch   0 Batch  807/1077 - Train Accuracy:  0.662, Validation Accuracy:  0.666, Loss:  0.762
Epoch   0 Batch  808/1077 - Train Accuracy:  0.661, Validation Accuracy:  0.662, Loss:  0.778
Epoch   0 Batch  809/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.655, Loss:  0.830
Epoch   0 Batch  810/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.650, Loss:  0.738
Epoch   0 Batch  811/1077 - Train Accuracy:  0.670, Validation Accuracy:  0.652, Loss:  0.715
Epoch   0 Batch  812/1077 - Train Accuracy:  0.636, Validation Accuracy:  0.650, Loss:  0.791
Epoch   0 Batch  813/1077 - Train Accuracy:  0.656, Validation Accuracy:  0.654, Loss:  0.748
Epoch   0 Batch  814/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.658, Loss:  0.796
Epoch   0 Batch  815/1077 - Train Accuracy:  0.641, Validation Accuracy:  0.655, Loss:  0.784
Epoch   0 Batch  816/1077 - Train Accuracy:  0.690, Validation Accuracy:  0.658, Loss:  0.779
Epoch   0 Batch  817/1077 - Train Accuracy:  0.631, Validation Accuracy:  0.660, Loss:  0.839
Epoch   0 Batch  818/1077 - Train Accuracy:  0.646, Validation Accuracy:  0.665, Loss:  0.832
Epoch   0 Batch  819/1077 - Train Accuracy:  0.644, Validation Accuracy:  0.659, Loss:  0.796
Epoch   0 Batch  820/1077 - Train Accuracy:  0.620, Validation Accuracy:  0.667, Loss:  0.759
Epoch   0 Batch  821/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.663, Loss:  0.739
Epoch   0 Batch  822/1077 - Train Accuracy:  0.661, Validation Accuracy:  0.658, Loss:  0.749
Epoch   0 Batch  823/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.654, Loss:  0.762
Epoch   0 Batch  824/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.650, Loss:  0.750
Epoch   0 Batch  825/1077 - Train Accuracy:  0.677, Validation Accuracy:  0.656, Loss:  0.734
Epoch   0 Batch  826/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.651, Loss:  0.731
Epoch   0 Batch  827/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.655, Loss:  0.808
Epoch   0 Batch  828/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.656, Loss:  0.724
Epoch   0 Batch  829/1077 - Train Accuracy:  0.664, Validation Accuracy:  0.659, Loss:  0.796
Epoch   0 Batch  830/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.661, Loss:  0.774
Epoch   0 Batch  831/1077 - Train Accuracy:  0.615, Validation Accuracy:  0.663, Loss:  0.801
Epoch   0 Batch  832/1077 - Train Accuracy:  0.690, Validation Accuracy:  0.671, Loss:  0.749
Epoch   0 Batch  833/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.665, Loss:  0.768
Epoch   0 Batch  834/1077 - Train Accuracy:  0.677, Validation Accuracy:  0.669, Loss:  0.729
Epoch   0 Batch  835/1077 - Train Accuracy:  0.659, Validation Accuracy:  0.672, Loss:  0.788
Epoch   0 Batch  836/1077 - Train Accuracy:  0.674, Validation Accuracy:  0.677, Loss:  0.793
Epoch   0 Batch  837/1077 - Train Accuracy:  0.659, Validation Accuracy:  0.679, Loss:  0.834
Epoch   0 Batch  838/1077 - Train Accuracy:  0.638, Validation Accuracy:  0.673, Loss:  0.724
Epoch   0 Batch  839/1077 - Train Accuracy:  0.675, Validation Accuracy:  0.664, Loss:  0.731
Epoch   0 Batch  840/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.668, Loss:  0.741
Epoch   0 Batch  841/1077 - Train Accuracy:  0.668, Validation Accuracy:  0.672, Loss:  0.745
Epoch   0 Batch  842/1077 - Train Accuracy:  0.684, Validation Accuracy:  0.668, Loss:  0.743
Epoch   0 Batch  843/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.675, Loss:  0.706
Epoch   0 Batch  844/1077 - Train Accuracy:  0.677, Validation Accuracy:  0.677, Loss:  0.727
Epoch   0 Batch  845/1077 - Train Accuracy:  0.660, Validation Accuracy:  0.682, Loss:  0.766
Epoch   0 Batch  846/1077 - Train Accuracy:  0.665, Validation Accuracy:  0.669, Loss:  0.761
Epoch   0 Batch  847/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.664, Loss:  0.766
Epoch   0 Batch  848/1077 - Train Accuracy:  0.668, Validation Accuracy:  0.668, Loss:  0.764
Epoch   0 Batch  849/1077 - Train Accuracy:  0.675, Validation Accuracy:  0.670, Loss:  0.694
Epoch   0 Batch  850/1077 - Train Accuracy:  0.636, Validation Accuracy:  0.670, Loss:  0.798
Epoch   0 Batch  851/1077 - Train Accuracy:  0.672, Validation Accuracy:  0.674, Loss:  0.771
Epoch   0 Batch  852/1077 - Train Accuracy:  0.646, Validation Accuracy:  0.668, Loss:  0.770
Epoch   0 Batch  853/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.670, Loss:  0.686
Epoch   0 Batch  854/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.672, Loss:  0.764
Epoch   0 Batch  855/1077 - Train Accuracy:  0.666, Validation Accuracy:  0.670, Loss:  0.734
Epoch   0 Batch  856/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.674, Loss:  0.740
Epoch   0 Batch  857/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.669, Loss:  0.733
Epoch   0 Batch  858/1077 - Train Accuracy:  0.677, Validation Accuracy:  0.673, Loss:  0.746
Epoch   0 Batch  859/1077 - Train Accuracy:  0.684, Validation Accuracy:  0.670, Loss:  0.738
Epoch   0 Batch  860/1077 - Train Accuracy:  0.650, Validation Accuracy:  0.677, Loss:  0.736
Epoch   0 Batch  861/1077 - Train Accuracy:  0.676, Validation Accuracy:  0.675, Loss:  0.752
Epoch   0 Batch  862/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.663, Loss:  0.749
Epoch   0 Batch  863/1077 - Train Accuracy:  0.689, Validation Accuracy:  0.651, Loss:  0.716
Epoch   0 Batch  864/1077 - Train Accuracy:  0.647, Validation Accuracy:  0.657, Loss:  0.738
Epoch   0 Batch  865/1077 - Train Accuracy:  0.710, Validation Accuracy:  0.663, Loss:  0.678
Epoch   0 Batch  866/1077 - Train Accuracy:  0.672, Validation Accuracy:  0.667, Loss:  0.735
Epoch   0 Batch  867/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.653, Loss:  0.815
Epoch   0 Batch  868/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.650, Loss:  0.770
Epoch   0 Batch  869/1077 - Train Accuracy:  0.649, Validation Accuracy:  0.649, Loss:  0.758
Epoch   0 Batch  870/1077 - Train Accuracy:  0.605, Validation Accuracy:  0.665, Loss:  0.810
Epoch   0 Batch  871/1077 - Train Accuracy:  0.628, Validation Accuracy:  0.661, Loss:  0.769
Epoch   0 Batch  872/1077 - Train Accuracy:  0.692, Validation Accuracy:  0.668, Loss:  0.721
Epoch   0 Batch  873/1077 - Train Accuracy:  0.639, Validation Accuracy:  0.661, Loss:  0.731
Epoch   0 Batch  874/1077 - Train Accuracy:  0.642, Validation Accuracy:  0.660, Loss:  0.750
Epoch   0 Batch  875/1077 - Train Accuracy:  0.662, Validation Accuracy:  0.670, Loss:  0.733
Epoch   0 Batch  876/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.671, Loss:  0.728
Epoch   0 Batch  877/1077 - Train Accuracy:  0.672, Validation Accuracy:  0.670, Loss:  0.721
Epoch   0 Batch  878/1077 - Train Accuracy:  0.685, Validation Accuracy:  0.677, Loss:  0.747
Epoch   0 Batch  879/1077 - Train Accuracy:  0.693, Validation Accuracy:  0.672, Loss:  0.691
Epoch   0 Batch  880/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.672, Loss:  0.733
Epoch   0 Batch  881/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.671, Loss:  0.751
Epoch   0 Batch  882/1077 - Train Accuracy:  0.670, Validation Accuracy:  0.672, Loss:  0.737
Epoch   0 Batch  883/1077 - Train Accuracy:  0.601, Validation Accuracy:  0.670, Loss:  0.819
Epoch   0 Batch  884/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.669, Loss:  0.727
Epoch   0 Batch  885/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.680, Loss:  0.627
Epoch   0 Batch  886/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.679, Loss:  0.755
Epoch   0 Batch  887/1077 - Train Accuracy:  0.646, Validation Accuracy:  0.676, Loss:  0.784
Epoch   0 Batch  888/1077 - Train Accuracy:  0.671, Validation Accuracy:  0.665, Loss:  0.857
Epoch   0 Batch  889/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.651, Loss:  0.743
Epoch   0 Batch  890/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.649, Loss:  0.718
Epoch   0 Batch  891/1077 - Train Accuracy:  0.653, Validation Accuracy:  0.659, Loss:  0.765
Epoch   0 Batch  892/1077 - Train Accuracy:  0.680, Validation Accuracy:  0.662, Loss:  0.708
Epoch   0 Batch  893/1077 - Train Accuracy:  0.667, Validation Accuracy:  0.664, Loss:  0.745
Epoch   0 Batch  894/1077 - Train Accuracy:  0.667, Validation Accuracy:  0.667, Loss:  0.710
Epoch   0 Batch  895/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.675, Loss:  0.743
Epoch   0 Batch  896/1077 - Train Accuracy:  0.623, Validation Accuracy:  0.668, Loss:  0.794
Epoch   0 Batch  897/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.676, Loss:  0.701
Epoch   0 Batch  898/1077 - Train Accuracy:  0.671, Validation Accuracy:  0.677, Loss:  0.685
Epoch   0 Batch  899/1077 - Train Accuracy:  0.650, Validation Accuracy:  0.669, Loss:  0.774
Epoch   0 Batch  900/1077 - Train Accuracy:  0.654, Validation Accuracy:  0.673, Loss:  0.754
Epoch   0 Batch  901/1077 - Train Accuracy:  0.665, Validation Accuracy:  0.677, Loss:  0.793
Epoch   0 Batch  902/1077 - Train Accuracy:  0.692, Validation Accuracy:  0.675, Loss:  0.756
Epoch   0 Batch  903/1077 - Train Accuracy:  0.666, Validation Accuracy:  0.663, Loss:  0.696
Epoch   0 Batch  904/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.680, Loss:  0.783
Epoch   0 Batch  905/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.687, Loss:  0.676
Epoch   0 Batch  906/1077 - Train Accuracy:  0.667, Validation Accuracy:  0.682, Loss:  0.700
Epoch   0 Batch  907/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.687, Loss:  0.738
Epoch   0 Batch  908/1077 - Train Accuracy:  0.655, Validation Accuracy:  0.681, Loss:  0.753
Epoch   0 Batch  909/1077 - Train Accuracy:  0.649, Validation Accuracy:  0.679, Loss:  0.721
Epoch   0 Batch  910/1077 - Train Accuracy:  0.669, Validation Accuracy:  0.675, Loss:  0.735
Epoch   0 Batch  911/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.679, Loss:  0.676
Epoch   0 Batch  912/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.674, Loss:  0.730
Epoch   0 Batch  913/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.665, Loss:  0.739
Epoch   0 Batch  914/1077 - Train Accuracy:  0.713, Validation Accuracy:  0.644, Loss:  0.674
Epoch   0 Batch  915/1077 - Train Accuracy:  0.623, Validation Accuracy:  0.645, Loss:  0.773
Epoch   0 Batch  916/1077 - Train Accuracy:  0.656, Validation Accuracy:  0.657, Loss:  0.823
Epoch   0 Batch  917/1077 - Train Accuracy:  0.653, Validation Accuracy:  0.661, Loss:  0.742
Epoch   0 Batch  918/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.654, Loss:  0.673
Epoch   0 Batch  919/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.650, Loss:  0.768
Epoch   0 Batch  920/1077 - Train Accuracy:  0.660, Validation Accuracy:  0.651, Loss:  0.740
Epoch   0 Batch  921/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.653, Loss:  0.735
Epoch   0 Batch  922/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.662, Loss:  0.737
Epoch   0 Batch  923/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.676, Loss:  0.757
Epoch   0 Batch  924/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.685, Loss:  0.764
Epoch   0 Batch  925/1077 - Train Accuracy:  0.717, Validation Accuracy:  0.694, Loss:  0.701
Epoch   0 Batch  926/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.686, Loss:  0.754
Epoch   0 Batch  927/1077 - Train Accuracy:  0.629, Validation Accuracy:  0.680, Loss:  0.769
Epoch   0 Batch  928/1077 - Train Accuracy:  0.655, Validation Accuracy:  0.676, Loss:  0.756
Epoch   0 Batch  929/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.671, Loss:  0.755
Epoch   0 Batch  930/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.671, Loss:  0.723
Epoch   0 Batch  931/1077 - Train Accuracy:  0.668, Validation Accuracy:  0.668, Loss:  0.701
Epoch   0 Batch  932/1077 - Train Accuracy:  0.618, Validation Accuracy:  0.657, Loss:  0.784
Epoch   0 Batch  933/1077 - Train Accuracy:  0.680, Validation Accuracy:  0.660, Loss:  0.772
Epoch   0 Batch  934/1077 - Train Accuracy:  0.649, Validation Accuracy:  0.670, Loss:  0.735
Epoch   0 Batch  935/1077 - Train Accuracy:  0.665, Validation Accuracy:  0.670, Loss:  0.724
Epoch   0 Batch  936/1077 - Train Accuracy:  0.680, Validation Accuracy:  0.674, Loss:  0.708
Epoch   0 Batch  937/1077 - Train Accuracy:  0.669, Validation Accuracy:  0.672, Loss:  0.736
Epoch   0 Batch  938/1077 - Train Accuracy:  0.689, Validation Accuracy:  0.665, Loss:  0.736
Epoch   0 Batch  939/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.673, Loss:  0.719
Epoch   0 Batch  940/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.673, Loss:  0.695
Epoch   0 Batch  941/1077 - Train Accuracy:  0.690, Validation Accuracy:  0.665, Loss:  0.669
Epoch   0 Batch  942/1077 - Train Accuracy:  0.662, Validation Accuracy:  0.662, Loss:  0.742
Epoch   0 Batch  943/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.665, Loss:  0.722
Epoch   0 Batch  944/1077 - Train Accuracy:  0.639, Validation Accuracy:  0.669, Loss:  0.720
Epoch   0 Batch  945/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.672, Loss:  0.696
Epoch   0 Batch  946/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.672, Loss:  0.717
Epoch   0 Batch  947/1077 - Train Accuracy:  0.611, Validation Accuracy:  0.674, Loss:  0.793
Epoch   0 Batch  948/1077 - Train Accuracy:  0.661, Validation Accuracy:  0.687, Loss:  0.715
Epoch   0 Batch  949/1077 - Train Accuracy:  0.718, Validation Accuracy:  0.680, Loss:  0.636
Epoch   0 Batch  950/1077 - Train Accuracy:  0.651, Validation Accuracy:  0.680, Loss:  0.703
Epoch   0 Batch  951/1077 - Train Accuracy:  0.703, Validation Accuracy:  0.689, Loss:  0.703
Epoch   0 Batch  952/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.688, Loss:  0.698
Epoch   0 Batch  953/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.683, Loss:  0.680
Epoch   0 Batch  954/1077 - Train Accuracy:  0.631, Validation Accuracy:  0.680, Loss:  0.738
Epoch   0 Batch  955/1077 - Train Accuracy:  0.699, Validation Accuracy:  0.681, Loss:  0.706
Epoch   0 Batch  956/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.682, Loss:  0.685
Epoch   0 Batch  957/1077 - Train Accuracy:  0.712, Validation Accuracy:  0.688, Loss:  0.656
Epoch   0 Batch  958/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.692, Loss:  0.704
Epoch   0 Batch  959/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.690, Loss:  0.674
Epoch   0 Batch  960/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.695, Loss:  0.703
Epoch   0 Batch  961/1077 - Train Accuracy:  0.661, Validation Accuracy:  0.695, Loss:  0.704
Epoch   0 Batch  962/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.689, Loss:  0.691
Epoch   0 Batch  963/1077 - Train Accuracy:  0.655, Validation Accuracy:  0.682, Loss:  0.763
Epoch   0 Batch  964/1077 - Train Accuracy:  0.696, Validation Accuracy:  0.684, Loss:  0.667
Epoch   0 Batch  965/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.695, Loss:  0.762
Epoch   0 Batch  966/1077 - Train Accuracy:  0.724, Validation Accuracy:  0.701, Loss:  0.610
Epoch   0 Batch  967/1077 - Train Accuracy:  0.659, Validation Accuracy:  0.702, Loss:  0.724
Epoch   0 Batch  968/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.693, Loss:  0.770
Epoch   0 Batch  969/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.693, Loss:  0.720
Epoch   0 Batch  970/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.703, Loss:  0.715
Epoch   0 Batch  971/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.689, Loss:  0.679
Epoch   0 Batch  972/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.683, Loss:  0.714
Epoch   0 Batch  973/1077 - Train Accuracy:  0.720, Validation Accuracy:  0.683, Loss:  0.624
Epoch   0 Batch  974/1077 - Train Accuracy:  0.664, Validation Accuracy:  0.680, Loss:  0.690
Epoch   0 Batch  975/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.686, Loss:  0.645
Epoch   0 Batch  976/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.672, Loss:  0.668
Epoch   0 Batch  977/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.675, Loss:  0.659
Epoch   0 Batch  978/1077 - Train Accuracy:  0.703, Validation Accuracy:  0.663, Loss:  0.708
Epoch   0 Batch  979/1077 - Train Accuracy:  0.653, Validation Accuracy:  0.676, Loss:  0.747
Epoch   0 Batch  980/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.684, Loss:  0.705
Epoch   0 Batch  981/1077 - Train Accuracy:  0.674, Validation Accuracy:  0.696, Loss:  0.713
Epoch   0 Batch  982/1077 - Train Accuracy:  0.681, Validation Accuracy:  0.695, Loss:  0.675
Epoch   0 Batch  983/1077 - Train Accuracy:  0.671, Validation Accuracy:  0.693, Loss:  0.719
Epoch   0 Batch  984/1077 - Train Accuracy:  0.645, Validation Accuracy:  0.689, Loss:  0.739
Epoch   0 Batch  985/1077 - Train Accuracy:  0.680, Validation Accuracy:  0.688, Loss:  0.692
Epoch   0 Batch  986/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.688, Loss:  0.702
Epoch   0 Batch  987/1077 - Train Accuracy:  0.663, Validation Accuracy:  0.690, Loss:  0.660
Epoch   0 Batch  988/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.690, Loss:  0.718
Epoch   0 Batch  989/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.688, Loss:  0.698
Epoch   0 Batch  990/1077 - Train Accuracy:  0.653, Validation Accuracy:  0.685, Loss:  0.759
Epoch   0 Batch  991/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.684, Loss:  0.710
Epoch   0 Batch  992/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.681, Loss:  0.686
Epoch   0 Batch  993/1077 - Train Accuracy:  0.674, Validation Accuracy:  0.688, Loss:  0.660
Epoch   0 Batch  994/1077 - Train Accuracy:  0.677, Validation Accuracy:  0.687, Loss:  0.694
Epoch   0 Batch  995/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.690, Loss:  0.668
Epoch   0 Batch  996/1077 - Train Accuracy:  0.664, Validation Accuracy:  0.684, Loss:  0.680
Epoch   0 Batch  997/1077 - Train Accuracy:  0.662, Validation Accuracy:  0.683, Loss:  0.728
Epoch   0 Batch  998/1077 - Train Accuracy:  0.633, Validation Accuracy:  0.688, Loss:  0.678
Epoch   0 Batch  999/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.687, Loss:  0.691
Epoch   0 Batch 1000/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.686, Loss:  0.654
Epoch   0 Batch 1001/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.684, Loss:  0.621
Epoch   0 Batch 1002/1077 - Train Accuracy:  0.696, Validation Accuracy:  0.682, Loss:  0.668
Epoch   0 Batch 1003/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.680, Loss:  0.671
Epoch   0 Batch 1004/1077 - Train Accuracy:  0.710, Validation Accuracy:  0.669, Loss:  0.664
Epoch   0 Batch 1005/1077 - Train Accuracy:  0.687, Validation Accuracy:  0.670, Loss:  0.681
Epoch   0 Batch 1006/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.690, Loss:  0.626
Epoch   0 Batch 1007/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.698, Loss:  0.615
Epoch   0 Batch 1008/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.695, Loss:  0.701
Epoch   0 Batch 1009/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.691, Loss:  0.642
Epoch   0 Batch 1010/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.689, Loss:  0.706
Epoch   0 Batch 1011/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.684, Loss:  0.688
Epoch   0 Batch 1012/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.684, Loss:  0.668
Epoch   0 Batch 1013/1077 - Train Accuracy:  0.707, Validation Accuracy:  0.683, Loss:  0.611
Epoch   0 Batch 1014/1077 - Train Accuracy:  0.664, Validation Accuracy:  0.677, Loss:  0.701
Epoch   0 Batch 1015/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.687, Loss:  0.722
Epoch   0 Batch 1016/1077 - Train Accuracy:  0.649, Validation Accuracy:  0.685, Loss:  0.699
Epoch   0 Batch 1017/1077 - Train Accuracy:  0.669, Validation Accuracy:  0.674, Loss:  0.681
Epoch   0 Batch 1018/1077 - Train Accuracy:  0.675, Validation Accuracy:  0.681, Loss:  0.634
Epoch   0 Batch 1019/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.679, Loss:  0.701
Epoch   0 Batch 1020/1077 - Train Accuracy:  0.712, Validation Accuracy:  0.680, Loss:  0.625
Epoch   0 Batch 1021/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.689, Loss:  0.631
Epoch   0 Batch 1022/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.691, Loss:  0.613
Epoch   0 Batch 1023/1077 - Train Accuracy:  0.707, Validation Accuracy:  0.693, Loss:  0.639
Epoch   0 Batch 1024/1077 - Train Accuracy:  0.661, Validation Accuracy:  0.693, Loss:  0.694
Epoch   0 Batch 1025/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.696, Loss:  0.645
Epoch   0 Batch 1026/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.694, Loss:  0.596
Epoch   0 Batch 1027/1077 - Train Accuracy:  0.670, Validation Accuracy:  0.700, Loss:  0.693
Epoch   0 Batch 1028/1077 - Train Accuracy:  0.671, Validation Accuracy:  0.699, Loss:  0.669
Epoch   0 Batch 1029/1077 - Train Accuracy:  0.690, Validation Accuracy:  0.702, Loss:  0.649
Epoch   0 Batch 1030/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.703, Loss:  0.668
Epoch   0 Batch 1031/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.701, Loss:  0.691
Epoch   0 Batch 1032/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.698, Loss:  0.668
Epoch   0 Batch 1033/1077 - Train Accuracy:  0.672, Validation Accuracy:  0.698, Loss:  0.650
Epoch   0 Batch 1034/1077 - Train Accuracy:  0.653, Validation Accuracy:  0.702, Loss:  0.711
Epoch   0 Batch 1035/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.698, Loss:  0.586
Epoch   0 Batch 1036/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.694, Loss:  0.678
Epoch   0 Batch 1037/1077 - Train Accuracy:  0.665, Validation Accuracy:  0.695, Loss:  0.692
Epoch   0 Batch 1038/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.691, Loss:  0.649
Epoch   0 Batch 1039/1077 - Train Accuracy:  0.710, Validation Accuracy:  0.688, Loss:  0.642
Epoch   0 Batch 1040/1077 - Train Accuracy:  0.687, Validation Accuracy:  0.709, Loss:  0.674
Epoch   0 Batch 1041/1077 - Train Accuracy:  0.685, Validation Accuracy:  0.717, Loss:  0.676
Epoch   0 Batch 1042/1077 - Train Accuracy:  0.692, Validation Accuracy:  0.708, Loss:  0.662
Epoch   0 Batch 1043/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.711, Loss:  0.707
Epoch   0 Batch 1044/1077 - Train Accuracy:  0.673, Validation Accuracy:  0.698, Loss:  0.670
Epoch   0 Batch 1045/1077 - Train Accuracy:  0.654, Validation Accuracy:  0.689, Loss:  0.668
Epoch   0 Batch 1046/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.692, Loss:  0.587
Epoch   0 Batch 1047/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.690, Loss:  0.632
Epoch   0 Batch 1048/1077 - Train Accuracy:  0.681, Validation Accuracy:  0.690, Loss:  0.645
Epoch   0 Batch 1049/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.699, Loss:  0.666
Epoch   0 Batch 1050/1077 - Train Accuracy:  0.662, Validation Accuracy:  0.700, Loss:  0.675
Epoch   0 Batch 1051/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.700, Loss:  0.610
Epoch   0 Batch 1052/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.699, Loss:  0.616
Epoch   0 Batch 1053/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.701, Loss:  0.624
Epoch   0 Batch 1054/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.703, Loss:  0.666
Epoch   0 Batch 1055/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.682, Loss:  0.693
Epoch   0 Batch 1056/1077 - Train Accuracy:  0.681, Validation Accuracy:  0.673, Loss:  0.666
Epoch   0 Batch 1057/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.689, Loss:  0.706
Epoch   0 Batch 1058/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.685, Loss:  0.694
Epoch   0 Batch 1059/1077 - Train Accuracy:  0.639, Validation Accuracy:  0.675, Loss:  0.720
Epoch   0 Batch 1060/1077 - Train Accuracy:  0.684, Validation Accuracy:  0.692, Loss:  0.673
Epoch   0 Batch 1061/1077 - Train Accuracy:  0.658, Validation Accuracy:  0.695, Loss:  0.714
Epoch   0 Batch 1062/1077 - Train Accuracy:  0.632, Validation Accuracy:  0.688, Loss:  0.693
Epoch   0 Batch 1063/1077 - Train Accuracy:  0.675, Validation Accuracy:  0.682, Loss:  0.650
Epoch   0 Batch 1064/1077 - Train Accuracy:  0.710, Validation Accuracy:  0.685, Loss:  0.659
Epoch   0 Batch 1065/1077 - Train Accuracy:  0.699, Validation Accuracy:  0.698, Loss:  0.649
Epoch   0 Batch 1066/1077 - Train Accuracy:  0.671, Validation Accuracy:  0.704, Loss:  0.656
Epoch   0 Batch 1067/1077 - Train Accuracy:  0.715, Validation Accuracy:  0.692, Loss:  0.647
Epoch   0 Batch 1068/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.689, Loss:  0.629
Epoch   0 Batch 1069/1077 - Train Accuracy:  0.710, Validation Accuracy:  0.687, Loss:  0.626
Epoch   0 Batch 1070/1077 - Train Accuracy:  0.657, Validation Accuracy:  0.699, Loss:  0.697
Epoch   0 Batch 1071/1077 - Train Accuracy:  0.668, Validation Accuracy:  0.697, Loss:  0.613
Epoch   0 Batch 1072/1077 - Train Accuracy:  0.667, Validation Accuracy:  0.694, Loss:  0.635
Epoch   0 Batch 1073/1077 - Train Accuracy:  0.682, Validation Accuracy:  0.704, Loss:  0.661
Epoch   0 Batch 1074/1077 - Train Accuracy:  0.708, Validation Accuracy:  0.699, Loss:  0.656
Epoch   0 Batch 1075/1077 - Train Accuracy:  0.685, Validation Accuracy:  0.691, Loss:  0.697
Epoch   1 Batch    0/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.699, Loss:  0.594
Epoch   1 Batch    1/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.703, Loss:  0.644
Epoch   1 Batch    2/1077 - Train Accuracy:  0.643, Validation Accuracy:  0.699, Loss:  0.673
Epoch   1 Batch    3/1077 - Train Accuracy:  0.703, Validation Accuracy:  0.693, Loss:  0.620
Epoch   1 Batch    4/1077 - Train Accuracy:  0.689, Validation Accuracy:  0.685, Loss:  0.643
Epoch   1 Batch    5/1077 - Train Accuracy:  0.687, Validation Accuracy:  0.684, Loss:  0.710
Epoch   1 Batch    6/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.683, Loss:  0.642
Epoch   1 Batch    7/1077 - Train Accuracy:  0.680, Validation Accuracy:  0.687, Loss:  0.638
Epoch   1 Batch    8/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.697, Loss:  0.633
Epoch   1 Batch    9/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.688, Loss:  0.627
Epoch   1 Batch   10/1077 - Train Accuracy:  0.680, Validation Accuracy:  0.695, Loss:  0.659
Epoch   1 Batch   11/1077 - Train Accuracy:  0.652, Validation Accuracy:  0.699, Loss:  0.640
Epoch   1 Batch   12/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.699, Loss:  0.663
Epoch   1 Batch   13/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.694, Loss:  0.638
Epoch   1 Batch   14/1077 - Train Accuracy:  0.733, Validation Accuracy:  0.699, Loss:  0.585
Epoch   1 Batch   15/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.699, Loss:  0.603
Epoch   1 Batch   16/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.706, Loss:  0.624
Epoch   1 Batch   17/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.699, Loss:  0.612
Epoch   1 Batch   18/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.706, Loss:  0.615
Epoch   1 Batch   19/1077 - Train Accuracy:  0.687, Validation Accuracy:  0.704, Loss:  0.632
Epoch   1 Batch   20/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.699, Loss:  0.608
Epoch   1 Batch   21/1077 - Train Accuracy:  0.648, Validation Accuracy:  0.691, Loss:  0.678
Epoch   1 Batch   22/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.688, Loss:  0.629
Epoch   1 Batch   23/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.695, Loss:  0.616
Epoch   1 Batch   24/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.705, Loss:  0.615
Epoch   1 Batch   25/1077 - Train Accuracy:  0.697, Validation Accuracy:  0.714, Loss:  0.588
Epoch   1 Batch   26/1077 - Train Accuracy:  0.678, Validation Accuracy:  0.708, Loss:  0.642
Epoch   1 Batch   27/1077 - Train Accuracy:  0.701, Validation Accuracy:  0.705, Loss:  0.558
Epoch   1 Batch   28/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.710, Loss:  0.598
Epoch   1 Batch   29/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.706, Loss:  0.632
Epoch   1 Batch   30/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.721, Loss:  0.617
Epoch   1 Batch   31/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.716, Loss:  0.593
Epoch   1 Batch   32/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.714, Loss:  0.589
Epoch   1 Batch   33/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.712, Loss:  0.610
Epoch   1 Batch   34/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.707, Loss:  0.584
Epoch   1 Batch   35/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.711, Loss:  0.612
Epoch   1 Batch   36/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.712, Loss:  0.627
Epoch   1 Batch   37/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.706, Loss:  0.622
Epoch   1 Batch   38/1077 - Train Accuracy:  0.654, Validation Accuracy:  0.704, Loss:  0.674
Epoch   1 Batch   39/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.703, Loss:  0.629
Epoch   1 Batch   40/1077 - Train Accuracy:  0.701, Validation Accuracy:  0.700, Loss:  0.612
Epoch   1 Batch   41/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.702, Loss:  0.612
Epoch   1 Batch   42/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.700, Loss:  0.634
Epoch   1 Batch   43/1077 - Train Accuracy:  0.724, Validation Accuracy:  0.699, Loss:  0.604
Epoch   1 Batch   44/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.703, Loss:  0.611
Epoch   1 Batch   45/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.713, Loss:  0.612
Epoch   1 Batch   46/1077 - Train Accuracy:  0.697, Validation Accuracy:  0.713, Loss:  0.659
Epoch   1 Batch   47/1077 - Train Accuracy:  0.731, Validation Accuracy:  0.718, Loss:  0.597
Epoch   1 Batch   48/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.721, Loss:  0.633
Epoch   1 Batch   49/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.724, Loss:  0.606
Epoch   1 Batch   50/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.719, Loss:  0.598
Epoch   1 Batch   51/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.717, Loss:  0.600
Epoch   1 Batch   52/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.714, Loss:  0.608
Epoch   1 Batch   53/1077 - Train Accuracy:  0.707, Validation Accuracy:  0.711, Loss:  0.614
Epoch   1 Batch   54/1077 - Train Accuracy:  0.668, Validation Accuracy:  0.707, Loss:  0.675
Epoch   1 Batch   55/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.694, Loss:  0.572
Epoch   1 Batch   56/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.692, Loss:  0.577
Epoch   1 Batch   57/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.694, Loss:  0.563
Epoch   1 Batch   58/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.705, Loss:  0.578
Epoch   1 Batch   59/1077 - Train Accuracy:  0.701, Validation Accuracy:  0.706, Loss:  0.634
Epoch   1 Batch   60/1077 - Train Accuracy:  0.708, Validation Accuracy:  0.705, Loss:  0.570
Epoch   1 Batch   61/1077 - Train Accuracy:  0.677, Validation Accuracy:  0.706, Loss:  0.634
Epoch   1 Batch   62/1077 - Train Accuracy:  0.681, Validation Accuracy:  0.704, Loss:  0.620
Epoch   1 Batch   63/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.710, Loss:  0.552
Epoch   1 Batch   64/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.722, Loss:  0.607
Epoch   1 Batch   65/1077 - Train Accuracy:  0.692, Validation Accuracy:  0.720, Loss:  0.615
Epoch   1 Batch   66/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.723, Loss:  0.574
Epoch   1 Batch   67/1077 - Train Accuracy:  0.734, Validation Accuracy:  0.734, Loss:  0.557
Epoch   1 Batch   68/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.731, Loss:  0.603
Epoch   1 Batch   69/1077 - Train Accuracy:  0.699, Validation Accuracy:  0.727, Loss:  0.607
Epoch   1 Batch   70/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.742, Loss:  0.627
Epoch   1 Batch   71/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.739, Loss:  0.563
Epoch   1 Batch   72/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.738, Loss:  0.606
Epoch   1 Batch   73/1077 - Train Accuracy:  0.693, Validation Accuracy:  0.732, Loss:  0.622
Epoch   1 Batch   74/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.725, Loss:  0.549
Epoch   1 Batch   75/1077 - Train Accuracy:  0.726, Validation Accuracy:  0.735, Loss:  0.594
Epoch   1 Batch   76/1077 - Train Accuracy:  0.718, Validation Accuracy:  0.732, Loss:  0.530
Epoch   1 Batch   77/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.730, Loss:  0.597
Epoch   1 Batch   78/1077 - Train Accuracy:  0.683, Validation Accuracy:  0.721, Loss:  0.614
Epoch   1 Batch   79/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.732, Loss:  0.593
Epoch   1 Batch   80/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.726, Loss:  0.602
Epoch   1 Batch   81/1077 - Train Accuracy:  0.706, Validation Accuracy:  0.722, Loss:  0.586
Epoch   1 Batch   82/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.730, Loss:  0.520
Epoch   1 Batch   83/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.719, Loss:  0.623
Epoch   1 Batch   84/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.725, Loss:  0.595
Epoch   1 Batch   85/1077 - Train Accuracy:  0.707, Validation Accuracy:  0.735, Loss:  0.584
Epoch   1 Batch   86/1077 - Train Accuracy:  0.712, Validation Accuracy:  0.729, Loss:  0.574
Epoch   1 Batch   87/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.732, Loss:  0.634
Epoch   1 Batch   88/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.722, Loss:  0.609
Epoch   1 Batch   89/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.724, Loss:  0.618
Epoch   1 Batch   90/1077 - Train Accuracy:  0.706, Validation Accuracy:  0.728, Loss:  0.633
Epoch   1 Batch   91/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.725, Loss:  0.520
Epoch   1 Batch   92/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.728, Loss:  0.599
Epoch   1 Batch   93/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.719, Loss:  0.616
Epoch   1 Batch   94/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.719, Loss:  0.550
Epoch   1 Batch   95/1077 - Train Accuracy:  0.708, Validation Accuracy:  0.719, Loss:  0.611
Epoch   1 Batch   96/1077 - Train Accuracy:  0.696, Validation Accuracy:  0.714, Loss:  0.602
Epoch   1 Batch   97/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.708, Loss:  0.588
Epoch   1 Batch   98/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.715, Loss:  0.588
Epoch   1 Batch   99/1077 - Train Accuracy:  0.707, Validation Accuracy:  0.718, Loss:  0.618
Epoch   1 Batch  100/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.714, Loss:  0.601
Epoch   1 Batch  101/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.721, Loss:  0.587
Epoch   1 Batch  102/1077 - Train Accuracy:  0.713, Validation Accuracy:  0.721, Loss:  0.560
Epoch   1 Batch  103/1077 - Train Accuracy:  0.672, Validation Accuracy:  0.722, Loss:  0.637
Epoch   1 Batch  104/1077 - Train Accuracy:  0.692, Validation Accuracy:  0.732, Loss:  0.606
Epoch   1 Batch  105/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.738, Loss:  0.564
Epoch   1 Batch  106/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.742, Loss:  0.663
Epoch   1 Batch  107/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.744, Loss:  0.562
Epoch   1 Batch  108/1077 - Train Accuracy:  0.749, Validation Accuracy:  0.752, Loss:  0.510
Epoch   1 Batch  109/1077 - Train Accuracy:  0.706, Validation Accuracy:  0.744, Loss:  0.588
Epoch   1 Batch  110/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.735, Loss:  0.541
Epoch   1 Batch  111/1077 - Train Accuracy:  0.701, Validation Accuracy:  0.737, Loss:  0.576
Epoch   1 Batch  112/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.728, Loss:  0.577
Epoch   1 Batch  113/1077 - Train Accuracy:  0.684, Validation Accuracy:  0.731, Loss:  0.609
Epoch   1 Batch  114/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.734, Loss:  0.532
Epoch   1 Batch  115/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.734, Loss:  0.600
Epoch   1 Batch  116/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.737, Loss:  0.621
Epoch   1 Batch  117/1077 - Train Accuracy:  0.674, Validation Accuracy:  0.743, Loss:  0.601
Epoch   1 Batch  118/1077 - Train Accuracy:  0.689, Validation Accuracy:  0.726, Loss:  0.627
Epoch   1 Batch  119/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.721, Loss:  0.558
Epoch   1 Batch  120/1077 - Train Accuracy:  0.724, Validation Accuracy:  0.723, Loss:  0.582
Epoch   1 Batch  121/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.729, Loss:  0.573
Epoch   1 Batch  122/1077 - Train Accuracy:  0.717, Validation Accuracy:  0.721, Loss:  0.589
Epoch   1 Batch  123/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.727, Loss:  0.544
Epoch   1 Batch  124/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.726, Loss:  0.620
Epoch   1 Batch  125/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.727, Loss:  0.584
Epoch   1 Batch  126/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.728, Loss:  0.544
Epoch   1 Batch  127/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.731, Loss:  0.572
Epoch   1 Batch  128/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.729, Loss:  0.534
Epoch   1 Batch  129/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.723, Loss:  0.557
Epoch   1 Batch  130/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.738, Loss:  0.552
Epoch   1 Batch  131/1077 - Train Accuracy:  0.686, Validation Accuracy:  0.741, Loss:  0.587
Epoch   1 Batch  132/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.744, Loss:  0.576
Epoch   1 Batch  133/1077 - Train Accuracy:  0.693, Validation Accuracy:  0.723, Loss:  0.581
Epoch   1 Batch  134/1077 - Train Accuracy:  0.735, Validation Accuracy:  0.712, Loss:  0.533
Epoch   1 Batch  135/1077 - Train Accuracy:  0.712, Validation Accuracy:  0.728, Loss:  0.602
Epoch   1 Batch  136/1077 - Train Accuracy:  0.726, Validation Accuracy:  0.725, Loss:  0.556
Epoch   1 Batch  137/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.735, Loss:  0.550
Epoch   1 Batch  138/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.737, Loss:  0.550
Epoch   1 Batch  139/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.728, Loss:  0.576
Epoch   1 Batch  140/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.738, Loss:  0.587
Epoch   1 Batch  141/1077 - Train Accuracy:  0.694, Validation Accuracy:  0.737, Loss:  0.591
Epoch   1 Batch  142/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.734, Loss:  0.538
Epoch   1 Batch  143/1077 - Train Accuracy:  0.696, Validation Accuracy:  0.729, Loss:  0.586
Epoch   1 Batch  144/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.733, Loss:  0.640
Epoch   1 Batch  145/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.748, Loss:  0.579
Epoch   1 Batch  146/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.734, Loss:  0.600
Epoch   1 Batch  147/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.744, Loss:  0.603
Epoch   1 Batch  148/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.740, Loss:  0.572
Epoch   1 Batch  149/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.731, Loss:  0.579
Epoch   1 Batch  150/1077 - Train Accuracy:  0.731, Validation Accuracy:  0.735, Loss:  0.564
Epoch   1 Batch  151/1077 - Train Accuracy:  0.733, Validation Accuracy:  0.755, Loss:  0.548
Epoch   1 Batch  152/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.755, Loss:  0.550
Epoch   1 Batch  153/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.732, Loss:  0.595
Epoch   1 Batch  154/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.752, Loss:  0.605
Epoch   1 Batch  155/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.739, Loss:  0.604
Epoch   1 Batch  156/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.711, Loss:  0.558
Epoch   1 Batch  157/1077 - Train Accuracy:  0.703, Validation Accuracy:  0.722, Loss:  0.572
Epoch   1 Batch  158/1077 - Train Accuracy:  0.721, Validation Accuracy:  0.728, Loss:  0.579
Epoch   1 Batch  159/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.740, Loss:  0.526
Epoch   1 Batch  160/1077 - Train Accuracy:  0.734, Validation Accuracy:  0.739, Loss:  0.566
Epoch   1 Batch  161/1077 - Train Accuracy:  0.734, Validation Accuracy:  0.744, Loss:  0.592
Epoch   1 Batch  162/1077 - Train Accuracy:  0.701, Validation Accuracy:  0.728, Loss:  0.625
Epoch   1 Batch  163/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.726, Loss:  0.613
Epoch   1 Batch  164/1077 - Train Accuracy:  0.720, Validation Accuracy:  0.727, Loss:  0.596
Epoch   1 Batch  165/1077 - Train Accuracy:  0.697, Validation Accuracy:  0.723, Loss:  0.566
Epoch   1 Batch  166/1077 - Train Accuracy:  0.708, Validation Accuracy:  0.722, Loss:  0.567
Epoch   1 Batch  167/1077 - Train Accuracy:  0.692, Validation Accuracy:  0.733, Loss:  0.586
Epoch   1 Batch  168/1077 - Train Accuracy:  0.699, Validation Accuracy:  0.737, Loss:  0.588
Epoch   1 Batch  169/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.743, Loss:  0.569
Epoch   1 Batch  170/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.748, Loss:  0.591
Epoch   1 Batch  171/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.745, Loss:  0.554
Epoch   1 Batch  172/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.752, Loss:  0.525
Epoch   1 Batch  173/1077 - Train Accuracy:  0.720, Validation Accuracy:  0.745, Loss:  0.559
Epoch   1 Batch  174/1077 - Train Accuracy:  0.730, Validation Accuracy:  0.741, Loss:  0.548
Epoch   1 Batch  175/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.739, Loss:  0.569
Epoch   1 Batch  176/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.745, Loss:  0.556
Epoch   1 Batch  177/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.744, Loss:  0.595
Epoch   1 Batch  178/1077 - Train Accuracy:  0.706, Validation Accuracy:  0.731, Loss:  0.566
Epoch   1 Batch  179/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.740, Loss:  0.561
Epoch   1 Batch  180/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.729, Loss:  0.576
Epoch   1 Batch  181/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.732, Loss:  0.585
Epoch   1 Batch  182/1077 - Train Accuracy:  0.696, Validation Accuracy:  0.734, Loss:  0.552
Epoch   1 Batch  183/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.735, Loss:  0.562
Epoch   1 Batch  184/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.748, Loss:  0.544
Epoch   1 Batch  185/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.745, Loss:  0.574
Epoch   1 Batch  186/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.736, Loss:  0.569
Epoch   1 Batch  187/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.740, Loss:  0.529
Epoch   1 Batch  188/1077 - Train Accuracy:  0.707, Validation Accuracy:  0.738, Loss:  0.543
Epoch   1 Batch  189/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.743, Loss:  0.567
Epoch   1 Batch  190/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.735, Loss:  0.559
Epoch   1 Batch  191/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.733, Loss:  0.519
Epoch   1 Batch  192/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.738, Loss:  0.554
Epoch   1 Batch  193/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.746, Loss:  0.517
Epoch   1 Batch  194/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.754, Loss:  0.507
Epoch   1 Batch  195/1077 - Train Accuracy:  0.731, Validation Accuracy:  0.739, Loss:  0.524
Epoch   1 Batch  196/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.739, Loss:  0.547
Epoch   1 Batch  197/1077 - Train Accuracy:  0.698, Validation Accuracy:  0.737, Loss:  0.536
Epoch   1 Batch  198/1077 - Train Accuracy:  0.763, Validation Accuracy:  0.736, Loss:  0.498
Epoch   1 Batch  199/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.742, Loss:  0.531
Epoch   1 Batch  200/1077 - Train Accuracy:  0.695, Validation Accuracy:  0.744, Loss:  0.546
Epoch   1 Batch  201/1077 - Train Accuracy:  0.734, Validation Accuracy:  0.751, Loss:  0.510
Epoch   1 Batch  202/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.749, Loss:  0.541
Epoch   1 Batch  203/1077 - Train Accuracy:  0.708, Validation Accuracy:  0.750, Loss:  0.544
Epoch   1 Batch  204/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.752, Loss:  0.575
Epoch   1 Batch  205/1077 - Train Accuracy:  0.733, Validation Accuracy:  0.748, Loss:  0.549
Epoch   1 Batch  206/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.743, Loss:  0.540
Epoch   1 Batch  207/1077 - Train Accuracy:  0.737, Validation Accuracy:  0.741, Loss:  0.532
Epoch   1 Batch  208/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.752, Loss:  0.514
Epoch   1 Batch  209/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.755, Loss:  0.491
Epoch   1 Batch  210/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.757, Loss:  0.540
Epoch   1 Batch  211/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.747, Loss:  0.535
Epoch   1 Batch  212/1077 - Train Accuracy:  0.706, Validation Accuracy:  0.740, Loss:  0.511
Epoch   1 Batch  213/1077 - Train Accuracy:  0.718, Validation Accuracy:  0.734, Loss:  0.508
Epoch   1 Batch  214/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.732, Loss:  0.533
Epoch   1 Batch  215/1077 - Train Accuracy:  0.702, Validation Accuracy:  0.734, Loss:  0.548
Epoch   1 Batch  216/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.733, Loss:  0.534
Epoch   1 Batch  217/1077 - Train Accuracy:  0.751, Validation Accuracy:  0.733, Loss:  0.515
Epoch   1 Batch  218/1077 - Train Accuracy:  0.713, Validation Accuracy:  0.723, Loss:  0.578
Epoch   1 Batch  219/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.730, Loss:  0.530
Epoch   1 Batch  220/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.734, Loss:  0.549
Epoch   1 Batch  221/1077 - Train Accuracy:  0.767, Validation Accuracy:  0.741, Loss:  0.551
Epoch   1 Batch  222/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.731, Loss:  0.583
Epoch   1 Batch  223/1077 - Train Accuracy:  0.739, Validation Accuracy:  0.740, Loss:  0.502
Epoch   1 Batch  224/1077 - Train Accuracy:  0.721, Validation Accuracy:  0.739, Loss:  0.545
Epoch   1 Batch  225/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.741, Loss:  0.546
Epoch   1 Batch  226/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.742, Loss:  0.534
Epoch   1 Batch  227/1077 - Train Accuracy:  0.691, Validation Accuracy:  0.746, Loss:  0.578
Epoch   1 Batch  228/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.743, Loss:  0.535
Epoch   1 Batch  229/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.750, Loss:  0.557
Epoch   1 Batch  230/1077 - Train Accuracy:  0.713, Validation Accuracy:  0.754, Loss:  0.542
Epoch   1 Batch  231/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.754, Loss:  0.548
Epoch   1 Batch  232/1077 - Train Accuracy:  0.747, Validation Accuracy:  0.757, Loss:  0.552
Epoch   1 Batch  233/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.768, Loss:  0.563
Epoch   1 Batch  234/1077 - Train Accuracy:  0.737, Validation Accuracy:  0.765, Loss:  0.543
Epoch   1 Batch  235/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.761, Loss:  0.495
Epoch   1 Batch  236/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.756, Loss:  0.546
Epoch   1 Batch  237/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.760, Loss:  0.507
Epoch   1 Batch  238/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.755, Loss:  0.524
Epoch   1 Batch  239/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.754, Loss:  0.504
Epoch   1 Batch  240/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.750, Loss:  0.526
Epoch   1 Batch  241/1077 - Train Accuracy:  0.755, Validation Accuracy:  0.748, Loss:  0.504
Epoch   1 Batch  242/1077 - Train Accuracy:  0.724, Validation Accuracy:  0.762, Loss:  0.514
Epoch   1 Batch  243/1077 - Train Accuracy:  0.715, Validation Accuracy:  0.760, Loss:  0.551
Epoch   1 Batch  244/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.755, Loss:  0.517
Epoch   1 Batch  245/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.754, Loss:  0.487
Epoch   1 Batch  246/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.744, Loss:  0.530
Epoch   1 Batch  247/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.755, Loss:  0.503
Epoch   1 Batch  248/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.756, Loss:  0.512
Epoch   1 Batch  249/1077 - Train Accuracy:  0.730, Validation Accuracy:  0.756, Loss:  0.505
Epoch   1 Batch  250/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.754, Loss:  0.487
Epoch   1 Batch  251/1077 - Train Accuracy:  0.739, Validation Accuracy:  0.763, Loss:  0.520
Epoch   1 Batch  252/1077 - Train Accuracy:  0.760, Validation Accuracy:  0.759, Loss:  0.499
Epoch   1 Batch  253/1077 - Train Accuracy:  0.751, Validation Accuracy:  0.763, Loss:  0.504
Epoch   1 Batch  254/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.754, Loss:  0.521
Epoch   1 Batch  255/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.763, Loss:  0.512
Epoch   1 Batch  256/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.748, Loss:  0.546
Epoch   1 Batch  257/1077 - Train Accuracy:  0.727, Validation Accuracy:  0.754, Loss:  0.495
Epoch   1 Batch  258/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.749, Loss:  0.497
Epoch   1 Batch  259/1077 - Train Accuracy:  0.717, Validation Accuracy:  0.757, Loss:  0.493
Epoch   1 Batch  260/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.755, Loss:  0.497
Epoch   1 Batch  261/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.761, Loss:  0.474
Epoch   1 Batch  262/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.755, Loss:  0.507
Epoch   1 Batch  263/1077 - Train Accuracy:  0.758, Validation Accuracy:  0.766, Loss:  0.493
Epoch   1 Batch  264/1077 - Train Accuracy:  0.749, Validation Accuracy:  0.773, Loss:  0.512
Epoch   1 Batch  265/1077 - Train Accuracy:  0.715, Validation Accuracy:  0.771, Loss:  0.528
Epoch   1 Batch  266/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.769, Loss:  0.509
Epoch   1 Batch  267/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.762, Loss:  0.470
Epoch   1 Batch  268/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.750, Loss:  0.536
Epoch   1 Batch  269/1077 - Train Accuracy:  0.710, Validation Accuracy:  0.743, Loss:  0.562
Epoch   1 Batch  270/1077 - Train Accuracy:  0.693, Validation Accuracy:  0.739, Loss:  0.548
Epoch   1 Batch  271/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.743, Loss:  0.504
Epoch   1 Batch  272/1077 - Train Accuracy:  0.749, Validation Accuracy:  0.742, Loss:  0.553
Epoch   1 Batch  273/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.745, Loss:  0.521
Epoch   1 Batch  274/1077 - Train Accuracy:  0.763, Validation Accuracy:  0.738, Loss:  0.513
Epoch   1 Batch  275/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.748, Loss:  0.503
Epoch   1 Batch  276/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.756, Loss:  0.559
Epoch   1 Batch  277/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.748, Loss:  0.486
Epoch   1 Batch  278/1077 - Train Accuracy:  0.690, Validation Accuracy:  0.728, Loss:  0.564
Epoch   1 Batch  279/1077 - Train Accuracy:  0.720, Validation Accuracy:  0.731, Loss:  0.580
Epoch   1 Batch  280/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.728, Loss:  0.538
Epoch   1 Batch  281/1077 - Train Accuracy:  0.688, Validation Accuracy:  0.728, Loss:  0.530
Epoch   1 Batch  282/1077 - Train Accuracy:  0.711, Validation Accuracy:  0.752, Loss:  0.566
Epoch   1 Batch  283/1077 - Train Accuracy:  0.755, Validation Accuracy:  0.753, Loss:  0.524
Epoch   1 Batch  284/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.756, Loss:  0.536
Epoch   1 Batch  285/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.755, Loss:  0.510
Epoch   1 Batch  286/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.751, Loss:  0.488
Epoch   1 Batch  287/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.740, Loss:  0.494
Epoch   1 Batch  288/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.749, Loss:  0.518
Epoch   1 Batch  289/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.748, Loss:  0.512
Epoch   1 Batch  290/1077 - Train Accuracy:  0.705, Validation Accuracy:  0.755, Loss:  0.546
Epoch   1 Batch  291/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.758, Loss:  0.553
Epoch   1 Batch  292/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.775, Loss:  0.506
Epoch   1 Batch  293/1077 - Train Accuracy:  0.679, Validation Accuracy:  0.777, Loss:  0.548
Epoch   1 Batch  294/1077 - Train Accuracy:  0.735, Validation Accuracy:  0.762, Loss:  0.495
Epoch   1 Batch  295/1077 - Train Accuracy:  0.722, Validation Accuracy:  0.765, Loss:  0.548
Epoch   1 Batch  296/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.784, Loss:  0.465
Epoch   1 Batch  297/1077 - Train Accuracy:  0.714, Validation Accuracy:  0.762, Loss:  0.566
Epoch   1 Batch  298/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.760, Loss:  0.543
Epoch   1 Batch  299/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.757, Loss:  0.494
Epoch   1 Batch  300/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.757, Loss:  0.492
Epoch   1 Batch  301/1077 - Train Accuracy:  0.697, Validation Accuracy:  0.764, Loss:  0.507
Epoch   1 Batch  302/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.765, Loss:  0.505
Epoch   1 Batch  303/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.756, Loss:  0.517
Epoch   1 Batch  304/1077 - Train Accuracy:  0.730, Validation Accuracy:  0.745, Loss:  0.477
Epoch   1 Batch  305/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.752, Loss:  0.502
Epoch   1 Batch  306/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.755, Loss:  0.491
Epoch   1 Batch  307/1077 - Train Accuracy:  0.712, Validation Accuracy:  0.749, Loss:  0.510
Epoch   1 Batch  308/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.750, Loss:  0.557
Epoch   1 Batch  309/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.750, Loss:  0.459
Epoch   1 Batch  310/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.754, Loss:  0.517
Epoch   1 Batch  311/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.746, Loss:  0.479
Epoch   1 Batch  312/1077 - Train Accuracy:  0.724, Validation Accuracy:  0.750, Loss:  0.566
Epoch   1 Batch  313/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.752, Loss:  0.497
Epoch   1 Batch  314/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.756, Loss:  0.492
Epoch   1 Batch  315/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.755, Loss:  0.461
Epoch   1 Batch  316/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.758, Loss:  0.489
Epoch   1 Batch  317/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.753, Loss:  0.541
Epoch   1 Batch  318/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.753, Loss:  0.486
Epoch   1 Batch  319/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.744, Loss:  0.514
Epoch   1 Batch  320/1077 - Train Accuracy:  0.760, Validation Accuracy:  0.753, Loss:  0.504
Epoch   1 Batch  321/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.749, Loss:  0.498
Epoch   1 Batch  322/1077 - Train Accuracy:  0.737, Validation Accuracy:  0.753, Loss:  0.477
Epoch   1 Batch  323/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.740, Loss:  0.493
Epoch   1 Batch  324/1077 - Train Accuracy:  0.724, Validation Accuracy:  0.738, Loss:  0.497
Epoch   1 Batch  325/1077 - Train Accuracy:  0.751, Validation Accuracy:  0.754, Loss:  0.481
Epoch   1 Batch  326/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.772, Loss:  0.473
Epoch   1 Batch  327/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.766, Loss:  0.497
Epoch   1 Batch  328/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.767, Loss:  0.498
Epoch   1 Batch  329/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.755, Loss:  0.501
Epoch   1 Batch  330/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.754, Loss:  0.510
Epoch   1 Batch  331/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.757, Loss:  0.523
Epoch   1 Batch  332/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.753, Loss:  0.439
Epoch   1 Batch  333/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.755, Loss:  0.525
Epoch   1 Batch  334/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.758, Loss:  0.508
Epoch   1 Batch  335/1077 - Train Accuracy:  0.781, Validation Accuracy:  0.764, Loss:  0.470
Epoch   1 Batch  336/1077 - Train Accuracy:  0.730, Validation Accuracy:  0.759, Loss:  0.535
Epoch   1 Batch  337/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.757, Loss:  0.493
Epoch   1 Batch  338/1077 - Train Accuracy:  0.713, Validation Accuracy:  0.756, Loss:  0.553
Epoch   1 Batch  339/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.752, Loss:  0.483
Epoch   1 Batch  340/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.752, Loss:  0.488
Epoch   1 Batch  341/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.742, Loss:  0.531
Epoch   1 Batch  342/1077 - Train Accuracy:  0.726, Validation Accuracy:  0.745, Loss:  0.485
Epoch   1 Batch  343/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.752, Loss:  0.478
Epoch   1 Batch  344/1077 - Train Accuracy:  0.733, Validation Accuracy:  0.754, Loss:  0.471
Epoch   1 Batch  345/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.763, Loss:  0.461
Epoch   1 Batch  346/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.755, Loss:  0.527
Epoch   1 Batch  347/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.763, Loss:  0.470
Epoch   1 Batch  348/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.761, Loss:  0.479
Epoch   1 Batch  349/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.757, Loss:  0.474
Epoch   1 Batch  350/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.753, Loss:  0.509
Epoch   1 Batch  351/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.745, Loss:  0.505
Epoch   1 Batch  352/1077 - Train Accuracy:  0.739, Validation Accuracy:  0.751, Loss:  0.501
Epoch   1 Batch  353/1077 - Train Accuracy:  0.704, Validation Accuracy:  0.745, Loss:  0.525
Epoch   1 Batch  354/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.743, Loss:  0.517
Epoch   1 Batch  355/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.736, Loss:  0.496
Epoch   1 Batch  356/1077 - Train Accuracy:  0.730, Validation Accuracy:  0.742, Loss:  0.465
Epoch   1 Batch  357/1077 - Train Accuracy:  0.731, Validation Accuracy:  0.737, Loss:  0.480
Epoch   1 Batch  358/1077 - Train Accuracy:  0.684, Validation Accuracy:  0.738, Loss:  0.524
Epoch   1 Batch  359/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.739, Loss:  0.493
Epoch   1 Batch  360/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.756, Loss:  0.493
Epoch   1 Batch  361/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.756, Loss:  0.504
Epoch   1 Batch  362/1077 - Train Accuracy:  0.763, Validation Accuracy:  0.759, Loss:  0.481
Epoch   1 Batch  363/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.769, Loss:  0.504
Epoch   1 Batch  364/1077 - Train Accuracy:  0.731, Validation Accuracy:  0.755, Loss:  0.498
Epoch   1 Batch  365/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.756, Loss:  0.471
Epoch   1 Batch  366/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.757, Loss:  0.485
Epoch   1 Batch  367/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.759, Loss:  0.429
Epoch   1 Batch  368/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.757, Loss:  0.494
Epoch   1 Batch  369/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.766, Loss:  0.493
Epoch   1 Batch  370/1077 - Train Accuracy:  0.781, Validation Accuracy:  0.779, Loss:  0.464
Epoch   1 Batch  371/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.775, Loss:  0.461
Epoch   1 Batch  372/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.772, Loss:  0.461
Epoch   1 Batch  373/1077 - Train Accuracy:  0.782, Validation Accuracy:  0.775, Loss:  0.441
Epoch   1 Batch  374/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.763, Loss:  0.501
Epoch   1 Batch  375/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.768, Loss:  0.455
Epoch   1 Batch  376/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.776, Loss:  0.466
Epoch   1 Batch  377/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.778, Loss:  0.455
Epoch   1 Batch  378/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.768, Loss:  0.444
Epoch   1 Batch  379/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.777, Loss:  0.495
Epoch   1 Batch  380/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.779, Loss:  0.463
Epoch   1 Batch  381/1077 - Train Accuracy:  0.720, Validation Accuracy:  0.782, Loss:  0.506
Epoch   1 Batch  382/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.793, Loss:  0.509
Epoch   1 Batch  383/1077 - Train Accuracy:  0.749, Validation Accuracy:  0.791, Loss:  0.464
Epoch   1 Batch  384/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.784, Loss:  0.462
Epoch   1 Batch  385/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.778, Loss:  0.499
Epoch   1 Batch  386/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.772, Loss:  0.467
Epoch   1 Batch  387/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.772, Loss:  0.458
Epoch   1 Batch  388/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.777, Loss:  0.497
Epoch   1 Batch  389/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.774, Loss:  0.474
Epoch   1 Batch  390/1077 - Train Accuracy:  0.715, Validation Accuracy:  0.767, Loss:  0.487
Epoch   1 Batch  391/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.766, Loss:  0.465
Epoch   1 Batch  392/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.768, Loss:  0.467
Epoch   1 Batch  393/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.771, Loss:  0.449
Epoch   1 Batch  394/1077 - Train Accuracy:  0.739, Validation Accuracy:  0.766, Loss:  0.483
Epoch   1 Batch  395/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.769, Loss:  0.479
Epoch   1 Batch  396/1077 - Train Accuracy:  0.731, Validation Accuracy:  0.766, Loss:  0.499
Epoch   1 Batch  397/1077 - Train Accuracy:  0.751, Validation Accuracy:  0.773, Loss:  0.468
Epoch   1 Batch  398/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.775, Loss:  0.528
Epoch   1 Batch  399/1077 - Train Accuracy:  0.700, Validation Accuracy:  0.774, Loss:  0.514
Epoch   1 Batch  400/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.768, Loss:  0.506
Epoch   1 Batch  401/1077 - Train Accuracy:  0.737, Validation Accuracy:  0.765, Loss:  0.486
Epoch   1 Batch  402/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.754, Loss:  0.444
Epoch   1 Batch  403/1077 - Train Accuracy:  0.725, Validation Accuracy:  0.756, Loss:  0.490
Epoch   1 Batch  404/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.765, Loss:  0.445
Epoch   1 Batch  405/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.772, Loss:  0.497
Epoch   1 Batch  406/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.775, Loss:  0.469
Epoch   1 Batch  407/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.773, Loss:  0.517
Epoch   1 Batch  408/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.766, Loss:  0.505
Epoch   1 Batch  409/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.749, Loss:  0.487
Epoch   1 Batch  410/1077 - Train Accuracy:  0.734, Validation Accuracy:  0.756, Loss:  0.504
Epoch   1 Batch  411/1077 - Train Accuracy:  0.758, Validation Accuracy:  0.767, Loss:  0.481
Epoch   1 Batch  412/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.761, Loss:  0.442
Epoch   1 Batch  413/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.757, Loss:  0.469
Epoch   1 Batch  414/1077 - Train Accuracy:  0.721, Validation Accuracy:  0.756, Loss:  0.505
Epoch   1 Batch  415/1077 - Train Accuracy:  0.760, Validation Accuracy:  0.765, Loss:  0.467
Epoch   1 Batch  416/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.760, Loss:  0.483
Epoch   1 Batch  417/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.760, Loss:  0.505
Epoch   1 Batch  418/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.771, Loss:  0.463
Epoch   1 Batch  419/1077 - Train Accuracy:  0.747, Validation Accuracy:  0.769, Loss:  0.465
Epoch   1 Batch  420/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.782, Loss:  0.444
Epoch   1 Batch  421/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.792, Loss:  0.480
Epoch   1 Batch  422/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.769, Loss:  0.439
Epoch   1 Batch  423/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.756, Loss:  0.479
Epoch   1 Batch  424/1077 - Train Accuracy:  0.716, Validation Accuracy:  0.750, Loss:  0.478
Epoch   1 Batch  425/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.750, Loss:  0.436
Epoch   1 Batch  426/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.756, Loss:  0.479
Epoch   1 Batch  427/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.771, Loss:  0.493
Epoch   1 Batch  428/1077 - Train Accuracy:  0.767, Validation Accuracy:  0.776, Loss:  0.440
Epoch   1 Batch  429/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.778, Loss:  0.460
Epoch   1 Batch  430/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.771, Loss:  0.494
Epoch   1 Batch  431/1077 - Train Accuracy:  0.744, Validation Accuracy:  0.773, Loss:  0.441
Epoch   1 Batch  432/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.770, Loss:  0.454
Epoch   1 Batch  433/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.771, Loss:  0.481
Epoch   1 Batch  434/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.768, Loss:  0.458
Epoch   1 Batch  435/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.763, Loss:  0.475
Epoch   1 Batch  436/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.771, Loss:  0.444
Epoch   1 Batch  437/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.776, Loss:  0.453
Epoch   1 Batch  438/1077 - Train Accuracy:  0.699, Validation Accuracy:  0.768, Loss:  0.484
Epoch   1 Batch  439/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.768, Loss:  0.492
Epoch   1 Batch  440/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.759, Loss:  0.501
Epoch   1 Batch  441/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.766, Loss:  0.450
Epoch   1 Batch  442/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.758, Loss:  0.461
Epoch   1 Batch  443/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.761, Loss:  0.446
Epoch   1 Batch  444/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.756, Loss:  0.439
Epoch   1 Batch  445/1077 - Train Accuracy:  0.715, Validation Accuracy:  0.754, Loss:  0.495
Epoch   1 Batch  446/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.741, Loss:  0.410
Epoch   1 Batch  447/1077 - Train Accuracy:  0.736, Validation Accuracy:  0.725, Loss:  0.468
Epoch   1 Batch  448/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.728, Loss:  0.483
Epoch   1 Batch  449/1077 - Train Accuracy:  0.737, Validation Accuracy:  0.730, Loss:  0.482
Epoch   1 Batch  450/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.741, Loss:  0.447
Epoch   1 Batch  451/1077 - Train Accuracy:  0.782, Validation Accuracy:  0.746, Loss:  0.418
Epoch   1 Batch  452/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.746, Loss:  0.488
Epoch   1 Batch  453/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.765, Loss:  0.445
Epoch   1 Batch  454/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.761, Loss:  0.475
Epoch   1 Batch  455/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.762, Loss:  0.444
Epoch   1 Batch  456/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.758, Loss:  0.450
Epoch   1 Batch  457/1077 - Train Accuracy:  0.741, Validation Accuracy:  0.746, Loss:  0.422
Epoch   1 Batch  458/1077 - Train Accuracy:  0.709, Validation Accuracy:  0.755, Loss:  0.477
Epoch   1 Batch  459/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.758, Loss:  0.446
Epoch   1 Batch  460/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.763, Loss:  0.465
Epoch   1 Batch  461/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.762, Loss:  0.454
Epoch   1 Batch  462/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.775, Loss:  0.431
Epoch   1 Batch  463/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.773, Loss:  0.460
Epoch   1 Batch  464/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.772, Loss:  0.429
Epoch   1 Batch  465/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.766, Loss:  0.498
Epoch   1 Batch  466/1077 - Train Accuracy:  0.734, Validation Accuracy:  0.771, Loss:  0.451
Epoch   1 Batch  467/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.764, Loss:  0.429
Epoch   1 Batch  468/1077 - Train Accuracy:  0.767, Validation Accuracy:  0.761, Loss:  0.446
Epoch   1 Batch  469/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.754, Loss:  0.446
Epoch   1 Batch  470/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.766, Loss:  0.470
Epoch   1 Batch  471/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.779, Loss:  0.429
Epoch   1 Batch  472/1077 - Train Accuracy:  0.774, Validation Accuracy:  0.791, Loss:  0.452
Epoch   1 Batch  473/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.778, Loss:  0.456
Epoch   1 Batch  474/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.784, Loss:  0.444
Epoch   1 Batch  475/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.786, Loss:  0.413
Epoch   1 Batch  476/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.799, Loss:  0.470
Epoch   1 Batch  477/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.788, Loss:  0.429
Epoch   1 Batch  478/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.784, Loss:  0.449
Epoch   1 Batch  479/1077 - Train Accuracy:  0.726, Validation Accuracy:  0.785, Loss:  0.489
Epoch   1 Batch  480/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.780, Loss:  0.465
Epoch   1 Batch  481/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.781, Loss:  0.453
Epoch   1 Batch  482/1077 - Train Accuracy:  0.735, Validation Accuracy:  0.775, Loss:  0.508
Epoch   1 Batch  483/1077 - Train Accuracy:  0.723, Validation Accuracy:  0.776, Loss:  0.437
Epoch   1 Batch  484/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.771, Loss:  0.447
Epoch   1 Batch  485/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.776, Loss:  0.454
Epoch   1 Batch  486/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.774, Loss:  0.446
Epoch   1 Batch  487/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.771, Loss:  0.473
Epoch   1 Batch  488/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.777, Loss:  0.458
Epoch   1 Batch  489/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.770, Loss:  0.424
Epoch   1 Batch  490/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.770, Loss:  0.467
Epoch   1 Batch  491/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.759, Loss:  0.457
Epoch   1 Batch  492/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.761, Loss:  0.478
Epoch   1 Batch  493/1077 - Train Accuracy:  0.767, Validation Accuracy:  0.755, Loss:  0.416
Epoch   1 Batch  494/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.765, Loss:  0.409
Epoch   1 Batch  495/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.773, Loss:  0.431
Epoch   1 Batch  496/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.768, Loss:  0.452
Epoch   1 Batch  497/1077 - Train Accuracy:  0.720, Validation Accuracy:  0.751, Loss:  0.461
Epoch   1 Batch  498/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.758, Loss:  0.436
Epoch   1 Batch  499/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.755, Loss:  0.412
Epoch   1 Batch  500/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.759, Loss:  0.441
Epoch   1 Batch  501/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.757, Loss:  0.420
Epoch   1 Batch  502/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.772, Loss:  0.446
Epoch   1 Batch  503/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.776, Loss:  0.406
Epoch   1 Batch  504/1077 - Train Accuracy:  0.738, Validation Accuracy:  0.772, Loss:  0.449
Epoch   1 Batch  505/1077 - Train Accuracy:  0.805, Validation Accuracy:  0.784, Loss:  0.389
Epoch   1 Batch  506/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.776, Loss:  0.450
Epoch   1 Batch  507/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.776, Loss:  0.428
Epoch   1 Batch  508/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.778, Loss:  0.421
Epoch   1 Batch  509/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.777, Loss:  0.450
Epoch   1 Batch  510/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.773, Loss:  0.419
Epoch   1 Batch  511/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.775, Loss:  0.441
Epoch   1 Batch  512/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.765, Loss:  0.437
Epoch   1 Batch  513/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.767, Loss:  0.464
Epoch   1 Batch  514/1077 - Train Accuracy:  0.740, Validation Accuracy:  0.763, Loss:  0.419
Epoch   1 Batch  515/1077 - Train Accuracy:  0.748, Validation Accuracy:  0.762, Loss:  0.465
Epoch   1 Batch  516/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.757, Loss:  0.393
Epoch   1 Batch  517/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.765, Loss:  0.432
Epoch   1 Batch  518/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.759, Loss:  0.411
Epoch   1 Batch  519/1077 - Train Accuracy:  0.785, Validation Accuracy:  0.767, Loss:  0.435
Epoch   1 Batch  520/1077 - Train Accuracy:  0.793, Validation Accuracy:  0.772, Loss:  0.397
Epoch   1 Batch  521/1077 - Train Accuracy:  0.767, Validation Accuracy:  0.779, Loss:  0.410
Epoch   1 Batch  522/1077 - Train Accuracy:  0.721, Validation Accuracy:  0.780, Loss:  0.472
Epoch   1 Batch  523/1077 - Train Accuracy:  0.751, Validation Accuracy:  0.779, Loss:  0.447
Epoch   1 Batch  524/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.785, Loss:  0.420
Epoch   1 Batch  525/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.777, Loss:  0.420
Epoch   1 Batch  526/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.772, Loss:  0.417
Epoch   1 Batch  527/1077 - Train Accuracy:  0.735, Validation Accuracy:  0.777, Loss:  0.443
Epoch   1 Batch  528/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.791, Loss:  0.423
Epoch   1 Batch  529/1077 - Train Accuracy:  0.756, Validation Accuracy:  0.781, Loss:  0.430
Epoch   1 Batch  530/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.782, Loss:  0.443
Epoch   1 Batch  531/1077 - Train Accuracy:  0.763, Validation Accuracy:  0.780, Loss:  0.423
Epoch   1 Batch  532/1077 - Train Accuracy:  0.739, Validation Accuracy:  0.773, Loss:  0.456
Epoch   1 Batch  533/1077 - Train Accuracy:  0.728, Validation Accuracy:  0.796, Loss:  0.468
Epoch   1 Batch  534/1077 - Train Accuracy:  0.782, Validation Accuracy:  0.784, Loss:  0.412
Epoch   1 Batch  535/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.793, Loss:  0.427
Epoch   1 Batch  536/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.781, Loss:  0.417
Epoch   1 Batch  537/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.773, Loss:  0.402
Epoch   1 Batch  538/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.779, Loss:  0.389
Epoch   1 Batch  539/1077 - Train Accuracy:  0.742, Validation Accuracy:  0.775, Loss:  0.429
Epoch   1 Batch  540/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.776, Loss:  0.406
Epoch   1 Batch  541/1077 - Train Accuracy:  0.750, Validation Accuracy:  0.784, Loss:  0.420
Epoch   1 Batch  542/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.789, Loss:  0.414
Epoch   1 Batch  543/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.782, Loss:  0.415
Epoch   1 Batch  544/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.784, Loss:  0.405
Epoch   1 Batch  545/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.782, Loss:  0.446
Epoch   1 Batch  546/1077 - Train Accuracy:  0.754, Validation Accuracy:  0.768, Loss:  0.446
Epoch   1 Batch  547/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.769, Loss:  0.411
Epoch   1 Batch  548/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.766, Loss:  0.444
Epoch   1 Batch  549/1077 - Train Accuracy:  0.719, Validation Accuracy:  0.774, Loss:  0.485
Epoch   1 Batch  550/1077 - Train Accuracy:  0.703, Validation Accuracy:  0.781, Loss:  0.449
Epoch   1 Batch  551/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.770, Loss:  0.427
Epoch   1 Batch  552/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.774, Loss:  0.436
Epoch   1 Batch  553/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.783, Loss:  0.438
Epoch   1 Batch  554/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.788, Loss:  0.427
Epoch   1 Batch  555/1077 - Train Accuracy:  0.760, Validation Accuracy:  0.783, Loss:  0.417
Epoch   1 Batch  556/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.781, Loss:  0.397
Epoch   1 Batch  557/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.759, Loss:  0.424
Epoch   1 Batch  558/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.770, Loss:  0.402
Epoch   1 Batch  559/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.772, Loss:  0.416
Epoch   1 Batch  560/1077 - Train Accuracy:  0.752, Validation Accuracy:  0.771, Loss:  0.421
Epoch   1 Batch  561/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.771, Loss:  0.407
Epoch   1 Batch  562/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.771, Loss:  0.374
Epoch   1 Batch  563/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.771, Loss:  0.459
Epoch   1 Batch  564/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.779, Loss:  0.436
Epoch   1 Batch  565/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.776, Loss:  0.429
Epoch   1 Batch  566/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.775, Loss:  0.435
Epoch   1 Batch  567/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.772, Loss:  0.420
Epoch   1 Batch  568/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.776, Loss:  0.417
Epoch   1 Batch  569/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.778, Loss:  0.419
Epoch   1 Batch  570/1077 - Train Accuracy:  0.755, Validation Accuracy:  0.778, Loss:  0.466
Epoch   1 Batch  571/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.762, Loss:  0.386
Epoch   1 Batch  572/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.775, Loss:  0.395
Epoch   1 Batch  573/1077 - Train Accuracy:  0.747, Validation Accuracy:  0.775, Loss:  0.431
Epoch   1 Batch  574/1077 - Train Accuracy:  0.743, Validation Accuracy:  0.764, Loss:  0.439
Epoch   1 Batch  575/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.771, Loss:  0.409
Epoch   1 Batch  576/1077 - Train Accuracy:  0.782, Validation Accuracy:  0.768, Loss:  0.422
Epoch   1 Batch  577/1077 - Train Accuracy:  0.758, Validation Accuracy:  0.767, Loss:  0.450
Epoch   1 Batch  578/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.775, Loss:  0.427
Epoch   1 Batch  579/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.774, Loss:  0.421
Epoch   1 Batch  580/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.773, Loss:  0.350
Epoch   1 Batch  581/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.781, Loss:  0.402
Epoch   1 Batch  582/1077 - Train Accuracy:  0.788, Validation Accuracy:  0.783, Loss:  0.408
Epoch   1 Batch  583/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.792, Loss:  0.435
Epoch   1 Batch  584/1077 - Train Accuracy:  0.782, Validation Accuracy:  0.797, Loss:  0.405
Epoch   1 Batch  585/1077 - Train Accuracy:  0.801, Validation Accuracy:  0.797, Loss:  0.376
Epoch   1 Batch  586/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.803, Loss:  0.412
Epoch   1 Batch  587/1077 - Train Accuracy:  0.793, Validation Accuracy:  0.790, Loss:  0.399
Epoch   1 Batch  588/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.787, Loss:  0.415
Epoch   1 Batch  589/1077 - Train Accuracy:  0.796, Validation Accuracy:  0.782, Loss:  0.422
Epoch   1 Batch  590/1077 - Train Accuracy:  0.730, Validation Accuracy:  0.778, Loss:  0.425
Epoch   1 Batch  591/1077 - Train Accuracy:  0.797, Validation Accuracy:  0.777, Loss:  0.376
Epoch   1 Batch  592/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.771, Loss:  0.414
Epoch   1 Batch  593/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.777, Loss:  0.399
Epoch   1 Batch  594/1077 - Train Accuracy:  0.789, Validation Accuracy:  0.793, Loss:  0.434
Epoch   1 Batch  595/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.787, Loss:  0.409
Epoch   1 Batch  596/1077 - Train Accuracy:  0.781, Validation Accuracy:  0.794, Loss:  0.432
Epoch   1 Batch  597/1077 - Train Accuracy:  0.751, Validation Accuracy:  0.795, Loss:  0.419
Epoch   1 Batch  598/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.799, Loss:  0.406
Epoch   1 Batch  599/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.800, Loss:  0.468
Epoch   1 Batch  600/1077 - Train Accuracy:  0.781, Validation Accuracy:  0.795, Loss:  0.391
Epoch   1 Batch  601/1077 - Train Accuracy:  0.767, Validation Accuracy:  0.789, Loss:  0.404
Epoch   1 Batch  602/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.795, Loss:  0.419
Epoch   1 Batch  603/1077 - Train Accuracy:  0.758, Validation Accuracy:  0.799, Loss:  0.409
Epoch   1 Batch  604/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.787, Loss:  0.423
Epoch   1 Batch  605/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.775, Loss:  0.431
Epoch   1 Batch  606/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.778, Loss:  0.389
Epoch   1 Batch  607/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.783, Loss:  0.388
Epoch   1 Batch  608/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.791, Loss:  0.424
Epoch   1 Batch  609/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.792, Loss:  0.383
Epoch   1 Batch  610/1077 - Train Accuracy:  0.769, Validation Accuracy:  0.788, Loss:  0.416
Epoch   1 Batch  611/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.779, Loss:  0.408
Epoch   1 Batch  612/1077 - Train Accuracy:  0.774, Validation Accuracy:  0.796, Loss:  0.373
Epoch   1 Batch  613/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.797, Loss:  0.402
Epoch   1 Batch  614/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.790, Loss:  0.385
Epoch   1 Batch  615/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.798, Loss:  0.401
Epoch   1 Batch  616/1077 - Train Accuracy:  0.761, Validation Accuracy:  0.788, Loss:  0.430
Epoch   1 Batch  617/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.784, Loss:  0.386
Epoch   1 Batch  618/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.787, Loss:  0.413
Epoch   1 Batch  619/1077 - Train Accuracy:  0.755, Validation Accuracy:  0.790, Loss:  0.425
Epoch   1 Batch  620/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.798, Loss:  0.378
Epoch   1 Batch  621/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.790, Loss:  0.364
Epoch   1 Batch  622/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.782, Loss:  0.433
Epoch   1 Batch  623/1077 - Train Accuracy:  0.766, Validation Accuracy:  0.788, Loss:  0.424
Epoch   1 Batch  624/1077 - Train Accuracy:  0.813, Validation Accuracy:  0.791, Loss:  0.401
Epoch   1 Batch  625/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.792, Loss:  0.412
Epoch   1 Batch  626/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.789, Loss:  0.372
Epoch   1 Batch  627/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.788, Loss:  0.395
Epoch   1 Batch  628/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.783, Loss:  0.412
Epoch   1 Batch  629/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.796, Loss:  0.432
Epoch   1 Batch  630/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.807, Loss:  0.387
Epoch   1 Batch  631/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.797, Loss:  0.388
Epoch   1 Batch  632/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.791, Loss:  0.394
Epoch   1 Batch  633/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.787, Loss:  0.406
Epoch   1 Batch  634/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.784, Loss:  0.368
Epoch   1 Batch  635/1077 - Train Accuracy:  0.755, Validation Accuracy:  0.788, Loss:  0.439
Epoch   1 Batch  636/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.785, Loss:  0.387
Epoch   1 Batch  637/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.788, Loss:  0.402
Epoch   1 Batch  638/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.789, Loss:  0.400
Epoch   1 Batch  639/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.789, Loss:  0.396
Epoch   1 Batch  640/1077 - Train Accuracy:  0.746, Validation Accuracy:  0.787, Loss:  0.360
Epoch   1 Batch  641/1077 - Train Accuracy:  0.784, Validation Accuracy:  0.775, Loss:  0.395
Epoch   1 Batch  642/1077 - Train Accuracy:  0.749, Validation Accuracy:  0.761, Loss:  0.398
Epoch   1 Batch  643/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.771, Loss:  0.382
Epoch   1 Batch  644/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.765, Loss:  0.397
Epoch   1 Batch  645/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.766, Loss:  0.386
Epoch   1 Batch  646/1077 - Train Accuracy:  0.774, Validation Accuracy:  0.773, Loss:  0.407
Epoch   1 Batch  647/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.782, Loss:  0.387
Epoch   1 Batch  648/1077 - Train Accuracy:  0.789, Validation Accuracy:  0.784, Loss:  0.370
Epoch   1 Batch  649/1077 - Train Accuracy:  0.739, Validation Accuracy:  0.767, Loss:  0.409
Epoch   1 Batch  650/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.776, Loss:  0.394
Epoch   1 Batch  651/1077 - Train Accuracy:  0.778, Validation Accuracy:  0.798, Loss:  0.375
Epoch   1 Batch  652/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.800, Loss:  0.416
Epoch   1 Batch  653/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.795, Loss:  0.380
Epoch   1 Batch  654/1077 - Train Accuracy:  0.793, Validation Accuracy:  0.803, Loss:  0.375
Epoch   1 Batch  655/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.794, Loss:  0.405
Epoch   1 Batch  656/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.788, Loss:  0.390
Epoch   1 Batch  657/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.783, Loss:  0.406
Epoch   1 Batch  658/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.781, Loss:  0.369
Epoch   1 Batch  659/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.776, Loss:  0.389
Epoch   1 Batch  660/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.763, Loss:  0.389
Epoch   1 Batch  661/1077 - Train Accuracy:  0.801, Validation Accuracy:  0.786, Loss:  0.359
Epoch   1 Batch  662/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.788, Loss:  0.376
Epoch   1 Batch  663/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.794, Loss:  0.367
Epoch   1 Batch  664/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.795, Loss:  0.377
Epoch   1 Batch  665/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.782, Loss:  0.365
Epoch   1 Batch  666/1077 - Train Accuracy:  0.774, Validation Accuracy:  0.784, Loss:  0.428
Epoch   1 Batch  667/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.785, Loss:  0.430
Epoch   1 Batch  668/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.786, Loss:  0.364
Epoch   1 Batch  669/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.802, Loss:  0.350
Epoch   1 Batch  670/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.800, Loss:  0.380
Epoch   1 Batch  671/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.784, Loss:  0.400
Epoch   1 Batch  672/1077 - Train Accuracy:  0.806, Validation Accuracy:  0.789, Loss:  0.359
Epoch   1 Batch  673/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.787, Loss:  0.363
Epoch   1 Batch  674/1077 - Train Accuracy:  0.796, Validation Accuracy:  0.792, Loss:  0.382
Epoch   1 Batch  675/1077 - Train Accuracy:  0.797, Validation Accuracy:  0.796, Loss:  0.387
Epoch   1 Batch  676/1077 - Train Accuracy:  0.796, Validation Accuracy:  0.799, Loss:  0.390
Epoch   1 Batch  677/1077 - Train Accuracy:  0.755, Validation Accuracy:  0.794, Loss:  0.407
Epoch   1 Batch  678/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.797, Loss:  0.362
Epoch   1 Batch  679/1077 - Train Accuracy:  0.779, Validation Accuracy:  0.808, Loss:  0.395
Epoch   1 Batch  680/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.809, Loss:  0.381
Epoch   1 Batch  681/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.797, Loss:  0.383
Epoch   1 Batch  682/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.804, Loss:  0.377
Epoch   1 Batch  683/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.798, Loss:  0.370
Epoch   1 Batch  684/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.795, Loss:  0.375
Epoch   1 Batch  685/1077 - Train Accuracy:  0.768, Validation Accuracy:  0.797, Loss:  0.381
Epoch   1 Batch  686/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.807, Loss:  0.352
Epoch   1 Batch  687/1077 - Train Accuracy:  0.804, Validation Accuracy:  0.802, Loss:  0.382
Epoch   1 Batch  688/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.812, Loss:  0.365
Epoch   1 Batch  689/1077 - Train Accuracy:  0.816, Validation Accuracy:  0.812, Loss:  0.353
Epoch   1 Batch  690/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.821, Loss:  0.371
Epoch   1 Batch  691/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.818, Loss:  0.401
Epoch   1 Batch  692/1077 - Train Accuracy:  0.797, Validation Accuracy:  0.815, Loss:  0.349
Epoch   1 Batch  693/1077 - Train Accuracy:  0.729, Validation Accuracy:  0.798, Loss:  0.443
Epoch   1 Batch  694/1077 - Train Accuracy:  0.821, Validation Accuracy:  0.789, Loss:  0.361
Epoch   1 Batch  695/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.787, Loss:  0.354
Epoch   1 Batch  696/1077 - Train Accuracy:  0.781, Validation Accuracy:  0.791, Loss:  0.424
Epoch   1 Batch  697/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.794, Loss:  0.352
Epoch   1 Batch  698/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.793, Loss:  0.349
Epoch   1 Batch  699/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.787, Loss:  0.379
Epoch   1 Batch  700/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.799, Loss:  0.346
Epoch   1 Batch  701/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.810, Loss:  0.398
Epoch   1 Batch  702/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.805, Loss:  0.387
Epoch   1 Batch  703/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.799, Loss:  0.369
Epoch   1 Batch  704/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.793, Loss:  0.403
Epoch   1 Batch  705/1077 - Train Accuracy:  0.788, Validation Accuracy:  0.788, Loss:  0.417
Epoch   1 Batch  706/1077 - Train Accuracy:  0.745, Validation Accuracy:  0.796, Loss:  0.415
Epoch   1 Batch  707/1077 - Train Accuracy:  0.775, Validation Accuracy:  0.789, Loss:  0.362
Epoch   1 Batch  708/1077 - Train Accuracy:  0.782, Validation Accuracy:  0.798, Loss:  0.380
Epoch   1 Batch  709/1077 - Train Accuracy:  0.776, Validation Accuracy:  0.801, Loss:  0.401
Epoch   1 Batch  710/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.801, Loss:  0.357
Epoch   1 Batch  711/1077 - Train Accuracy:  0.776, Validation Accuracy:  0.796, Loss:  0.389
Epoch   1 Batch  712/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.796, Loss:  0.355
Epoch   1 Batch  713/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.809, Loss:  0.313
Epoch   1 Batch  714/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.802, Loss:  0.377
Epoch   1 Batch  715/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.794, Loss:  0.386
Epoch   1 Batch  716/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.795, Loss:  0.351
Epoch   1 Batch  717/1077 - Train Accuracy:  0.813, Validation Accuracy:  0.813, Loss:  0.398
Epoch   1 Batch  718/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.794, Loss:  0.372
Epoch   1 Batch  719/1077 - Train Accuracy:  0.753, Validation Accuracy:  0.809, Loss:  0.417
Epoch   1 Batch  720/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.809, Loss:  0.388
Epoch   1 Batch  721/1077 - Train Accuracy:  0.762, Validation Accuracy:  0.808, Loss:  0.398
Epoch   1 Batch  722/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.802, Loss:  0.360
Epoch   1 Batch  723/1077 - Train Accuracy:  0.788, Validation Accuracy:  0.804, Loss:  0.372
Epoch   1 Batch  724/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.808, Loss:  0.391
Epoch   1 Batch  725/1077 - Train Accuracy:  0.813, Validation Accuracy:  0.814, Loss:  0.329
Epoch   1 Batch  726/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.812, Loss:  0.364
Epoch   1 Batch  727/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.808, Loss:  0.352
Epoch   1 Batch  728/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.805, Loss:  0.374
Epoch   1 Batch  729/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.798, Loss:  0.390
Epoch   1 Batch  730/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.792, Loss:  0.371
Epoch   1 Batch  731/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.788, Loss:  0.383
Epoch   1 Batch  732/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.787, Loss:  0.383
Epoch   1 Batch  733/1077 - Train Accuracy:  0.790, Validation Accuracy:  0.793, Loss:  0.370
Epoch   1 Batch  734/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.804, Loss:  0.387
Epoch   1 Batch  735/1077 - Train Accuracy:  0.797, Validation Accuracy:  0.789, Loss:  0.355
Epoch   1 Batch  736/1077 - Train Accuracy:  0.810, Validation Accuracy:  0.793, Loss:  0.344
Epoch   1 Batch  737/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.812, Loss:  0.400
Epoch   1 Batch  738/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.815, Loss:  0.307
Epoch   1 Batch  739/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.799, Loss:  0.334
Epoch   1 Batch  740/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.801, Loss:  0.354
Epoch   1 Batch  741/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.803, Loss:  0.392
Epoch   1 Batch  742/1077 - Train Accuracy:  0.810, Validation Accuracy:  0.794, Loss:  0.349
Epoch   1 Batch  743/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.801, Loss:  0.372
Epoch   1 Batch  744/1077 - Train Accuracy:  0.810, Validation Accuracy:  0.800, Loss:  0.347
Epoch   1 Batch  745/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.798, Loss:  0.354
Epoch   1 Batch  746/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.793, Loss:  0.352
Epoch   1 Batch  747/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.798, Loss:  0.332
Epoch   1 Batch  748/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.804, Loss:  0.352
Epoch   1 Batch  749/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.805, Loss:  0.367
Epoch   1 Batch  750/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.803, Loss:  0.356
Epoch   1 Batch  751/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.806, Loss:  0.338
Epoch   1 Batch  752/1077 - Train Accuracy:  0.785, Validation Accuracy:  0.796, Loss:  0.328
Epoch   1 Batch  753/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.797, Loss:  0.347
Epoch   1 Batch  754/1077 - Train Accuracy:  0.784, Validation Accuracy:  0.800, Loss:  0.351
Epoch   1 Batch  755/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.805, Loss:  0.337
Epoch   1 Batch  756/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.799, Loss:  0.336
Epoch   1 Batch  757/1077 - Train Accuracy:  0.801, Validation Accuracy:  0.803, Loss:  0.360
Epoch   1 Batch  758/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.815, Loss:  0.309
Epoch   1 Batch  759/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.814, Loss:  0.318
Epoch   1 Batch  760/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.806, Loss:  0.349
Epoch   1 Batch  761/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.810, Loss:  0.340
Epoch   1 Batch  762/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.814, Loss:  0.311
Epoch   1 Batch  763/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.808, Loss:  0.307
Epoch   1 Batch  764/1077 - Train Accuracy:  0.813, Validation Accuracy:  0.824, Loss:  0.330
Epoch   1 Batch  765/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.817, Loss:  0.322
Epoch   1 Batch  766/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.821, Loss:  0.358
Epoch   1 Batch  767/1077 - Train Accuracy:  0.821, Validation Accuracy:  0.830, Loss:  0.325
Epoch   1 Batch  768/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.827, Loss:  0.326
Epoch   1 Batch  769/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.821, Loss:  0.325
Epoch   1 Batch  770/1077 - Train Accuracy:  0.816, Validation Accuracy:  0.820, Loss:  0.300
Epoch   1 Batch  771/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.815, Loss:  0.353
Epoch   1 Batch  772/1077 - Train Accuracy:  0.796, Validation Accuracy:  0.815, Loss:  0.319
Epoch   1 Batch  773/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.807, Loss:  0.331
Epoch   1 Batch  774/1077 - Train Accuracy:  0.793, Validation Accuracy:  0.818, Loss:  0.352
Epoch   1 Batch  775/1077 - Train Accuracy:  0.790, Validation Accuracy:  0.816, Loss:  0.330
Epoch   1 Batch  776/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.819, Loss:  0.332
Epoch   1 Batch  777/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.817, Loss:  0.347
Epoch   1 Batch  778/1077 - Train Accuracy:  0.806, Validation Accuracy:  0.820, Loss:  0.324
Epoch   1 Batch  779/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.819, Loss:  0.364
Epoch   1 Batch  780/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.811, Loss:  0.370
Epoch   1 Batch  781/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.813, Loss:  0.298
Epoch   1 Batch  782/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.813, Loss:  0.333
Epoch   1 Batch  783/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.811, Loss:  0.349
Epoch   1 Batch  784/1077 - Train Accuracy:  0.820, Validation Accuracy:  0.818, Loss:  0.319
Epoch   1 Batch  785/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.805, Loss:  0.321
Epoch   1 Batch  786/1077 - Train Accuracy:  0.757, Validation Accuracy:  0.812, Loss:  0.357
Epoch   1 Batch  787/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.792, Loss:  0.301
Epoch   1 Batch  788/1077 - Train Accuracy:  0.819, Validation Accuracy:  0.797, Loss:  0.314
Epoch   1 Batch  789/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.826, Loss:  0.364
Epoch   1 Batch  790/1077 - Train Accuracy:  0.732, Validation Accuracy:  0.813, Loss:  0.364
Epoch   1 Batch  791/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.816, Loss:  0.347
Epoch   1 Batch  792/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.812, Loss:  0.349
Epoch   1 Batch  793/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.798, Loss:  0.340
Epoch   1 Batch  794/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.802, Loss:  0.347
Epoch   1 Batch  795/1077 - Train Accuracy:  0.788, Validation Accuracy:  0.814, Loss:  0.360
Epoch   1 Batch  796/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.805, Loss:  0.350
Epoch   1 Batch  797/1077 - Train Accuracy:  0.780, Validation Accuracy:  0.798, Loss:  0.357
Epoch   1 Batch  798/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.810, Loss:  0.377
Epoch   1 Batch  799/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.808, Loss:  0.369
Epoch   1 Batch  800/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.800, Loss:  0.328
Epoch   1 Batch  801/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.801, Loss:  0.351
Epoch   1 Batch  802/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.811, Loss:  0.340
Epoch   1 Batch  803/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.820, Loss:  0.350
Epoch   1 Batch  804/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.820, Loss:  0.333
Epoch   1 Batch  805/1077 - Train Accuracy:  0.777, Validation Accuracy:  0.819, Loss:  0.328
Epoch   1 Batch  806/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.822, Loss:  0.330
Epoch   1 Batch  807/1077 - Train Accuracy:  0.810, Validation Accuracy:  0.822, Loss:  0.311
Epoch   1 Batch  808/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.818, Loss:  0.357
Epoch   1 Batch  809/1077 - Train Accuracy:  0.765, Validation Accuracy:  0.824, Loss:  0.396
Epoch   1 Batch  810/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.816, Loss:  0.299
Epoch   1 Batch  811/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.807, Loss:  0.300
Epoch   1 Batch  812/1077 - Train Accuracy:  0.770, Validation Accuracy:  0.813, Loss:  0.344
Epoch   1 Batch  813/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.810, Loss:  0.323
Epoch   1 Batch  814/1077 - Train Accuracy:  0.772, Validation Accuracy:  0.815, Loss:  0.346
Epoch   1 Batch  815/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.811, Loss:  0.336
Epoch   1 Batch  816/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.821, Loss:  0.340
Epoch   1 Batch  817/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.835, Loss:  0.352
Epoch   1 Batch  818/1077 - Train Accuracy:  0.820, Validation Accuracy:  0.837, Loss:  0.340
Epoch   1 Batch  819/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.833, Loss:  0.334
Epoch   1 Batch  820/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.834, Loss:  0.326
Epoch   1 Batch  821/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.840, Loss:  0.312
Epoch   1 Batch  822/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.829, Loss:  0.342
Epoch   1 Batch  823/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.831, Loss:  0.313
Epoch   1 Batch  824/1077 - Train Accuracy:  0.805, Validation Accuracy:  0.831, Loss:  0.332
Epoch   1 Batch  825/1077 - Train Accuracy:  0.801, Validation Accuracy:  0.827, Loss:  0.318
Epoch   1 Batch  826/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.827, Loss:  0.322
Epoch   1 Batch  827/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.815, Loss:  0.361
Epoch   1 Batch  828/1077 - Train Accuracy:  0.819, Validation Accuracy:  0.816, Loss:  0.327
Epoch   1 Batch  829/1077 - Train Accuracy:  0.784, Validation Accuracy:  0.815, Loss:  0.353
Epoch   1 Batch  830/1077 - Train Accuracy:  0.804, Validation Accuracy:  0.815, Loss:  0.338
Epoch   1 Batch  831/1077 - Train Accuracy:  0.771, Validation Accuracy:  0.821, Loss:  0.327
Epoch   1 Batch  832/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.825, Loss:  0.315
Epoch   1 Batch  833/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.825, Loss:  0.340
Epoch   1 Batch  834/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.829, Loss:  0.312
Epoch   1 Batch  835/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.824, Loss:  0.319
Epoch   1 Batch  836/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.825, Loss:  0.341
Epoch   1 Batch  837/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.815, Loss:  0.369
Epoch   1 Batch  838/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.822, Loss:  0.294
Epoch   1 Batch  839/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.824, Loss:  0.294
Epoch   1 Batch  840/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.826, Loss:  0.304
Epoch   1 Batch  841/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.826, Loss:  0.316
Epoch   1 Batch  842/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.834, Loss:  0.300
Epoch   1 Batch  843/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.845, Loss:  0.298
Epoch   1 Batch  844/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.845, Loss:  0.317
Epoch   1 Batch  845/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.844, Loss:  0.307
Epoch   1 Batch  846/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.844, Loss:  0.336
Epoch   1 Batch  847/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.844, Loss:  0.343
Epoch   1 Batch  848/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.830, Loss:  0.295
Epoch   1 Batch  849/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.833, Loss:  0.284
Epoch   1 Batch  850/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.839, Loss:  0.337
Epoch   1 Batch  851/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.849, Loss:  0.328
Epoch   1 Batch  852/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.845, Loss:  0.331
Epoch   1 Batch  853/1077 - Train Accuracy:  0.816, Validation Accuracy:  0.838, Loss:  0.300
Epoch   1 Batch  854/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.831, Loss:  0.316
Epoch   1 Batch  855/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.818, Loss:  0.314
Epoch   1 Batch  856/1077 - Train Accuracy:  0.810, Validation Accuracy:  0.817, Loss:  0.315
Epoch   1 Batch  857/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.813, Loss:  0.307
Epoch   1 Batch  858/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.811, Loss:  0.310
Epoch   1 Batch  859/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.805, Loss:  0.320
Epoch   1 Batch  860/1077 - Train Accuracy:  0.819, Validation Accuracy:  0.806, Loss:  0.305
Epoch   1 Batch  861/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.796, Loss:  0.298
Epoch   1 Batch  862/1077 - Train Accuracy:  0.822, Validation Accuracy:  0.804, Loss:  0.313
Epoch   1 Batch  863/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.801, Loss:  0.306
Epoch   1 Batch  864/1077 - Train Accuracy:  0.802, Validation Accuracy:  0.793, Loss:  0.308
Epoch   1 Batch  865/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.796, Loss:  0.269
Epoch   1 Batch  866/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.800, Loss:  0.306
Epoch   1 Batch  867/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.803, Loss:  0.362
Epoch   1 Batch  868/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.813, Loss:  0.318
Epoch   1 Batch  869/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.822, Loss:  0.313
Epoch   1 Batch  870/1077 - Train Accuracy:  0.764, Validation Accuracy:  0.822, Loss:  0.330
Epoch   1 Batch  871/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.815, Loss:  0.307
Epoch   1 Batch  872/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.823, Loss:  0.307
Epoch   1 Batch  873/1077 - Train Accuracy:  0.806, Validation Accuracy:  0.825, Loss:  0.323
Epoch   1 Batch  874/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.827, Loss:  0.319
Epoch   1 Batch  875/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.832, Loss:  0.306
Epoch   1 Batch  876/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.838, Loss:  0.315
Epoch   1 Batch  877/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.842, Loss:  0.293
Epoch   1 Batch  878/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.841, Loss:  0.309
Epoch   1 Batch  879/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.837, Loss:  0.287
Epoch   1 Batch  880/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.841, Loss:  0.294
Epoch   1 Batch  881/1077 - Train Accuracy:  0.783, Validation Accuracy:  0.842, Loss:  0.335
Epoch   1 Batch  882/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.843, Loss:  0.318
Epoch   1 Batch  883/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.847, Loss:  0.368
Epoch   1 Batch  884/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.839, Loss:  0.290
Epoch   1 Batch  885/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.841, Loss:  0.254
Epoch   1 Batch  886/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.835, Loss:  0.307
Epoch   1 Batch  887/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.833, Loss:  0.318
Epoch   1 Batch  888/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.845, Loss:  0.313
Epoch   1 Batch  889/1077 - Train Accuracy:  0.819, Validation Accuracy:  0.827, Loss:  0.278
Epoch   1 Batch  890/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.824, Loss:  0.292
Epoch   1 Batch  891/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.831, Loss:  0.309
Epoch   1 Batch  892/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.823, Loss:  0.287
Epoch   1 Batch  893/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.822, Loss:  0.303
Epoch   1 Batch  894/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.821, Loss:  0.282
Epoch   1 Batch  895/1077 - Train Accuracy:  0.803, Validation Accuracy:  0.805, Loss:  0.303
Epoch   1 Batch  896/1077 - Train Accuracy:  0.787, Validation Accuracy:  0.806, Loss:  0.336
Epoch   1 Batch  897/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.810, Loss:  0.285
Epoch   1 Batch  898/1077 - Train Accuracy:  0.797, Validation Accuracy:  0.813, Loss:  0.278
Epoch   1 Batch  899/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.821, Loss:  0.314
Epoch   1 Batch  900/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.827, Loss:  0.324
Epoch   1 Batch  901/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.834, Loss:  0.308
Epoch   1 Batch  902/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.837, Loss:  0.316
Epoch   1 Batch  903/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.831, Loss:  0.294
Epoch   1 Batch  904/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.826, Loss:  0.302
Epoch   1 Batch  905/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.825, Loss:  0.281
Epoch   1 Batch  906/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.834, Loss:  0.285
Epoch   1 Batch  907/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.819, Loss:  0.284
Epoch   1 Batch  908/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.827, Loss:  0.312
Epoch   1 Batch  909/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.829, Loss:  0.292
Epoch   1 Batch  910/1077 - Train Accuracy:  0.804, Validation Accuracy:  0.831, Loss:  0.294
Epoch   1 Batch  911/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.834, Loss:  0.281
Epoch   1 Batch  912/1077 - Train Accuracy:  0.820, Validation Accuracy:  0.832, Loss:  0.304
Epoch   1 Batch  913/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.833, Loss:  0.317
Epoch   1 Batch  914/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.830, Loss:  0.301
Epoch   1 Batch  915/1077 - Train Accuracy:  0.797, Validation Accuracy:  0.818, Loss:  0.303
Epoch   1 Batch  916/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.814, Loss:  0.336
Epoch   1 Batch  917/1077 - Train Accuracy:  0.821, Validation Accuracy:  0.810, Loss:  0.281
Epoch   1 Batch  918/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.806, Loss:  0.267
Epoch   1 Batch  919/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.818, Loss:  0.288
Epoch   1 Batch  920/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.826, Loss:  0.290
Epoch   1 Batch  921/1077 - Train Accuracy:  0.805, Validation Accuracy:  0.831, Loss:  0.293
Epoch   1 Batch  922/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.829, Loss:  0.312
Epoch   1 Batch  923/1077 - Train Accuracy:  0.822, Validation Accuracy:  0.817, Loss:  0.303
Epoch   1 Batch  924/1077 - Train Accuracy:  0.805, Validation Accuracy:  0.810, Loss:  0.342
Epoch   1 Batch  925/1077 - Train Accuracy:  0.822, Validation Accuracy:  0.802, Loss:  0.289
Epoch   1 Batch  926/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.782, Loss:  0.319
Epoch   1 Batch  927/1077 - Train Accuracy:  0.774, Validation Accuracy:  0.792, Loss:  0.332
Epoch   1 Batch  928/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.805, Loss:  0.300
Epoch   1 Batch  929/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.804, Loss:  0.301
Epoch   1 Batch  930/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.805, Loss:  0.278
Epoch   1 Batch  931/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.809, Loss:  0.283
Epoch   1 Batch  932/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.815, Loss:  0.300
Epoch   1 Batch  933/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.824, Loss:  0.294
Epoch   1 Batch  934/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.831, Loss:  0.282
Epoch   1 Batch  935/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.813, Loss:  0.299
Epoch   1 Batch  936/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.817, Loss:  0.317
Epoch   1 Batch  937/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.808, Loss:  0.314
Epoch   1 Batch  938/1077 - Train Accuracy:  0.851, Validation Accuracy:  0.803, Loss:  0.297
Epoch   1 Batch  939/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.798, Loss:  0.302
Epoch   1 Batch  940/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.798, Loss:  0.271
Epoch   1 Batch  941/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.805, Loss:  0.265
Epoch   1 Batch  942/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.810, Loss:  0.297
Epoch   1 Batch  943/1077 - Train Accuracy:  0.821, Validation Accuracy:  0.809, Loss:  0.288
Epoch   1 Batch  944/1077 - Train Accuracy:  0.795, Validation Accuracy:  0.806, Loss:  0.286
Epoch   1 Batch  945/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.810, Loss:  0.272
Epoch   1 Batch  946/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.809, Loss:  0.293
Epoch   1 Batch  947/1077 - Train Accuracy:  0.759, Validation Accuracy:  0.816, Loss:  0.316
Epoch   1 Batch  948/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.823, Loss:  0.307
Epoch   1 Batch  949/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.831, Loss:  0.257
Epoch   1 Batch  950/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.834, Loss:  0.279
Epoch   1 Batch  951/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.838, Loss:  0.304
Epoch   1 Batch  952/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.837, Loss:  0.272
Epoch   1 Batch  953/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.833, Loss:  0.274
Epoch   1 Batch  954/1077 - Train Accuracy:  0.804, Validation Accuracy:  0.840, Loss:  0.289
Epoch   1 Batch  955/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.833, Loss:  0.287
Epoch   1 Batch  956/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.834, Loss:  0.297
Epoch   1 Batch  957/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.832, Loss:  0.271
Epoch   1 Batch  958/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.822, Loss:  0.284
Epoch   1 Batch  959/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.830, Loss:  0.266
Epoch   1 Batch  960/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.834, Loss:  0.264
Epoch   1 Batch  961/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.832, Loss:  0.272
Epoch   1 Batch  962/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.826, Loss:  0.288
Epoch   1 Batch  963/1077 - Train Accuracy:  0.849, Validation Accuracy:  0.836, Loss:  0.323
Epoch   1 Batch  964/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.822, Loss:  0.272
Epoch   1 Batch  965/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.839, Loss:  0.315
Epoch   1 Batch  966/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.830, Loss:  0.252
Epoch   1 Batch  967/1077 - Train Accuracy:  0.820, Validation Accuracy:  0.842, Loss:  0.279
Epoch   1 Batch  968/1077 - Train Accuracy:  0.786, Validation Accuracy:  0.833, Loss:  0.314
Epoch   1 Batch  969/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.842, Loss:  0.293
Epoch   1 Batch  970/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.844, Loss:  0.328
Epoch   1 Batch  971/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.846, Loss:  0.272
Epoch   1 Batch  972/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.832, Loss:  0.279
Epoch   1 Batch  973/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.835, Loss:  0.246
Epoch   1 Batch  974/1077 - Train Accuracy:  0.796, Validation Accuracy:  0.830, Loss:  0.266
Epoch   1 Batch  975/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.822, Loss:  0.260
Epoch   1 Batch  976/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.812, Loss:  0.277
Epoch   1 Batch  977/1077 - Train Accuracy:  0.851, Validation Accuracy:  0.822, Loss:  0.245
Epoch   1 Batch  978/1077 - Train Accuracy:  0.847, Validation Accuracy:  0.821, Loss:  0.286
Epoch   1 Batch  979/1077 - Train Accuracy:  0.842, Validation Accuracy:  0.825, Loss:  0.285
Epoch   1 Batch  980/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.819, Loss:  0.287
Epoch   1 Batch  981/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.813, Loss:  0.283
Epoch   1 Batch  982/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.836, Loss:  0.270
Epoch   1 Batch  983/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.830, Loss:  0.288
Epoch   1 Batch  984/1077 - Train Accuracy:  0.793, Validation Accuracy:  0.830, Loss:  0.302
Epoch   1 Batch  985/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.826, Loss:  0.257
Epoch   1 Batch  986/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.830, Loss:  0.292
Epoch   1 Batch  987/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.832, Loss:  0.253
Epoch   1 Batch  988/1077 - Train Accuracy:  0.842, Validation Accuracy:  0.842, Loss:  0.274
Epoch   1 Batch  989/1077 - Train Accuracy:  0.813, Validation Accuracy:  0.841, Loss:  0.285
Epoch   1 Batch  990/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.829, Loss:  0.294
Epoch   1 Batch  991/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.842, Loss:  0.288
Epoch   1 Batch  992/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.841, Loss:  0.276
Epoch   1 Batch  993/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.841, Loss:  0.243
Epoch   1 Batch  994/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.834, Loss:  0.254
Epoch   1 Batch  995/1077 - Train Accuracy:  0.820, Validation Accuracy:  0.843, Loss:  0.271
Epoch   1 Batch  996/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.834, Loss:  0.266
Epoch   1 Batch  997/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.824, Loss:  0.286
Epoch   1 Batch  998/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.819, Loss:  0.278
Epoch   1 Batch  999/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.817, Loss:  0.270
Epoch   1 Batch 1000/1077 - Train Accuracy:  0.847, Validation Accuracy:  0.819, Loss:  0.249
Epoch   1 Batch 1001/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.811, Loss:  0.252
Epoch   1 Batch 1002/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.817, Loss:  0.244
Epoch   1 Batch 1003/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.809, Loss:  0.271
Epoch   1 Batch 1004/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.806, Loss:  0.267
Epoch   1 Batch 1005/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.810, Loss:  0.256
Epoch   1 Batch 1006/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.818, Loss:  0.244
Epoch   1 Batch 1007/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.815, Loss:  0.246
Epoch   1 Batch 1008/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.819, Loss:  0.299
Epoch   1 Batch 1009/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.830, Loss:  0.237
Epoch   1 Batch 1010/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.836, Loss:  0.272
Epoch   1 Batch 1011/1077 - Train Accuracy:  0.822, Validation Accuracy:  0.837, Loss:  0.257
Epoch   1 Batch 1012/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.840, Loss:  0.246
Epoch   1 Batch 1013/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.847, Loss:  0.247
Epoch   1 Batch 1014/1077 - Train Accuracy:  0.820, Validation Accuracy:  0.840, Loss:  0.260
Epoch   1 Batch 1015/1077 - Train Accuracy:  0.816, Validation Accuracy:  0.829, Loss:  0.298
Epoch   1 Batch 1016/1077 - Train Accuracy:  0.792, Validation Accuracy:  0.814, Loss:  0.267
Epoch   1 Batch 1017/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.827, Loss:  0.274
Epoch   1 Batch 1018/1077 - Train Accuracy:  0.807, Validation Accuracy:  0.827, Loss:  0.255
Epoch   1 Batch 1019/1077 - Train Accuracy:  0.819, Validation Accuracy:  0.843, Loss:  0.310
Epoch   1 Batch 1020/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.836, Loss:  0.262
Epoch   1 Batch 1021/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.835, Loss:  0.259
Epoch   1 Batch 1022/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.825, Loss:  0.242
Epoch   1 Batch 1023/1077 - Train Accuracy:  0.822, Validation Accuracy:  0.833, Loss:  0.252
Epoch   1 Batch 1024/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.841, Loss:  0.290
Epoch   1 Batch 1025/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.842, Loss:  0.271
Epoch   1 Batch 1026/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.838, Loss:  0.250
Epoch   1 Batch 1027/1077 - Train Accuracy:  0.793, Validation Accuracy:  0.843, Loss:  0.279
Epoch   1 Batch 1028/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.833, Loss:  0.312
Epoch   1 Batch 1029/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.826, Loss:  0.359
Epoch   1 Batch 1030/1077 - Train Accuracy:  0.822, Validation Accuracy:  0.830, Loss:  0.322
Epoch   1 Batch 1031/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.820, Loss:  0.293
Epoch   1 Batch 1032/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.814, Loss:  0.294
Epoch   1 Batch 1033/1077 - Train Accuracy:  0.791, Validation Accuracy:  0.805, Loss:  0.299
Epoch   1 Batch 1034/1077 - Train Accuracy:  0.773, Validation Accuracy:  0.822, Loss:  0.315
Epoch   1 Batch 1035/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.823, Loss:  0.244
Epoch   1 Batch 1036/1077 - Train Accuracy:  0.819, Validation Accuracy:  0.830, Loss:  0.301
Epoch   1 Batch 1037/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.831, Loss:  0.283
Epoch   1 Batch 1038/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.838, Loss:  0.302
Epoch   1 Batch 1039/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.831, Loss:  0.271
Epoch   1 Batch 1040/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.804, Loss:  0.294
Epoch   1 Batch 1041/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.821, Loss:  0.295
Epoch   1 Batch 1042/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.832, Loss:  0.285
Epoch   1 Batch 1043/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.834, Loss:  0.309
Epoch   1 Batch 1044/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.843, Loss:  0.288
Epoch   1 Batch 1045/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.835, Loss:  0.291
Epoch   1 Batch 1046/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.836, Loss:  0.246
Epoch   1 Batch 1047/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.833, Loss:  0.257
Epoch   1 Batch 1048/1077 - Train Accuracy:  0.804, Validation Accuracy:  0.835, Loss:  0.265
Epoch   1 Batch 1049/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.831, Loss:  0.295
Epoch   1 Batch 1050/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.824, Loss:  0.276
Epoch   1 Batch 1051/1077 - Train Accuracy:  0.831, Validation Accuracy:  0.817, Loss:  0.279
Epoch   1 Batch 1052/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.822, Loss:  0.266
Epoch   1 Batch 1053/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.829, Loss:  0.271
Epoch   1 Batch 1054/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.831, Loss:  0.279
Epoch   1 Batch 1055/1077 - Train Accuracy:  0.799, Validation Accuracy:  0.816, Loss:  0.314
Epoch   1 Batch 1056/1077 - Train Accuracy:  0.798, Validation Accuracy:  0.823, Loss:  0.319
Epoch   1 Batch 1057/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.835, Loss:  0.320
Epoch   1 Batch 1058/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.826, Loss:  0.327
Epoch   1 Batch 1059/1077 - Train Accuracy:  0.776, Validation Accuracy:  0.811, Loss:  0.301
Epoch   1 Batch 1060/1077 - Train Accuracy:  0.816, Validation Accuracy:  0.822, Loss:  0.290
Epoch   1 Batch 1061/1077 - Train Accuracy:  0.840, Validation Accuracy:  0.830, Loss:  0.302
Epoch   1 Batch 1062/1077 - Train Accuracy:  0.794, Validation Accuracy:  0.826, Loss:  0.278
Epoch   1 Batch 1063/1077 - Train Accuracy:  0.814, Validation Accuracy:  0.810, Loss:  0.277
Epoch   1 Batch 1064/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.820, Loss:  0.279
Epoch   1 Batch 1065/1077 - Train Accuracy:  0.821, Validation Accuracy:  0.831, Loss:  0.272
Epoch   1 Batch 1066/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.830, Loss:  0.275
Epoch   1 Batch 1067/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.826, Loss:  0.274
Epoch   1 Batch 1068/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.831, Loss:  0.265
Epoch   1 Batch 1069/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.830, Loss:  0.233
Epoch   1 Batch 1070/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.828, Loss:  0.273
Epoch   1 Batch 1071/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.833, Loss:  0.252
Epoch   1 Batch 1072/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.828, Loss:  0.258
Epoch   1 Batch 1073/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.826, Loss:  0.280
Epoch   1 Batch 1074/1077 - Train Accuracy:  0.840, Validation Accuracy:  0.817, Loss:  0.305
Epoch   1 Batch 1075/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.815, Loss:  0.294
Epoch   2 Batch    0/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.820, Loss:  0.235
Epoch   2 Batch    1/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.820, Loss:  0.239
Epoch   2 Batch    2/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.820, Loss:  0.265
Epoch   2 Batch    3/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.817, Loss:  0.260
Epoch   2 Batch    4/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.820, Loss:  0.246
Epoch   2 Batch    5/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.828, Loss:  0.294
Epoch   2 Batch    6/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.830, Loss:  0.253
Epoch   2 Batch    7/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.823, Loss:  0.239
Epoch   2 Batch    8/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.824, Loss:  0.242
Epoch   2 Batch    9/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.831, Loss:  0.249
Epoch   2 Batch   10/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.829, Loss:  0.249
Epoch   2 Batch   11/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.838, Loss:  0.255
Epoch   2 Batch   12/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.844, Loss:  0.260
Epoch   2 Batch   13/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.841, Loss:  0.255
Epoch   2 Batch   14/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.846, Loss:  0.229
Epoch   2 Batch   15/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.846, Loss:  0.237
Epoch   2 Batch   16/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.850, Loss:  0.250
Epoch   2 Batch   17/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.850, Loss:  0.241
Epoch   2 Batch   18/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.846, Loss:  0.240
Epoch   2 Batch   19/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.843, Loss:  0.245
Epoch   2 Batch   20/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.847, Loss:  0.229
Epoch   2 Batch   21/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.850, Loss:  0.256
Epoch   2 Batch   22/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.839, Loss:  0.245
Epoch   2 Batch   23/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.845, Loss:  0.254
Epoch   2 Batch   24/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.846, Loss:  0.235
Epoch   2 Batch   25/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.845, Loss:  0.240
Epoch   2 Batch   26/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.839, Loss:  0.254
Epoch   2 Batch   27/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.839, Loss:  0.209
Epoch   2 Batch   28/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.846, Loss:  0.237
Epoch   2 Batch   29/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.853, Loss:  0.240
Epoch   2 Batch   30/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.844, Loss:  0.241
Epoch   2 Batch   31/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.849, Loss:  0.232
Epoch   2 Batch   32/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.857, Loss:  0.233
Epoch   2 Batch   33/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.839, Loss:  0.226
Epoch   2 Batch   34/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.853, Loss:  0.221
Epoch   2 Batch   35/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.847, Loss:  0.233
Epoch   2 Batch   36/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.843, Loss:  0.238
Epoch   2 Batch   37/1077 - Train Accuracy:  0.842, Validation Accuracy:  0.849, Loss:  0.257
Epoch   2 Batch   38/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.850, Loss:  0.270
Epoch   2 Batch   39/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.853, Loss:  0.264
Epoch   2 Batch   40/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.850, Loss:  0.227
Epoch   2 Batch   41/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.846, Loss:  0.235
Epoch   2 Batch   42/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.842, Loss:  0.256
Epoch   2 Batch   43/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.837, Loss:  0.221
Epoch   2 Batch   44/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.838, Loss:  0.236
Epoch   2 Batch   45/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.853, Loss:  0.230
Epoch   2 Batch   46/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.845, Loss:  0.247
Epoch   2 Batch   47/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.842, Loss:  0.237
Epoch   2 Batch   48/1077 - Train Accuracy:  0.818, Validation Accuracy:  0.843, Loss:  0.298
Epoch   2 Batch   49/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.859, Loss:  0.239
Epoch   2 Batch   50/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.855, Loss:  0.237
Epoch   2 Batch   51/1077 - Train Accuracy:  0.832, Validation Accuracy:  0.843, Loss:  0.245
Epoch   2 Batch   52/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.857, Loss:  0.265
Epoch   2 Batch   53/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.858, Loss:  0.240
Epoch   2 Batch   54/1077 - Train Accuracy:  0.788, Validation Accuracy:  0.833, Loss:  0.286
Epoch   2 Batch   55/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.837, Loss:  0.248
Epoch   2 Batch   56/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.827, Loss:  0.213
Epoch   2 Batch   57/1077 - Train Accuracy:  0.811, Validation Accuracy:  0.833, Loss:  0.235
Epoch   2 Batch   58/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.846, Loss:  0.225
Epoch   2 Batch   59/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.849, Loss:  0.243
Epoch   2 Batch   60/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.840, Loss:  0.237
Epoch   2 Batch   61/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.834, Loss:  0.258
Epoch   2 Batch   62/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.845, Loss:  0.261
Epoch   2 Batch   63/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.833, Loss:  0.226
Epoch   2 Batch   64/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.825, Loss:  0.235
Epoch   2 Batch   65/1077 - Train Accuracy:  0.815, Validation Accuracy:  0.836, Loss:  0.236
Epoch   2 Batch   66/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.836, Loss:  0.219
Epoch   2 Batch   67/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.837, Loss:  0.222
Epoch   2 Batch   68/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.844, Loss:  0.253
Epoch   2 Batch   69/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.848, Loss:  0.249
Epoch   2 Batch   70/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.849, Loss:  0.232
Epoch   2 Batch   71/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.854, Loss:  0.204
Epoch   2 Batch   72/1077 - Train Accuracy:  0.809, Validation Accuracy:  0.846, Loss:  0.243
Epoch   2 Batch   73/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.839, Loss:  0.243
Epoch   2 Batch   74/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.839, Loss:  0.218
Epoch   2 Batch   75/1077 - Train Accuracy:  0.849, Validation Accuracy:  0.835, Loss:  0.265
Epoch   2 Batch   76/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.833, Loss:  0.201
Epoch   2 Batch   77/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.835, Loss:  0.232
Epoch   2 Batch   78/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.845, Loss:  0.249
Epoch   2 Batch   79/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.841, Loss:  0.234
Epoch   2 Batch   80/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.841, Loss:  0.222
Epoch   2 Batch   81/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.845, Loss:  0.221
Epoch   2 Batch   82/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.855, Loss:  0.219
Epoch   2 Batch   83/1077 - Train Accuracy:  0.840, Validation Accuracy:  0.863, Loss:  0.240
Epoch   2 Batch   84/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.861, Loss:  0.223
Epoch   2 Batch   85/1077 - Train Accuracy:  0.828, Validation Accuracy:  0.864, Loss:  0.208
Epoch   2 Batch   86/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.859, Loss:  0.232
Epoch   2 Batch   87/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.859, Loss:  0.266
Epoch   2 Batch   88/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.853, Loss:  0.234
Epoch   2 Batch   89/1077 - Train Accuracy:  0.816, Validation Accuracy:  0.855, Loss:  0.237
Epoch   2 Batch   90/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.847, Loss:  0.250
Epoch   2 Batch   91/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.847, Loss:  0.212
Epoch   2 Batch   92/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.835, Loss:  0.230
Epoch   2 Batch   93/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.841, Loss:  0.226
Epoch   2 Batch   94/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.855, Loss:  0.203
Epoch   2 Batch   95/1077 - Train Accuracy:  0.849, Validation Accuracy:  0.861, Loss:  0.235
Epoch   2 Batch   96/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.857, Loss:  0.244
Epoch   2 Batch   97/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.849, Loss:  0.243
Epoch   2 Batch   98/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.850, Loss:  0.239
Epoch   2 Batch   99/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.855, Loss:  0.217
Epoch   2 Batch  100/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.855, Loss:  0.222
Epoch   2 Batch  101/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.854, Loss:  0.216
Epoch   2 Batch  102/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.849, Loss:  0.221
Epoch   2 Batch  103/1077 - Train Accuracy:  0.831, Validation Accuracy:  0.853, Loss:  0.237
Epoch   2 Batch  104/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.847, Loss:  0.227
Epoch   2 Batch  105/1077 - Train Accuracy:  0.842, Validation Accuracy:  0.840, Loss:  0.222
Epoch   2 Batch  106/1077 - Train Accuracy:  0.851, Validation Accuracy:  0.843, Loss:  0.261
Epoch   2 Batch  107/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.843, Loss:  0.211
Epoch   2 Batch  108/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.845, Loss:  0.201
Epoch   2 Batch  109/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.832, Loss:  0.224
Epoch   2 Batch  110/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.843, Loss:  0.203
Epoch   2 Batch  111/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.839, Loss:  0.227
Epoch   2 Batch  112/1077 - Train Accuracy:  0.842, Validation Accuracy:  0.843, Loss:  0.210
Epoch   2 Batch  113/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.855, Loss:  0.225
Epoch   2 Batch  114/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.853, Loss:  0.214
Epoch   2 Batch  115/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.850, Loss:  0.230
Epoch   2 Batch  116/1077 - Train Accuracy:  0.800, Validation Accuracy:  0.859, Loss:  0.243
Epoch   2 Batch  117/1077 - Train Accuracy:  0.831, Validation Accuracy:  0.856, Loss:  0.212
Epoch   2 Batch  118/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.850, Loss:  0.227
Epoch   2 Batch  119/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.848, Loss:  0.214
Epoch   2 Batch  120/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.846, Loss:  0.235
Epoch   2 Batch  121/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.850, Loss:  0.218
Epoch   2 Batch  122/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.846, Loss:  0.217
Epoch   2 Batch  123/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.843, Loss:  0.205
Epoch   2 Batch  124/1077 - Train Accuracy:  0.808, Validation Accuracy:  0.842, Loss:  0.242
Epoch   2 Batch  125/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.839, Loss:  0.212
Epoch   2 Batch  126/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.853, Loss:  0.209
Epoch   2 Batch  127/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.860, Loss:  0.216
Epoch   2 Batch  128/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.865, Loss:  0.208
Epoch   2 Batch  129/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.860, Loss:  0.227
Epoch   2 Batch  130/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.855, Loss:  0.209
Epoch   2 Batch  131/1077 - Train Accuracy:  0.826, Validation Accuracy:  0.857, Loss:  0.223
Epoch   2 Batch  132/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.851, Loss:  0.212
Epoch   2 Batch  133/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.864, Loss:  0.214
Epoch   2 Batch  134/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.860, Loss:  0.211
Epoch   2 Batch  135/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.862, Loss:  0.235
Epoch   2 Batch  136/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.857, Loss:  0.213
Epoch   2 Batch  137/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.853, Loss:  0.188
Epoch   2 Batch  138/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.851, Loss:  0.209
Epoch   2 Batch  139/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.838, Loss:  0.228
Epoch   2 Batch  140/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.848, Loss:  0.226
Epoch   2 Batch  141/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.856, Loss:  0.240
Epoch   2 Batch  142/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.858, Loss:  0.193
Epoch   2 Batch  143/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.858, Loss:  0.231
Epoch   2 Batch  144/1077 - Train Accuracy:  0.840, Validation Accuracy:  0.860, Loss:  0.247
Epoch   2 Batch  145/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.854, Loss:  0.225
Epoch   2 Batch  146/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.852, Loss:  0.257
Epoch   2 Batch  147/1077 - Train Accuracy:  0.805, Validation Accuracy:  0.854, Loss:  0.215
Epoch   2 Batch  148/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.860, Loss:  0.222
Epoch   2 Batch  149/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.855, Loss:  0.204
Epoch   2 Batch  150/1077 - Train Accuracy:  0.847, Validation Accuracy:  0.855, Loss:  0.218
Epoch   2 Batch  151/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.857, Loss:  0.206
Epoch   2 Batch  152/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.855, Loss:  0.241
Epoch   2 Batch  153/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.863, Loss:  0.226
Epoch   2 Batch  154/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.851, Loss:  0.203
Epoch   2 Batch  155/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.849, Loss:  0.204
Epoch   2 Batch  156/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.850, Loss:  0.203
Epoch   2 Batch  157/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.847, Loss:  0.209
Epoch   2 Batch  158/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.843, Loss:  0.227
Epoch   2 Batch  159/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.843, Loss:  0.187
Epoch   2 Batch  160/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.841, Loss:  0.206
Epoch   2 Batch  161/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.842, Loss:  0.193
Epoch   2 Batch  162/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.849, Loss:  0.258
Epoch   2 Batch  163/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.856, Loss:  0.231
Epoch   2 Batch  164/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.857, Loss:  0.200
Epoch   2 Batch  165/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.854, Loss:  0.205
Epoch   2 Batch  166/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.855, Loss:  0.199
Epoch   2 Batch  167/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.852, Loss:  0.206
Epoch   2 Batch  168/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.858, Loss:  0.232
Epoch   2 Batch  169/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.860, Loss:  0.225
Epoch   2 Batch  170/1077 - Train Accuracy:  0.836, Validation Accuracy:  0.859, Loss:  0.221
Epoch   2 Batch  171/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.858, Loss:  0.204
Epoch   2 Batch  172/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.865, Loss:  0.191
Epoch   2 Batch  173/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.862, Loss:  0.213
Epoch   2 Batch  174/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.861, Loss:  0.199
Epoch   2 Batch  175/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.861, Loss:  0.221
Epoch   2 Batch  176/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.855, Loss:  0.184
Epoch   2 Batch  177/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.863, Loss:  0.226
Epoch   2 Batch  178/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.862, Loss:  0.215
Epoch   2 Batch  179/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.858, Loss:  0.208
Epoch   2 Batch  180/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.858, Loss:  0.175
Epoch   2 Batch  181/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.867, Loss:  0.207
Epoch   2 Batch  182/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.864, Loss:  0.202
Epoch   2 Batch  183/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.861, Loss:  0.212
Epoch   2 Batch  184/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.852, Loss:  0.184
Epoch   2 Batch  185/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.850, Loss:  0.204
Epoch   2 Batch  186/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.855, Loss:  0.214
Epoch   2 Batch  187/1077 - Train Accuracy:  0.849, Validation Accuracy:  0.856, Loss:  0.182
Epoch   2 Batch  188/1077 - Train Accuracy:  0.841, Validation Accuracy:  0.864, Loss:  0.213
Epoch   2 Batch  189/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.859, Loss:  0.202
Epoch   2 Batch  190/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.860, Loss:  0.194
Epoch   2 Batch  191/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.865, Loss:  0.170
Epoch   2 Batch  192/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.868, Loss:  0.192
Epoch   2 Batch  193/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.860, Loss:  0.201
Epoch   2 Batch  194/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.865, Loss:  0.181
Epoch   2 Batch  195/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.869, Loss:  0.196
Epoch   2 Batch  196/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.872, Loss:  0.191
Epoch   2 Batch  197/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.877, Loss:  0.213
Epoch   2 Batch  198/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.881, Loss:  0.183
Epoch   2 Batch  199/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.873, Loss:  0.200
Epoch   2 Batch  200/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.871, Loss:  0.218
Epoch   2 Batch  201/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.865, Loss:  0.184
Epoch   2 Batch  202/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.864, Loss:  0.197
Epoch   2 Batch  203/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.845, Loss:  0.206
Epoch   2 Batch  204/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.847, Loss:  0.222
Epoch   2 Batch  205/1077 - Train Accuracy:  0.817, Validation Accuracy:  0.848, Loss:  0.228
Epoch   2 Batch  206/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.868, Loss:  0.213
Epoch   2 Batch  207/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.858, Loss:  0.184
Epoch   2 Batch  208/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.857, Loss:  0.184
Epoch   2 Batch  209/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.857, Loss:  0.190
Epoch   2 Batch  210/1077 - Train Accuracy:  0.851, Validation Accuracy:  0.858, Loss:  0.200
Epoch   2 Batch  211/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.862, Loss:  0.188
Epoch   2 Batch  212/1077 - Train Accuracy:  0.842, Validation Accuracy:  0.862, Loss:  0.178
Epoch   2 Batch  213/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.862, Loss:  0.188
Epoch   2 Batch  214/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.848, Loss:  0.185
Epoch   2 Batch  215/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.840, Loss:  0.198
Epoch   2 Batch  216/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.840, Loss:  0.211
Epoch   2 Batch  217/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.852, Loss:  0.194
Epoch   2 Batch  218/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.841, Loss:  0.219
Epoch   2 Batch  219/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.842, Loss:  0.196
Epoch   2 Batch  220/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.847, Loss:  0.207
Epoch   2 Batch  221/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.853, Loss:  0.194
Epoch   2 Batch  222/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.860, Loss:  0.205
Epoch   2 Batch  223/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.879, Loss:  0.187
Epoch   2 Batch  224/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.876, Loss:  0.205
Epoch   2 Batch  225/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.874, Loss:  0.221
Epoch   2 Batch  226/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.875, Loss:  0.187
Epoch   2 Batch  227/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.862, Loss:  0.225
Epoch   2 Batch  228/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.869, Loss:  0.193
Epoch   2 Batch  229/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.866, Loss:  0.192
Epoch   2 Batch  230/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.866, Loss:  0.177
Epoch   2 Batch  231/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.866, Loss:  0.208
Epoch   2 Batch  232/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.874, Loss:  0.184
Epoch   2 Batch  233/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.873, Loss:  0.233
Epoch   2 Batch  234/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.871, Loss:  0.196
Epoch   2 Batch  235/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.870, Loss:  0.194
Epoch   2 Batch  236/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.873, Loss:  0.210
Epoch   2 Batch  237/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.877, Loss:  0.180
Epoch   2 Batch  238/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.876, Loss:  0.201
Epoch   2 Batch  239/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.876, Loss:  0.173
Epoch   2 Batch  240/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.873, Loss:  0.190
Epoch   2 Batch  241/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.875, Loss:  0.191
Epoch   2 Batch  242/1077 - Train Accuracy:  0.847, Validation Accuracy:  0.882, Loss:  0.196
Epoch   2 Batch  243/1077 - Train Accuracy:  0.824, Validation Accuracy:  0.887, Loss:  0.205
Epoch   2 Batch  244/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.883, Loss:  0.198
Epoch   2 Batch  245/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.884, Loss:  0.176
Epoch   2 Batch  246/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.875, Loss:  0.207
Epoch   2 Batch  247/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.864, Loss:  0.180
Epoch   2 Batch  248/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.866, Loss:  0.198
Epoch   2 Batch  249/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.868, Loss:  0.189
Epoch   2 Batch  250/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.875, Loss:  0.186
Epoch   2 Batch  251/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.870, Loss:  0.201
Epoch   2 Batch  252/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.870, Loss:  0.198
Epoch   2 Batch  253/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.873, Loss:  0.170
Epoch   2 Batch  254/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.871, Loss:  0.191
Epoch   2 Batch  255/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.876, Loss:  0.190
Epoch   2 Batch  256/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.879, Loss:  0.212
Epoch   2 Batch  257/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.877, Loss:  0.173
Epoch   2 Batch  258/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.880, Loss:  0.165
Epoch   2 Batch  259/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.885, Loss:  0.175
Epoch   2 Batch  260/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.878, Loss:  0.165
Epoch   2 Batch  261/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.874, Loss:  0.183
Epoch   2 Batch  262/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.893, Loss:  0.163
Epoch   2 Batch  263/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.896, Loss:  0.169
Epoch   2 Batch  264/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.886, Loss:  0.178
Epoch   2 Batch  265/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.880, Loss:  0.180
Epoch   2 Batch  266/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.885, Loss:  0.170
Epoch   2 Batch  267/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.883, Loss:  0.182
Epoch   2 Batch  268/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.882, Loss:  0.218
Epoch   2 Batch  269/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.873, Loss:  0.230
Epoch   2 Batch  270/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.875, Loss:  0.198
Epoch   2 Batch  271/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.867, Loss:  0.174
Epoch   2 Batch  272/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.866, Loss:  0.229
Epoch   2 Batch  273/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.875, Loss:  0.178
Epoch   2 Batch  274/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.869, Loss:  0.181
Epoch   2 Batch  275/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.870, Loss:  0.192
Epoch   2 Batch  276/1077 - Train Accuracy:  0.823, Validation Accuracy:  0.868, Loss:  0.206
Epoch   2 Batch  277/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.867, Loss:  0.159
Epoch   2 Batch  278/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.858, Loss:  0.219
Epoch   2 Batch  279/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.873, Loss:  0.208
Epoch   2 Batch  280/1077 - Train Accuracy:  0.840, Validation Accuracy:  0.875, Loss:  0.194
Epoch   2 Batch  281/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.874, Loss:  0.179
Epoch   2 Batch  282/1077 - Train Accuracy:  0.851, Validation Accuracy:  0.866, Loss:  0.206
Epoch   2 Batch  283/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.866, Loss:  0.203
Epoch   2 Batch  284/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.873, Loss:  0.203
Epoch   2 Batch  285/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.871, Loss:  0.192
Epoch   2 Batch  286/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.869, Loss:  0.164
Epoch   2 Batch  287/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.864, Loss:  0.179
Epoch   2 Batch  288/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.870, Loss:  0.187
Epoch   2 Batch  289/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.875, Loss:  0.182
Epoch   2 Batch  290/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.883, Loss:  0.220
Epoch   2 Batch  291/1077 - Train Accuracy:  0.835, Validation Accuracy:  0.880, Loss:  0.211
Epoch   2 Batch  292/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.880, Loss:  0.192
Epoch   2 Batch  293/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.861, Loss:  0.188
Epoch   2 Batch  294/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.855, Loss:  0.183
Epoch   2 Batch  295/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.863, Loss:  0.196
Epoch   2 Batch  296/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.860, Loss:  0.173
Epoch   2 Batch  297/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.864, Loss:  0.196
Epoch   2 Batch  298/1077 - Train Accuracy:  0.812, Validation Accuracy:  0.863, Loss:  0.210
Epoch   2 Batch  299/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.874, Loss:  0.195
Epoch   2 Batch  300/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.880, Loss:  0.168
Epoch   2 Batch  301/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.876, Loss:  0.174
Epoch   2 Batch  302/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.870, Loss:  0.160
Epoch   2 Batch  303/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.873, Loss:  0.187
Epoch   2 Batch  304/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.881, Loss:  0.175
Epoch   2 Batch  305/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.874, Loss:  0.164
Epoch   2 Batch  306/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.879, Loss:  0.186
Epoch   2 Batch  307/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.874, Loss:  0.165
Epoch   2 Batch  308/1077 - Train Accuracy:  0.829, Validation Accuracy:  0.877, Loss:  0.197
Epoch   2 Batch  309/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.885, Loss:  0.153
Epoch   2 Batch  310/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.878, Loss:  0.185
Epoch   2 Batch  311/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.870, Loss:  0.183
Epoch   2 Batch  312/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.874, Loss:  0.202
Epoch   2 Batch  313/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.879, Loss:  0.149
Epoch   2 Batch  314/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.871, Loss:  0.165
Epoch   2 Batch  315/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.875, Loss:  0.157
Epoch   2 Batch  316/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.864, Loss:  0.158
Epoch   2 Batch  317/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.859, Loss:  0.207
Epoch   2 Batch  318/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.866, Loss:  0.165
Epoch   2 Batch  319/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.850, Loss:  0.192
Epoch   2 Batch  320/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.855, Loss:  0.181
Epoch   2 Batch  321/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.869, Loss:  0.168
Epoch   2 Batch  322/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.874, Loss:  0.177
Epoch   2 Batch  323/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.873, Loss:  0.169
Epoch   2 Batch  324/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.877, Loss:  0.157
Epoch   2 Batch  325/1077 - Train Accuracy:  0.856, Validation Accuracy:  0.872, Loss:  0.172
Epoch   2 Batch  326/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.875, Loss:  0.159
Epoch   2 Batch  327/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.874, Loss:  0.188
Epoch   2 Batch  328/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.865, Loss:  0.182
Epoch   2 Batch  329/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.865, Loss:  0.170
Epoch   2 Batch  330/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.863, Loss:  0.178
Epoch   2 Batch  331/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.857, Loss:  0.198
Epoch   2 Batch  332/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.856, Loss:  0.154
Epoch   2 Batch  333/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.855, Loss:  0.179
Epoch   2 Batch  334/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.838, Loss:  0.174
Epoch   2 Batch  335/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.839, Loss:  0.153
Epoch   2 Batch  336/1077 - Train Accuracy:  0.849, Validation Accuracy:  0.839, Loss:  0.216
Epoch   2 Batch  337/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.849, Loss:  0.175
Epoch   2 Batch  338/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.864, Loss:  0.200
Epoch   2 Batch  339/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.858, Loss:  0.165
Epoch   2 Batch  340/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.853, Loss:  0.162
Epoch   2 Batch  341/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.858, Loss:  0.205
Epoch   2 Batch  342/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.857, Loss:  0.163
Epoch   2 Batch  343/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.859, Loss:  0.171
Epoch   2 Batch  344/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.855, Loss:  0.177
Epoch   2 Batch  345/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.855, Loss:  0.152
Epoch   2 Batch  346/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.863, Loss:  0.200
Epoch   2 Batch  347/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.860, Loss:  0.160
Epoch   2 Batch  348/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.853, Loss:  0.162
Epoch   2 Batch  349/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.847, Loss:  0.168
Epoch   2 Batch  350/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.851, Loss:  0.177
Epoch   2 Batch  351/1077 - Train Accuracy:  0.831, Validation Accuracy:  0.845, Loss:  0.184
Epoch   2 Batch  352/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.848, Loss:  0.177
Epoch   2 Batch  353/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.856, Loss:  0.204
Epoch   2 Batch  354/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.858, Loss:  0.195
Epoch   2 Batch  355/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.865, Loss:  0.166
Epoch   2 Batch  356/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.869, Loss:  0.167
Epoch   2 Batch  357/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.860, Loss:  0.152
Epoch   2 Batch  358/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.857, Loss:  0.170
Epoch   2 Batch  359/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.864, Loss:  0.169
Epoch   2 Batch  360/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.881, Loss:  0.168
Epoch   2 Batch  361/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.878, Loss:  0.171
Epoch   2 Batch  362/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.875, Loss:  0.164
Epoch   2 Batch  363/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.877, Loss:  0.178
Epoch   2 Batch  364/1077 - Train Accuracy:  0.849, Validation Accuracy:  0.878, Loss:  0.172
Epoch   2 Batch  365/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.872, Loss:  0.157
Epoch   2 Batch  366/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.873, Loss:  0.157
Epoch   2 Batch  367/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.876, Loss:  0.140
Epoch   2 Batch  368/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.879, Loss:  0.190
Epoch   2 Batch  369/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.874, Loss:  0.178
Epoch   2 Batch  370/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.874, Loss:  0.157
Epoch   2 Batch  371/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.876, Loss:  0.142
Epoch   2 Batch  372/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.880, Loss:  0.139
Epoch   2 Batch  373/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.873, Loss:  0.166
Epoch   2 Batch  374/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.864, Loss:  0.186
Epoch   2 Batch  375/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.850, Loss:  0.160
Epoch   2 Batch  376/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.852, Loss:  0.179
Epoch   2 Batch  377/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.858, Loss:  0.172
Epoch   2 Batch  378/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.870, Loss:  0.145
Epoch   2 Batch  379/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.869, Loss:  0.183
Epoch   2 Batch  380/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.877, Loss:  0.171
Epoch   2 Batch  381/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.870, Loss:  0.210
Epoch   2 Batch  382/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.862, Loss:  0.201
Epoch   2 Batch  383/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.864, Loss:  0.161
Epoch   2 Batch  384/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.880, Loss:  0.152
Epoch   2 Batch  385/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.880, Loss:  0.155
Epoch   2 Batch  386/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.881, Loss:  0.154
Epoch   2 Batch  387/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.885, Loss:  0.176
Epoch   2 Batch  388/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.888, Loss:  0.166
Epoch   2 Batch  389/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.885, Loss:  0.164
Epoch   2 Batch  390/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.882, Loss:  0.170
Epoch   2 Batch  391/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.881, Loss:  0.159
Epoch   2 Batch  392/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.880, Loss:  0.167
Epoch   2 Batch  393/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.883, Loss:  0.149
Epoch   2 Batch  394/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.880, Loss:  0.163
Epoch   2 Batch  395/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.884, Loss:  0.157
Epoch   2 Batch  396/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.875, Loss:  0.165
Epoch   2 Batch  397/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.879, Loss:  0.164
Epoch   2 Batch  398/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.880, Loss:  0.167
Epoch   2 Batch  399/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.876, Loss:  0.166
Epoch   2 Batch  400/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.877, Loss:  0.183
Epoch   2 Batch  401/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.887, Loss:  0.160
Epoch   2 Batch  402/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.897, Loss:  0.142
Epoch   2 Batch  403/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.893, Loss:  0.183
Epoch   2 Batch  404/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.898, Loss:  0.153
Epoch   2 Batch  405/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.900, Loss:  0.170
Epoch   2 Batch  406/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.888, Loss:  0.159
Epoch   2 Batch  407/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.882, Loss:  0.166
Epoch   2 Batch  408/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.888, Loss:  0.162
Epoch   2 Batch  409/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.892, Loss:  0.177
Epoch   2 Batch  410/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.895, Loss:  0.156
Epoch   2 Batch  411/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.896, Loss:  0.167
Epoch   2 Batch  412/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.882, Loss:  0.128
Epoch   2 Batch  413/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.885, Loss:  0.150
Epoch   2 Batch  414/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.889, Loss:  0.165
Epoch   2 Batch  415/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.886, Loss:  0.165
Epoch   2 Batch  416/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.871, Loss:  0.175
Epoch   2 Batch  417/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.880, Loss:  0.209
Epoch   2 Batch  418/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.888, Loss:  0.166
Epoch   2 Batch  419/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.885, Loss:  0.141
Epoch   2 Batch  420/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.872, Loss:  0.145
Epoch   2 Batch  421/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.878, Loss:  0.188
Epoch   2 Batch  422/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.878, Loss:  0.157
Epoch   2 Batch  423/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.877, Loss:  0.185
Epoch   2 Batch  424/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.877, Loss:  0.169
Epoch   2 Batch  425/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.872, Loss:  0.146
Epoch   2 Batch  426/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.871, Loss:  0.156
Epoch   2 Batch  427/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.890, Loss:  0.147
Epoch   2 Batch  428/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.891, Loss:  0.146
Epoch   2 Batch  429/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.894, Loss:  0.154
Epoch   2 Batch  430/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.885, Loss:  0.149
Epoch   2 Batch  431/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.887, Loss:  0.136
Epoch   2 Batch  432/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.886, Loss:  0.159
Epoch   2 Batch  433/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.887, Loss:  0.183
Epoch   2 Batch  434/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.887, Loss:  0.167
Epoch   2 Batch  435/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.874, Loss:  0.160
Epoch   2 Batch  436/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.866, Loss:  0.161
Epoch   2 Batch  437/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.868, Loss:  0.143
Epoch   2 Batch  438/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.865, Loss:  0.158
Epoch   2 Batch  439/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.874, Loss:  0.201
Epoch   2 Batch  440/1077 - Train Accuracy:  0.825, Validation Accuracy:  0.875, Loss:  0.190
Epoch   2 Batch  441/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.875, Loss:  0.167
Epoch   2 Batch  442/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.875, Loss:  0.154
Epoch   2 Batch  443/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.873, Loss:  0.144
Epoch   2 Batch  444/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.873, Loss:  0.157
Epoch   2 Batch  445/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.862, Loss:  0.164
Epoch   2 Batch  446/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.860, Loss:  0.133
Epoch   2 Batch  447/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.857, Loss:  0.158
Epoch   2 Batch  448/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.866, Loss:  0.207
Epoch   2 Batch  449/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.865, Loss:  0.185
Epoch   2 Batch  450/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.866, Loss:  0.159
Epoch   2 Batch  451/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.865, Loss:  0.152
Epoch   2 Batch  452/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.861, Loss:  0.158
Epoch   2 Batch  453/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.874, Loss:  0.162
Epoch   2 Batch  454/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.873, Loss:  0.194
Epoch   2 Batch  455/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.869, Loss:  0.160
Epoch   2 Batch  456/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.870, Loss:  0.148
Epoch   2 Batch  457/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.869, Loss:  0.134
Epoch   2 Batch  458/1077 - Train Accuracy:  0.834, Validation Accuracy:  0.887, Loss:  0.166
Epoch   2 Batch  459/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.887, Loss:  0.159
Epoch   2 Batch  460/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.880, Loss:  0.156
Epoch   2 Batch  461/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.877, Loss:  0.156
Epoch   2 Batch  462/1077 - Train Accuracy:  0.848, Validation Accuracy:  0.879, Loss:  0.170
Epoch   2 Batch  463/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.892, Loss:  0.162
Epoch   2 Batch  464/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.883, Loss:  0.149
Epoch   2 Batch  465/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.879, Loss:  0.167
Epoch   2 Batch  466/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.891, Loss:  0.161
Epoch   2 Batch  467/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.875, Loss:  0.171
Epoch   2 Batch  468/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.875, Loss:  0.168
Epoch   2 Batch  469/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.861, Loss:  0.153
Epoch   2 Batch  470/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.874, Loss:  0.158
Epoch   2 Batch  471/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.876, Loss:  0.132
Epoch   2 Batch  472/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.886, Loss:  0.149
Epoch   2 Batch  473/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.885, Loss:  0.171
Epoch   2 Batch  474/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.886, Loss:  0.163
Epoch   2 Batch  475/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.883, Loss:  0.142
Epoch   2 Batch  476/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.879, Loss:  0.137
Epoch   2 Batch  477/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.875, Loss:  0.164
Epoch   2 Batch  478/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.878, Loss:  0.142
Epoch   2 Batch  479/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.883, Loss:  0.177
Epoch   2 Batch  480/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.896, Loss:  0.164
Epoch   2 Batch  481/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.895, Loss:  0.149
Epoch   2 Batch  482/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.899, Loss:  0.189
Epoch   2 Batch  483/1077 - Train Accuracy:  0.831, Validation Accuracy:  0.877, Loss:  0.145
Epoch   2 Batch  484/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.879, Loss:  0.189
Epoch   2 Batch  485/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.886, Loss:  0.208
Epoch   2 Batch  486/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.876, Loss:  0.155
Epoch   2 Batch  487/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.869, Loss:  0.165
Epoch   2 Batch  488/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.875, Loss:  0.224
Epoch   2 Batch  489/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.877, Loss:  0.161
Epoch   2 Batch  490/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.880, Loss:  0.204
Epoch   2 Batch  491/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.864, Loss:  0.203
Epoch   2 Batch  492/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.869, Loss:  0.213
Epoch   2 Batch  493/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.877, Loss:  0.159
Epoch   2 Batch  494/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.868, Loss:  0.169
Epoch   2 Batch  495/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.869, Loss:  0.195
Epoch   2 Batch  496/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.856, Loss:  0.183
Epoch   2 Batch  497/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.842, Loss:  0.196
Epoch   2 Batch  498/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.841, Loss:  0.205
Epoch   2 Batch  499/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.864, Loss:  0.150
Epoch   2 Batch  500/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.867, Loss:  0.159
Epoch   2 Batch  501/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.885, Loss:  0.182
Epoch   2 Batch  502/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.885, Loss:  0.182
Epoch   2 Batch  503/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.879, Loss:  0.167
Epoch   2 Batch  504/1077 - Train Accuracy:  0.854, Validation Accuracy:  0.873, Loss:  0.179
Epoch   2 Batch  505/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.874, Loss:  0.137
Epoch   2 Batch  506/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.891, Loss:  0.172
Epoch   2 Batch  507/1077 - Train Accuracy:  0.840, Validation Accuracy:  0.890, Loss:  0.181
Epoch   2 Batch  508/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.885, Loss:  0.155
Epoch   2 Batch  509/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.888, Loss:  0.177
Epoch   2 Batch  510/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.885, Loss:  0.173
Epoch   2 Batch  511/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.885, Loss:  0.171
Epoch   2 Batch  512/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.879, Loss:  0.169
Epoch   2 Batch  513/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.879, Loss:  0.188
Epoch   2 Batch  514/1077 - Train Accuracy:  0.843, Validation Accuracy:  0.877, Loss:  0.164
Epoch   2 Batch  515/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.887, Loss:  0.196
Epoch   2 Batch  516/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.893, Loss:  0.182
Epoch   2 Batch  517/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.891, Loss:  0.181
Epoch   2 Batch  518/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.893, Loss:  0.157
Epoch   2 Batch  519/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.891, Loss:  0.158
Epoch   2 Batch  520/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.878, Loss:  0.158
Epoch   2 Batch  521/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.887, Loss:  0.164
Epoch   2 Batch  522/1077 - Train Accuracy:  0.821, Validation Accuracy:  0.873, Loss:  0.184
Epoch   2 Batch  523/1077 - Train Accuracy:  0.839, Validation Accuracy:  0.870, Loss:  0.179
Epoch   2 Batch  524/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.876, Loss:  0.170
Epoch   2 Batch  525/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.868, Loss:  0.151
Epoch   2 Batch  526/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.870, Loss:  0.162
Epoch   2 Batch  527/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.868, Loss:  0.171
Epoch   2 Batch  528/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.865, Loss:  0.162
Epoch   2 Batch  529/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.867, Loss:  0.146
Epoch   2 Batch  530/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.871, Loss:  0.169
Epoch   2 Batch  531/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.871, Loss:  0.146
Epoch   2 Batch  532/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.874, Loss:  0.173
Epoch   2 Batch  533/1077 - Train Accuracy:  0.851, Validation Accuracy:  0.885, Loss:  0.168
Epoch   2 Batch  534/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.879, Loss:  0.151
Epoch   2 Batch  535/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.872, Loss:  0.158
Epoch   2 Batch  536/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.875, Loss:  0.164
Epoch   2 Batch  537/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.878, Loss:  0.137
Epoch   2 Batch  538/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.878, Loss:  0.135
Epoch   2 Batch  539/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.889, Loss:  0.163
Epoch   2 Batch  540/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.890, Loss:  0.134
Epoch   2 Batch  541/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.896, Loss:  0.148
Epoch   2 Batch  542/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.891, Loss:  0.140
Epoch   2 Batch  543/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.883, Loss:  0.142
Epoch   2 Batch  544/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.886, Loss:  0.130
Epoch   2 Batch  545/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.887, Loss:  0.160
Epoch   2 Batch  546/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.882, Loss:  0.153
Epoch   2 Batch  547/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.887, Loss:  0.135
Epoch   2 Batch  548/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.886, Loss:  0.163
Epoch   2 Batch  549/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.890, Loss:  0.161
Epoch   2 Batch  550/1077 - Train Accuracy:  0.838, Validation Accuracy:  0.887, Loss:  0.140
Epoch   2 Batch  551/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.881, Loss:  0.144
Epoch   2 Batch  552/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.881, Loss:  0.150
Epoch   2 Batch  553/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.881, Loss:  0.148
Epoch   2 Batch  554/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.888, Loss:  0.142
Epoch   2 Batch  555/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.893, Loss:  0.131
Epoch   2 Batch  556/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.897, Loss:  0.127
Epoch   2 Batch  557/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.900, Loss:  0.136
Epoch   2 Batch  558/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.895, Loss:  0.120
Epoch   2 Batch  559/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.898, Loss:  0.143
Epoch   2 Batch  560/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.898, Loss:  0.135
Epoch   2 Batch  561/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.899, Loss:  0.129
Epoch   2 Batch  562/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.905, Loss:  0.124
Epoch   2 Batch  563/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.901, Loss:  0.143
Epoch   2 Batch  564/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.900, Loss:  0.151
Epoch   2 Batch  565/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.876, Loss:  0.135
Epoch   2 Batch  566/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.869, Loss:  0.138
Epoch   2 Batch  567/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.873, Loss:  0.139
Epoch   2 Batch  568/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.875, Loss:  0.134
Epoch   2 Batch  569/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.877, Loss:  0.154
Epoch   2 Batch  570/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.881, Loss:  0.147
Epoch   2 Batch  571/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.883, Loss:  0.119
Epoch   2 Batch  572/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.874, Loss:  0.131
Epoch   2 Batch  573/1077 - Train Accuracy:  0.827, Validation Accuracy:  0.884, Loss:  0.165
Epoch   2 Batch  574/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.891, Loss:  0.151
Epoch   2 Batch  575/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.868, Loss:  0.127
Epoch   2 Batch  576/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.868, Loss:  0.136
Epoch   2 Batch  577/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.868, Loss:  0.143
Epoch   2 Batch  578/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.866, Loss:  0.139
Epoch   2 Batch  579/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.871, Loss:  0.140
Epoch   2 Batch  580/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.886, Loss:  0.118
Epoch   2 Batch  581/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.900, Loss:  0.116
Epoch   2 Batch  582/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.898, Loss:  0.135
Epoch   2 Batch  583/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.894, Loss:  0.149
Epoch   2 Batch  584/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.902, Loss:  0.123
Epoch   2 Batch  585/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.888, Loss:  0.107
Epoch   2 Batch  586/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.887, Loss:  0.128
Epoch   2 Batch  587/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.886, Loss:  0.158
Epoch   2 Batch  588/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.878, Loss:  0.137
Epoch   2 Batch  589/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.874, Loss:  0.143
Epoch   2 Batch  590/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.878, Loss:  0.143
Epoch   2 Batch  591/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.876, Loss:  0.124
Epoch   2 Batch  592/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.878, Loss:  0.140
Epoch   2 Batch  593/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.884, Loss:  0.132
Epoch   2 Batch  594/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.886, Loss:  0.154
Epoch   2 Batch  595/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.877, Loss:  0.127
Epoch   2 Batch  596/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.882, Loss:  0.149
Epoch   2 Batch  597/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.879, Loss:  0.142
Epoch   2 Batch  598/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.876, Loss:  0.135
Epoch   2 Batch  599/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.882, Loss:  0.175
Epoch   2 Batch  600/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.879, Loss:  0.139
Epoch   2 Batch  601/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.875, Loss:  0.138
Epoch   2 Batch  602/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.876, Loss:  0.139
Epoch   2 Batch  603/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.870, Loss:  0.159
Epoch   2 Batch  604/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.870, Loss:  0.178
Epoch   2 Batch  605/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.874, Loss:  0.173
Epoch   2 Batch  606/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.872, Loss:  0.121
Epoch   2 Batch  607/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.879, Loss:  0.135
Epoch   2 Batch  608/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.881, Loss:  0.151
Epoch   2 Batch  609/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.886, Loss:  0.140
Epoch   2 Batch  610/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.889, Loss:  0.155
Epoch   2 Batch  611/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.884, Loss:  0.119
Epoch   2 Batch  612/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.888, Loss:  0.119
Epoch   2 Batch  613/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.887, Loss:  0.139
Epoch   2 Batch  614/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.893, Loss:  0.132
Epoch   2 Batch  615/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.885, Loss:  0.139
Epoch   2 Batch  616/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.886, Loss:  0.159
Epoch   2 Batch  617/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.886, Loss:  0.129
Epoch   2 Batch  618/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.872, Loss:  0.135
Epoch   2 Batch  619/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.854, Loss:  0.136
Epoch   2 Batch  620/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.860, Loss:  0.127
Epoch   2 Batch  621/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.867, Loss:  0.128
Epoch   2 Batch  622/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.879, Loss:  0.154
Epoch   2 Batch  623/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.879, Loss:  0.151
Epoch   2 Batch  624/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.880, Loss:  0.144
Epoch   2 Batch  625/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.880, Loss:  0.135
Epoch   2 Batch  626/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.882, Loss:  0.137
Epoch   2 Batch  627/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.890, Loss:  0.128
Epoch   2 Batch  628/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.892, Loss:  0.154
Epoch   2 Batch  629/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.893, Loss:  0.156
Epoch   2 Batch  630/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.893, Loss:  0.120
Epoch   2 Batch  631/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.880, Loss:  0.131
Epoch   2 Batch  632/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.881, Loss:  0.114
Epoch   2 Batch  633/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.875, Loss:  0.154
Epoch   2 Batch  634/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.879, Loss:  0.107
Epoch   2 Batch  635/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.878, Loss:  0.157
Epoch   2 Batch  636/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.884, Loss:  0.119
Epoch   2 Batch  637/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.882, Loss:  0.137
Epoch   2 Batch  638/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.886, Loss:  0.128
Epoch   2 Batch  639/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.891, Loss:  0.154
Epoch   2 Batch  640/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.887, Loss:  0.121
Epoch   2 Batch  641/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.871, Loss:  0.115
Epoch   2 Batch  642/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.868, Loss:  0.136
Epoch   2 Batch  643/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.866, Loss:  0.150
Epoch   2 Batch  644/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.873, Loss:  0.139
Epoch   2 Batch  645/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.882, Loss:  0.143
Epoch   2 Batch  646/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.895, Loss:  0.138
Epoch   2 Batch  647/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.885, Loss:  0.140
Epoch   2 Batch  648/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.879, Loss:  0.131
Epoch   2 Batch  649/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.898, Loss:  0.153
Epoch   2 Batch  650/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.897, Loss:  0.128
Epoch   2 Batch  651/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.902, Loss:  0.124
Epoch   2 Batch  652/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.901, Loss:  0.143
Epoch   2 Batch  653/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.908, Loss:  0.139
Epoch   2 Batch  654/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.895, Loss:  0.117
Epoch   2 Batch  655/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.897, Loss:  0.147
Epoch   2 Batch  656/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.891, Loss:  0.151
Epoch   2 Batch  657/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.882, Loss:  0.146
Epoch   2 Batch  658/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.871, Loss:  0.122
Epoch   2 Batch  659/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.870, Loss:  0.135
Epoch   2 Batch  660/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.867, Loss:  0.137
Epoch   2 Batch  661/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.869, Loss:  0.117
Epoch   2 Batch  662/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.871, Loss:  0.123
Epoch   2 Batch  663/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.868, Loss:  0.136
Epoch   2 Batch  664/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.870, Loss:  0.128
Epoch   2 Batch  665/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.875, Loss:  0.102
Epoch   2 Batch  666/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.862, Loss:  0.142
Epoch   2 Batch  667/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.866, Loss:  0.150
Epoch   2 Batch  668/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.869, Loss:  0.128
Epoch   2 Batch  669/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.869, Loss:  0.136
Epoch   2 Batch  670/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.858, Loss:  0.157
Epoch   2 Batch  671/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.860, Loss:  0.137
Epoch   2 Batch  672/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.867, Loss:  0.118
Epoch   2 Batch  673/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.879, Loss:  0.126
Epoch   2 Batch  674/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.882, Loss:  0.127
Epoch   2 Batch  675/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.886, Loss:  0.153
Epoch   2 Batch  676/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.892, Loss:  0.115
Epoch   2 Batch  677/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.888, Loss:  0.152
Epoch   2 Batch  678/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.886, Loss:  0.121
Epoch   2 Batch  679/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.888, Loss:  0.138
Epoch   2 Batch  680/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.890, Loss:  0.127
Epoch   2 Batch  681/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.892, Loss:  0.130
Epoch   2 Batch  682/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.891, Loss:  0.125
Epoch   2 Batch  683/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.888, Loss:  0.134
Epoch   2 Batch  684/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.887, Loss:  0.143
Epoch   2 Batch  685/1077 - Train Accuracy:  0.844, Validation Accuracy:  0.881, Loss:  0.135
Epoch   2 Batch  686/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.879, Loss:  0.119
Epoch   2 Batch  687/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.888, Loss:  0.136
Epoch   2 Batch  688/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.893, Loss:  0.124
Epoch   2 Batch  689/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.884, Loss:  0.091
Epoch   2 Batch  690/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.885, Loss:  0.126
Epoch   2 Batch  691/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.886, Loss:  0.147
Epoch   2 Batch  692/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.896, Loss:  0.109
Epoch   2 Batch  693/1077 - Train Accuracy:  0.837, Validation Accuracy:  0.890, Loss:  0.168
Epoch   2 Batch  694/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.886, Loss:  0.137
Epoch   2 Batch  695/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.886, Loss:  0.124
Epoch   2 Batch  696/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.891, Loss:  0.139
Epoch   2 Batch  697/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.900, Loss:  0.122
Epoch   2 Batch  698/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.904, Loss:  0.120
Epoch   2 Batch  699/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.913, Loss:  0.114
Epoch   2 Batch  700/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.903, Loss:  0.107
Epoch   2 Batch  701/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.908, Loss:  0.142
Epoch   2 Batch  702/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.905, Loss:  0.135
Epoch   2 Batch  703/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.901, Loss:  0.115
Epoch   2 Batch  704/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.896, Loss:  0.163
Epoch   2 Batch  705/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.907, Loss:  0.144
Epoch   2 Batch  706/1077 - Train Accuracy:  0.845, Validation Accuracy:  0.900, Loss:  0.167
Epoch   2 Batch  707/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.907, Loss:  0.134
Epoch   2 Batch  708/1077 - Train Accuracy:  0.862, Validation Accuracy:  0.912, Loss:  0.134
Epoch   2 Batch  709/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.909, Loss:  0.148
Epoch   2 Batch  710/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.904, Loss:  0.111
Epoch   2 Batch  711/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.907, Loss:  0.139
Epoch   2 Batch  712/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.889, Loss:  0.117
Epoch   2 Batch  713/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.888, Loss:  0.091
Epoch   2 Batch  714/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.893, Loss:  0.158
Epoch   2 Batch  715/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.887, Loss:  0.142
Epoch   2 Batch  716/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.879, Loss:  0.100
Epoch   2 Batch  717/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.896, Loss:  0.147
Epoch   2 Batch  718/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.895, Loss:  0.125
Epoch   2 Batch  719/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.893, Loss:  0.115
Epoch   2 Batch  720/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.901, Loss:  0.143
Epoch   2 Batch  721/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.903, Loss:  0.176
Epoch   2 Batch  722/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.899, Loss:  0.135
Epoch   2 Batch  723/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.891, Loss:  0.123
Epoch   2 Batch  724/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.895, Loss:  0.137
Epoch   2 Batch  725/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.894, Loss:  0.108
Epoch   2 Batch  726/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.895, Loss:  0.143
Epoch   2 Batch  727/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.893, Loss:  0.135
Epoch   2 Batch  728/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.880, Loss:  0.148
Epoch   2 Batch  729/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.877, Loss:  0.139
Epoch   2 Batch  730/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.875, Loss:  0.158
Epoch   2 Batch  731/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.871, Loss:  0.117
Epoch   2 Batch  732/1077 - Train Accuracy:  0.853, Validation Accuracy:  0.875, Loss:  0.156
Epoch   2 Batch  733/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.878, Loss:  0.146
Epoch   2 Batch  734/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.866, Loss:  0.136
Epoch   2 Batch  735/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.868, Loss:  0.125
Epoch   2 Batch  736/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.869, Loss:  0.103
Epoch   2 Batch  737/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.873, Loss:  0.135
Epoch   2 Batch  738/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.873, Loss:  0.104
Epoch   2 Batch  739/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.891, Loss:  0.112
Epoch   2 Batch  740/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.893, Loss:  0.108
Epoch   2 Batch  741/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.897, Loss:  0.144
Epoch   2 Batch  742/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.907, Loss:  0.132
Epoch   2 Batch  743/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.917, Loss:  0.135
Epoch   2 Batch  744/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.909, Loss:  0.127
Epoch   2 Batch  745/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.908, Loss:  0.124
Epoch   2 Batch  746/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.904, Loss:  0.109
Epoch   2 Batch  747/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.903, Loss:  0.100
Epoch   2 Batch  748/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.896, Loss:  0.107
Epoch   2 Batch  749/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.897, Loss:  0.117
Epoch   2 Batch  750/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.902, Loss:  0.111
Epoch   2 Batch  751/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.901, Loss:  0.125
Epoch   2 Batch  752/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.893, Loss:  0.110
Epoch   2 Batch  753/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.888, Loss:  0.119
Epoch   2 Batch  754/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.863, Loss:  0.125
Epoch   2 Batch  755/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.868, Loss:  0.109
Epoch   2 Batch  756/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.870, Loss:  0.112
Epoch   2 Batch  757/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.871, Loss:  0.119
Epoch   2 Batch  758/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.890, Loss:  0.109
Epoch   2 Batch  759/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.891, Loss:  0.126
Epoch   2 Batch  760/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.895, Loss:  0.122
Epoch   2 Batch  761/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.896, Loss:  0.116
Epoch   2 Batch  762/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.897, Loss:  0.114
Epoch   2 Batch  763/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.897, Loss:  0.101
Epoch   2 Batch  764/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.896, Loss:  0.107
Epoch   2 Batch  765/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.892, Loss:  0.116
Epoch   2 Batch  766/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.886, Loss:  0.115
Epoch   2 Batch  767/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.891, Loss:  0.097
Epoch   2 Batch  768/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.901, Loss:  0.118
Epoch   2 Batch  769/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.904, Loss:  0.119
Epoch   2 Batch  770/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.906, Loss:  0.106
Epoch   2 Batch  771/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.898, Loss:  0.134
Epoch   2 Batch  772/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.899, Loss:  0.093
Epoch   2 Batch  773/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.901, Loss:  0.120
Epoch   2 Batch  774/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.906, Loss:  0.127
Epoch   2 Batch  775/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.912, Loss:  0.127
Epoch   2 Batch  776/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.914, Loss:  0.104
Epoch   2 Batch  777/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.916, Loss:  0.138
Epoch   2 Batch  778/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.911, Loss:  0.109
Epoch   2 Batch  779/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.904, Loss:  0.129
Epoch   2 Batch  780/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.897, Loss:  0.154
Epoch   2 Batch  781/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.877, Loss:  0.098
Epoch   2 Batch  782/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.874, Loss:  0.113
Epoch   2 Batch  783/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.869, Loss:  0.123
Epoch   2 Batch  784/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.881, Loss:  0.101
Epoch   2 Batch  785/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.877, Loss:  0.124
Epoch   2 Batch  786/1077 - Train Accuracy:  0.847, Validation Accuracy:  0.875, Loss:  0.120
Epoch   2 Batch  787/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.880, Loss:  0.099
Epoch   2 Batch  788/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.879, Loss:  0.105
Epoch   2 Batch  789/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.876, Loss:  0.122
Epoch   2 Batch  790/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.880, Loss:  0.123
Epoch   2 Batch  791/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.882, Loss:  0.128
Epoch   2 Batch  792/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.884, Loss:  0.130
Epoch   2 Batch  793/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.879, Loss:  0.123
Epoch   2 Batch  794/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.885, Loss:  0.096
Epoch   2 Batch  795/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.884, Loss:  0.129
Epoch   2 Batch  796/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.886, Loss:  0.114
Epoch   2 Batch  797/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.887, Loss:  0.116
Epoch   2 Batch  798/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.906, Loss:  0.124
Epoch   2 Batch  799/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.901, Loss:  0.138
Epoch   2 Batch  800/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.901, Loss:  0.114
Epoch   2 Batch  801/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.904, Loss:  0.125
Epoch   2 Batch  802/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.911, Loss:  0.125
Epoch   2 Batch  803/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.910, Loss:  0.129
Epoch   2 Batch  804/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.911, Loss:  0.095
Epoch   2 Batch  805/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.910, Loss:  0.115
Epoch   2 Batch  806/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.890, Loss:  0.110
Epoch   2 Batch  807/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.892, Loss:  0.115
Epoch   2 Batch  808/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.891, Loss:  0.152
Epoch   2 Batch  809/1077 - Train Accuracy:  0.833, Validation Accuracy:  0.892, Loss:  0.166
Epoch   2 Batch  810/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.900, Loss:  0.103
Epoch   2 Batch  811/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.903, Loss:  0.124
Epoch   2 Batch  812/1077 - Train Accuracy:  0.860, Validation Accuracy:  0.902, Loss:  0.123
Epoch   2 Batch  813/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.897, Loss:  0.114
Epoch   2 Batch  814/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.894, Loss:  0.136
Epoch   2 Batch  815/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.895, Loss:  0.120
Epoch   2 Batch  816/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.895, Loss:  0.133
Epoch   2 Batch  817/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.896, Loss:  0.129
Epoch   2 Batch  818/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.884, Loss:  0.132
Epoch   2 Batch  819/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.882, Loss:  0.117
Epoch   2 Batch  820/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.886, Loss:  0.109
Epoch   2 Batch  821/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.886, Loss:  0.123
Epoch   2 Batch  822/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.880, Loss:  0.135
Epoch   2 Batch  823/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.883, Loss:  0.115
Epoch   2 Batch  824/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.871, Loss:  0.123
Epoch   2 Batch  825/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.881, Loss:  0.108
Epoch   2 Batch  826/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.884, Loss:  0.103
Epoch   2 Batch  827/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.888, Loss:  0.125
Epoch   2 Batch  828/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.898, Loss:  0.122
Epoch   2 Batch  829/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.896, Loss:  0.142
Epoch   2 Batch  830/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.897, Loss:  0.114
Epoch   2 Batch  831/1077 - Train Accuracy:  0.846, Validation Accuracy:  0.897, Loss:  0.115
Epoch   2 Batch  832/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.905, Loss:  0.113
Epoch   2 Batch  833/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.912, Loss:  0.118
Epoch   2 Batch  834/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.912, Loss:  0.118
Epoch   2 Batch  835/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.909, Loss:  0.112
Epoch   2 Batch  836/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.910, Loss:  0.125
Epoch   2 Batch  837/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.909, Loss:  0.136
Epoch   2 Batch  838/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.902, Loss:  0.114
Epoch   2 Batch  839/1077 - Train Accuracy:  0.868, Validation Accuracy:  0.906, Loss:  0.106
Epoch   2 Batch  840/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.898, Loss:  0.107
Epoch   2 Batch  841/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.895, Loss:  0.140
Epoch   2 Batch  842/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.898, Loss:  0.107
Epoch   2 Batch  843/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.901, Loss:  0.107
Epoch   2 Batch  844/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.902, Loss:  0.112
Epoch   2 Batch  845/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.909, Loss:  0.114
Epoch   2 Batch  846/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.903, Loss:  0.144
Epoch   2 Batch  847/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.900, Loss:  0.134
Epoch   2 Batch  848/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.903, Loss:  0.110
Epoch   2 Batch  849/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.912, Loss:  0.109
Epoch   2 Batch  850/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.908, Loss:  0.146
Epoch   2 Batch  851/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.908, Loss:  0.119
Epoch   2 Batch  852/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.910, Loss:  0.138
Epoch   2 Batch  853/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.908, Loss:  0.112
Epoch   2 Batch  854/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.899, Loss:  0.115
Epoch   2 Batch  855/1077 - Train Accuracy:  0.850, Validation Accuracy:  0.896, Loss:  0.122
Epoch   2 Batch  856/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.896, Loss:  0.125
Epoch   2 Batch  857/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.898, Loss:  0.105
Epoch   2 Batch  858/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.895, Loss:  0.107
Epoch   2 Batch  859/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.890, Loss:  0.143
Epoch   2 Batch  860/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.895, Loss:  0.133
Epoch   2 Batch  861/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.903, Loss:  0.117
Epoch   2 Batch  862/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.898, Loss:  0.121
Epoch   2 Batch  863/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.896, Loss:  0.109
Epoch   2 Batch  864/1077 - Train Accuracy:  0.852, Validation Accuracy:  0.899, Loss:  0.131
Epoch   2 Batch  865/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.888, Loss:  0.112
Epoch   2 Batch  866/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.879, Loss:  0.127
Epoch   2 Batch  867/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.885, Loss:  0.172
Epoch   2 Batch  868/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.884, Loss:  0.113
Epoch   2 Batch  869/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.887, Loss:  0.118
Epoch   2 Batch  870/1077 - Train Accuracy:  0.830, Validation Accuracy:  0.894, Loss:  0.124
Epoch   2 Batch  871/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.894, Loss:  0.111
Epoch   2 Batch  872/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.897, Loss:  0.109
Epoch   2 Batch  873/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.887, Loss:  0.134
Epoch   2 Batch  874/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.873, Loss:  0.132
Epoch   2 Batch  875/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.871, Loss:  0.107
Epoch   2 Batch  876/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.865, Loss:  0.111
Epoch   2 Batch  877/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.870, Loss:  0.099
Epoch   2 Batch  878/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.880, Loss:  0.118
Epoch   2 Batch  879/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.882, Loss:  0.096
Epoch   2 Batch  880/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.884, Loss:  0.114
Epoch   2 Batch  881/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.888, Loss:  0.120
Epoch   2 Batch  882/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.888, Loss:  0.115
Epoch   2 Batch  883/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.895, Loss:  0.175
Epoch   2 Batch  884/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.891, Loss:  0.108
Epoch   2 Batch  885/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.894, Loss:  0.087
Epoch   2 Batch  886/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.902, Loss:  0.108
Epoch   2 Batch  887/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.891, Loss:  0.124
Epoch   2 Batch  888/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.885, Loss:  0.108
Epoch   2 Batch  889/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.885, Loss:  0.105
Epoch   2 Batch  890/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.888, Loss:  0.103
Epoch   2 Batch  891/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.893, Loss:  0.116
Epoch   2 Batch  892/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.893, Loss:  0.099
Epoch   2 Batch  893/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.891, Loss:  0.097
Epoch   2 Batch  894/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.891, Loss:  0.108
Epoch   2 Batch  895/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.890, Loss:  0.095
Epoch   2 Batch  896/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.886, Loss:  0.117
Epoch   2 Batch  897/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.886, Loss:  0.099
Epoch   2 Batch  898/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.885, Loss:  0.086
Epoch   2 Batch  899/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.887, Loss:  0.114
Epoch   2 Batch  900/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.884, Loss:  0.119
Epoch   2 Batch  901/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.884, Loss:  0.144
Epoch   2 Batch  902/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.883, Loss:  0.116
Epoch   2 Batch  903/1077 - Train Accuracy:  0.865, Validation Accuracy:  0.889, Loss:  0.110
Epoch   2 Batch  904/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.893, Loss:  0.105
Epoch   2 Batch  905/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.893, Loss:  0.092
Epoch   2 Batch  906/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.890, Loss:  0.106
Epoch   2 Batch  907/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.892, Loss:  0.101
Epoch   2 Batch  908/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.892, Loss:  0.132
Epoch   2 Batch  909/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.892, Loss:  0.116
Epoch   2 Batch  910/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.887, Loss:  0.116
Epoch   2 Batch  911/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.891, Loss:  0.117
Epoch   2 Batch  912/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.891, Loss:  0.103
Epoch   2 Batch  913/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.885, Loss:  0.129
Epoch   2 Batch  914/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.888, Loss:  0.137
Epoch   2 Batch  915/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.896, Loss:  0.105
Epoch   2 Batch  916/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.898, Loss:  0.125
Epoch   2 Batch  917/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.907, Loss:  0.098
Epoch   2 Batch  918/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.906, Loss:  0.101
Epoch   2 Batch  919/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.896, Loss:  0.100
Epoch   2 Batch  920/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.886, Loss:  0.100
Epoch   2 Batch  921/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.881, Loss:  0.116
Epoch   2 Batch  922/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.882, Loss:  0.127
Epoch   2 Batch  923/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.893, Loss:  0.093
Epoch   2 Batch  924/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.893, Loss:  0.135
Epoch   2 Batch  925/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.897, Loss:  0.093
Epoch   2 Batch  926/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.898, Loss:  0.108
Epoch   2 Batch  927/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.896, Loss:  0.124
Epoch   2 Batch  928/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.891, Loss:  0.116
Epoch   2 Batch  929/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.897, Loss:  0.110
Epoch   2 Batch  930/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.900, Loss:  0.099
Epoch   2 Batch  931/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.904, Loss:  0.099
Epoch   2 Batch  932/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.907, Loss:  0.101
Epoch   2 Batch  933/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.907, Loss:  0.112
Epoch   2 Batch  934/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.898, Loss:  0.098
Epoch   2 Batch  935/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.895, Loss:  0.119
Epoch   2 Batch  936/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.893, Loss:  0.111
Epoch   2 Batch  937/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.891, Loss:  0.119
Epoch   2 Batch  938/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.892, Loss:  0.104
Epoch   2 Batch  939/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.888, Loss:  0.119
Epoch   2 Batch  940/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.881, Loss:  0.090
Epoch   2 Batch  941/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.872, Loss:  0.102
Epoch   2 Batch  942/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.873, Loss:  0.105
Epoch   2 Batch  943/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.870, Loss:  0.111
Epoch   2 Batch  944/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.870, Loss:  0.085
Epoch   2 Batch  945/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.868, Loss:  0.090
Epoch   2 Batch  946/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.872, Loss:  0.103
Epoch   2 Batch  947/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.877, Loss:  0.109
Epoch   2 Batch  948/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.887, Loss:  0.116
Epoch   2 Batch  949/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.886, Loss:  0.083
Epoch   2 Batch  950/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.886, Loss:  0.089
Epoch   2 Batch  951/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.885, Loss:  0.129
Epoch   2 Batch  952/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.886, Loss:  0.081
Epoch   2 Batch  953/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.895, Loss:  0.099
Epoch   2 Batch  954/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.904, Loss:  0.110
Epoch   2 Batch  955/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.904, Loss:  0.104
Epoch   2 Batch  956/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.902, Loss:  0.116
Epoch   2 Batch  957/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.900, Loss:  0.082
Epoch   2 Batch  958/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.892, Loss:  0.107
Epoch   2 Batch  959/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.898, Loss:  0.091
Epoch   2 Batch  960/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.894, Loss:  0.098
Epoch   2 Batch  961/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.886, Loss:  0.087
Epoch   2 Batch  962/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.890, Loss:  0.106
Epoch   2 Batch  963/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.896, Loss:  0.132
Epoch   2 Batch  964/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.900, Loss:  0.095
Epoch   2 Batch  965/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.893, Loss:  0.110
Epoch   2 Batch  966/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.907, Loss:  0.089
Epoch   2 Batch  967/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.901, Loss:  0.104
Epoch   2 Batch  968/1077 - Train Accuracy:  0.859, Validation Accuracy:  0.901, Loss:  0.123
Epoch   2 Batch  969/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.902, Loss:  0.121
Epoch   2 Batch  970/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.892, Loss:  0.113
Epoch   2 Batch  971/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.890, Loss:  0.106
Epoch   2 Batch  972/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.879, Loss:  0.102
Epoch   2 Batch  973/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.881, Loss:  0.088
Epoch   2 Batch  974/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.875, Loss:  0.074
Epoch   2 Batch  975/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.879, Loss:  0.090
Epoch   2 Batch  976/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.885, Loss:  0.102
Epoch   2 Batch  977/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.880, Loss:  0.072
Epoch   2 Batch  978/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.883, Loss:  0.105
Epoch   2 Batch  979/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.883, Loss:  0.118
Epoch   2 Batch  980/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.884, Loss:  0.108
Epoch   2 Batch  981/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.889, Loss:  0.096
Epoch   2 Batch  982/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.893, Loss:  0.116
Epoch   2 Batch  983/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.896, Loss:  0.107
Epoch   2 Batch  984/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.887, Loss:  0.108
Epoch   2 Batch  985/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.891, Loss:  0.089
Epoch   2 Batch  986/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.894, Loss:  0.110
Epoch   2 Batch  987/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.891, Loss:  0.092
Epoch   2 Batch  988/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.878, Loss:  0.108
Epoch   2 Batch  989/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.875, Loss:  0.117
Epoch   2 Batch  990/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.866, Loss:  0.113
Epoch   2 Batch  991/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.859, Loss:  0.102
Epoch   2 Batch  992/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.861, Loss:  0.099
Epoch   2 Batch  993/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.865, Loss:  0.083
Epoch   2 Batch  994/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.874, Loss:  0.098
Epoch   2 Batch  995/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.872, Loss:  0.103
Epoch   2 Batch  996/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.873, Loss:  0.088
Epoch   2 Batch  997/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.873, Loss:  0.108
Epoch   2 Batch  998/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.869, Loss:  0.104
Epoch   2 Batch  999/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.876, Loss:  0.100
Epoch   2 Batch 1000/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.877, Loss:  0.090
Epoch   2 Batch 1001/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.878, Loss:  0.092
Epoch   2 Batch 1002/1077 - Train Accuracy:  0.957, Validation Accuracy:  0.879, Loss:  0.079
Epoch   2 Batch 1003/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.879, Loss:  0.107
Epoch   2 Batch 1004/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.879, Loss:  0.108
Epoch   2 Batch 1005/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.889, Loss:  0.091
Epoch   2 Batch 1006/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.895, Loss:  0.088
Epoch   2 Batch 1007/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.895, Loss:  0.083
Epoch   2 Batch 1008/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.895, Loss:  0.125
Epoch   2 Batch 1009/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.897, Loss:  0.087
Epoch   2 Batch 1010/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.902, Loss:  0.134
Epoch   2 Batch 1011/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.902, Loss:  0.099
Epoch   2 Batch 1012/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.902, Loss:  0.079
Epoch   2 Batch 1013/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.905, Loss:  0.078
Epoch   2 Batch 1014/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.906, Loss:  0.106
Epoch   2 Batch 1015/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.902, Loss:  0.141
Epoch   2 Batch 1016/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.903, Loss:  0.109
Epoch   2 Batch 1017/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.903, Loss:  0.096
Epoch   2 Batch 1018/1077 - Train Accuracy:  0.873, Validation Accuracy:  0.902, Loss:  0.107
Epoch   2 Batch 1019/1077 - Train Accuracy:  0.861, Validation Accuracy:  0.912, Loss:  0.125
Epoch   2 Batch 1020/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.910, Loss:  0.088
Epoch   2 Batch 1021/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.904, Loss:  0.102
Epoch   2 Batch 1022/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.894, Loss:  0.081
Epoch   2 Batch 1023/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.885, Loss:  0.108
Epoch   2 Batch 1024/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.887, Loss:  0.127
Epoch   2 Batch 1025/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.885, Loss:  0.112
Epoch   2 Batch 1026/1077 - Train Accuracy:  0.944, Validation Accuracy:  0.882, Loss:  0.100
Epoch   2 Batch 1027/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.877, Loss:  0.101
Epoch   2 Batch 1028/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.884, Loss:  0.096
Epoch   2 Batch 1029/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.885, Loss:  0.092
Epoch   2 Batch 1030/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.883, Loss:  0.115
Epoch   2 Batch 1031/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.884, Loss:  0.129
Epoch   2 Batch 1032/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.874, Loss:  0.114
Epoch   2 Batch 1033/1077 - Train Accuracy:  0.858, Validation Accuracy:  0.888, Loss:  0.103
Epoch   2 Batch 1034/1077 - Train Accuracy:  0.857, Validation Accuracy:  0.884, Loss:  0.108
Epoch   2 Batch 1035/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.884, Loss:  0.080
Epoch   2 Batch 1036/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.885, Loss:  0.117
Epoch   2 Batch 1037/1077 - Train Accuracy:  0.870, Validation Accuracy:  0.896, Loss:  0.101
Epoch   2 Batch 1038/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.892, Loss:  0.119
Epoch   2 Batch 1039/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.901, Loss:  0.107
Epoch   2 Batch 1040/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.897, Loss:  0.103
Epoch   2 Batch 1041/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.900, Loss:  0.118
Epoch   2 Batch 1042/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.898, Loss:  0.091
Epoch   2 Batch 1043/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.890, Loss:  0.125
Epoch   2 Batch 1044/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.903, Loss:  0.122
Epoch   2 Batch 1045/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.895, Loss:  0.102
Epoch   2 Batch 1046/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.897, Loss:  0.089
Epoch   2 Batch 1047/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.896, Loss:  0.091
Epoch   2 Batch 1048/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.893, Loss:  0.086
Epoch   2 Batch 1049/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.892, Loss:  0.099
Epoch   2 Batch 1050/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.886, Loss:  0.093
Epoch   2 Batch 1051/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.891, Loss:  0.103
Epoch   2 Batch 1052/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.886, Loss:  0.085
Epoch   2 Batch 1053/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.884, Loss:  0.095
Epoch   2 Batch 1054/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.873, Loss:  0.096
Epoch   2 Batch 1055/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.873, Loss:  0.114
Epoch   2 Batch 1056/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.875, Loss:  0.108
Epoch   2 Batch 1057/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.879, Loss:  0.113
Epoch   2 Batch 1058/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.891, Loss:  0.116
Epoch   2 Batch 1059/1077 - Train Accuracy:  0.867, Validation Accuracy:  0.901, Loss:  0.122
Epoch   2 Batch 1060/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.915, Loss:  0.092
Epoch   2 Batch 1061/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.907, Loss:  0.115
Epoch   2 Batch 1062/1077 - Train Accuracy:  0.863, Validation Accuracy:  0.909, Loss:  0.119
Epoch   2 Batch 1063/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.906, Loss:  0.102
Epoch   2 Batch 1064/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.906, Loss:  0.092
Epoch   2 Batch 1065/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.900, Loss:  0.105
Epoch   2 Batch 1066/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.897, Loss:  0.097
Epoch   2 Batch 1067/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.896, Loss:  0.106
Epoch   2 Batch 1068/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.891, Loss:  0.096
Epoch   2 Batch 1069/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.895, Loss:  0.075
Epoch   2 Batch 1070/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.889, Loss:  0.101
Epoch   2 Batch 1071/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.894, Loss:  0.093
Epoch   2 Batch 1072/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.896, Loss:  0.098
Epoch   2 Batch 1073/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.895, Loss:  0.106
Epoch   2 Batch 1074/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.888, Loss:  0.121
Epoch   2 Batch 1075/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.889, Loss:  0.124
Epoch   3 Batch    0/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.889, Loss:  0.084
Epoch   3 Batch    1/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.890, Loss:  0.084
Epoch   3 Batch    2/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.898, Loss:  0.105
Epoch   3 Batch    3/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.902, Loss:  0.106
Epoch   3 Batch    4/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.896, Loss:  0.084
Epoch   3 Batch    5/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.897, Loss:  0.128
Epoch   3 Batch    6/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.893, Loss:  0.110
Epoch   3 Batch    7/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.893, Loss:  0.100
Epoch   3 Batch    8/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.888, Loss:  0.105
Epoch   3 Batch    9/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.902, Loss:  0.094
Epoch   3 Batch   10/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.896, Loss:  0.102
Epoch   3 Batch   11/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.885, Loss:  0.105
Epoch   3 Batch   12/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.882, Loss:  0.095
Epoch   3 Batch   13/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.885, Loss:  0.104
Epoch   3 Batch   14/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.886, Loss:  0.087
Epoch   3 Batch   15/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.886, Loss:  0.098
Epoch   3 Batch   16/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.890, Loss:  0.110
Epoch   3 Batch   17/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.896, Loss:  0.091
Epoch   3 Batch   18/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.904, Loss:  0.085
Epoch   3 Batch   19/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.908, Loss:  0.096
Epoch   3 Batch   20/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.899, Loss:  0.091
Epoch   3 Batch   21/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.901, Loss:  0.106
Epoch   3 Batch   22/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.900, Loss:  0.093
Epoch   3 Batch   23/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.883, Loss:  0.105
Epoch   3 Batch   24/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.884, Loss:  0.084
Epoch   3 Batch   25/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.885, Loss:  0.095
Epoch   3 Batch   26/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.885, Loss:  0.099
Epoch   3 Batch   27/1077 - Train Accuracy:  0.940, Validation Accuracy:  0.880, Loss:  0.077
Epoch   3 Batch   28/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.882, Loss:  0.110
Epoch   3 Batch   29/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.881, Loss:  0.109
Epoch   3 Batch   30/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.896, Loss:  0.091
Epoch   3 Batch   31/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.900, Loss:  0.092
Epoch   3 Batch   32/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.905, Loss:  0.105
Epoch   3 Batch   33/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.898, Loss:  0.099
Epoch   3 Batch   34/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.897, Loss:  0.076
Epoch   3 Batch   35/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.889, Loss:  0.089
Epoch   3 Batch   36/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.888, Loss:  0.098
Epoch   3 Batch   37/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.886, Loss:  0.104
Epoch   3 Batch   38/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.891, Loss:  0.121
Epoch   3 Batch   39/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.900, Loss:  0.107
Epoch   3 Batch   40/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.905, Loss:  0.077
Epoch   3 Batch   41/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.906, Loss:  0.091
Epoch   3 Batch   42/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.905, Loss:  0.095
Epoch   3 Batch   43/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.907, Loss:  0.062
Epoch   3 Batch   44/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.910, Loss:  0.083
Epoch   3 Batch   45/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.896, Loss:  0.087
Epoch   3 Batch   46/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.901, Loss:  0.094
Epoch   3 Batch   47/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.894, Loss:  0.097
Epoch   3 Batch   48/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.897, Loss:  0.134
Epoch   3 Batch   49/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.897, Loss:  0.102
Epoch   3 Batch   50/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.890, Loss:  0.091
Epoch   3 Batch   51/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.890, Loss:  0.103
Epoch   3 Batch   52/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.885, Loss:  0.114
Epoch   3 Batch   53/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.884, Loss:  0.095
Epoch   3 Batch   54/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.880, Loss:  0.129
Epoch   3 Batch   55/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.890, Loss:  0.089
Epoch   3 Batch   56/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.878, Loss:  0.081
Epoch   3 Batch   57/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.881, Loss:  0.090
Epoch   3 Batch   58/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.885, Loss:  0.086
Epoch   3 Batch   59/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.895, Loss:  0.085
Epoch   3 Batch   60/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.894, Loss:  0.081
Epoch   3 Batch   61/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.887, Loss:  0.111
Epoch   3 Batch   62/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.891, Loss:  0.103
Epoch   3 Batch   63/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.897, Loss:  0.072
Epoch   3 Batch   64/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.887, Loss:  0.083
Epoch   3 Batch   65/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.875, Loss:  0.078
Epoch   3 Batch   66/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.886, Loss:  0.069
Epoch   3 Batch   67/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.884, Loss:  0.085
Epoch   3 Batch   68/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.884, Loss:  0.097
Epoch   3 Batch   69/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.887, Loss:  0.119
Epoch   3 Batch   70/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.888, Loss:  0.092
Epoch   3 Batch   71/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.890, Loss:  0.070
Epoch   3 Batch   72/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.893, Loss:  0.089
Epoch   3 Batch   73/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.895, Loss:  0.101
Epoch   3 Batch   74/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.899, Loss:  0.082
Epoch   3 Batch   75/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.892, Loss:  0.105
Epoch   3 Batch   76/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.889, Loss:  0.073
Epoch   3 Batch   77/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.893, Loss:  0.095
Epoch   3 Batch   78/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.897, Loss:  0.090
Epoch   3 Batch   79/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.890, Loss:  0.094
Epoch   3 Batch   80/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.897, Loss:  0.086
Epoch   3 Batch   81/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.893, Loss:  0.081
Epoch   3 Batch   82/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.899, Loss:  0.095
Epoch   3 Batch   83/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.899, Loss:  0.091
Epoch   3 Batch   84/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.902, Loss:  0.085
Epoch   3 Batch   85/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.901, Loss:  0.080
Epoch   3 Batch   86/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.889, Loss:  0.099
Epoch   3 Batch   87/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.884, Loss:  0.114
Epoch   3 Batch   88/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.887, Loss:  0.111
Epoch   3 Batch   89/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.890, Loss:  0.093
Epoch   3 Batch   90/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.884, Loss:  0.112
Epoch   3 Batch   91/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.881, Loss:  0.082
Epoch   3 Batch   92/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.895, Loss:  0.106
Epoch   3 Batch   93/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.895, Loss:  0.086
Epoch   3 Batch   94/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.898, Loss:  0.101
Epoch   3 Batch   95/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.900, Loss:  0.112
Epoch   3 Batch   96/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.898, Loss:  0.091
Epoch   3 Batch   97/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.888, Loss:  0.117
Epoch   3 Batch   98/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.895, Loss:  0.113
Epoch   3 Batch   99/1077 - Train Accuracy:  0.940, Validation Accuracy:  0.888, Loss:  0.084
Epoch   3 Batch  100/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.881, Loss:  0.091
Epoch   3 Batch  101/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.887, Loss:  0.089
Epoch   3 Batch  102/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.895, Loss:  0.090
Epoch   3 Batch  103/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.896, Loss:  0.095
Epoch   3 Batch  104/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.892, Loss:  0.101
Epoch   3 Batch  105/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.891, Loss:  0.085
Epoch   3 Batch  106/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.892, Loss:  0.126
Epoch   3 Batch  107/1077 - Train Accuracy:  0.888, Validation Accuracy:  0.884, Loss:  0.102
Epoch   3 Batch  108/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.887, Loss:  0.100
Epoch   3 Batch  109/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.902, Loss:  0.101
Epoch   3 Batch  110/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.900, Loss:  0.082
Epoch   3 Batch  111/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.903, Loss:  0.103
Epoch   3 Batch  112/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.887, Loss:  0.094
Epoch   3 Batch  113/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.887, Loss:  0.102
Epoch   3 Batch  114/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.887, Loss:  0.085
Epoch   3 Batch  115/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.889, Loss:  0.109
Epoch   3 Batch  116/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.897, Loss:  0.106
Epoch   3 Batch  117/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.885, Loss:  0.086
Epoch   3 Batch  118/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.885, Loss:  0.101
Epoch   3 Batch  119/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.899, Loss:  0.098
Epoch   3 Batch  120/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.900, Loss:  0.115
Epoch   3 Batch  121/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.890, Loss:  0.094
Epoch   3 Batch  122/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.889, Loss:  0.095
Epoch   3 Batch  123/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.898, Loss:  0.096
Epoch   3 Batch  124/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.901, Loss:  0.103
Epoch   3 Batch  125/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.897, Loss:  0.110
Epoch   3 Batch  126/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.893, Loss:  0.098
Epoch   3 Batch  127/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.890, Loss:  0.092
Epoch   3 Batch  128/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.877, Loss:  0.087
Epoch   3 Batch  129/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.865, Loss:  0.121
Epoch   3 Batch  130/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.870, Loss:  0.093
Epoch   3 Batch  131/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.874, Loss:  0.100
Epoch   3 Batch  132/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.879, Loss:  0.092
Epoch   3 Batch  133/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.879, Loss:  0.085
Epoch   3 Batch  134/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.885, Loss:  0.082
Epoch   3 Batch  135/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.882, Loss:  0.104
Epoch   3 Batch  136/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.885, Loss:  0.092
Epoch   3 Batch  137/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.878, Loss:  0.074
Epoch   3 Batch  138/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.896, Loss:  0.110
Epoch   3 Batch  139/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.889, Loss:  0.120
Epoch   3 Batch  140/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.892, Loss:  0.102
Epoch   3 Batch  141/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.888, Loss:  0.117
Epoch   3 Batch  142/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.881, Loss:  0.092
Epoch   3 Batch  143/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.876, Loss:  0.101
Epoch   3 Batch  144/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.877, Loss:  0.142
Epoch   3 Batch  145/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.867, Loss:  0.094
Epoch   3 Batch  146/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.867, Loss:  0.148
Epoch   3 Batch  147/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.876, Loss:  0.106
Epoch   3 Batch  148/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.876, Loss:  0.133
Epoch   3 Batch  149/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.881, Loss:  0.106
Epoch   3 Batch  150/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.882, Loss:  0.119
Epoch   3 Batch  151/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.876, Loss:  0.097
Epoch   3 Batch  152/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.884, Loss:  0.130
Epoch   3 Batch  153/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.892, Loss:  0.104
Epoch   3 Batch  154/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.891, Loss:  0.100
Epoch   3 Batch  155/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.884, Loss:  0.096
Epoch   3 Batch  156/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.873, Loss:  0.083
Epoch   3 Batch  157/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.884, Loss:  0.101
Epoch   3 Batch  158/1077 - Train Accuracy:  0.872, Validation Accuracy:  0.880, Loss:  0.126
Epoch   3 Batch  159/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.887, Loss:  0.081
Epoch   3 Batch  160/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.886, Loss:  0.091
Epoch   3 Batch  161/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.891, Loss:  0.089
Epoch   3 Batch  162/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.891, Loss:  0.116
Epoch   3 Batch  163/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.889, Loss:  0.099
Epoch   3 Batch  164/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.882, Loss:  0.101
Epoch   3 Batch  165/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.876, Loss:  0.081
Epoch   3 Batch  166/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.880, Loss:  0.101
Epoch   3 Batch  167/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.897, Loss:  0.094
Epoch   3 Batch  168/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.895, Loss:  0.105
Epoch   3 Batch  169/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.891, Loss:  0.118
Epoch   3 Batch  170/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.887, Loss:  0.089
Epoch   3 Batch  171/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.883, Loss:  0.096
Epoch   3 Batch  172/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.872, Loss:  0.091
Epoch   3 Batch  173/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.872, Loss:  0.102
Epoch   3 Batch  174/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.867, Loss:  0.087
Epoch   3 Batch  175/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.879, Loss:  0.102
Epoch   3 Batch  176/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.883, Loss:  0.086
Epoch   3 Batch  177/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.875, Loss:  0.111
Epoch   3 Batch  178/1077 - Train Accuracy:  0.874, Validation Accuracy:  0.883, Loss:  0.093
Epoch   3 Batch  179/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.889, Loss:  0.097
Epoch   3 Batch  180/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.891, Loss:  0.085
Epoch   3 Batch  181/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.889, Loss:  0.094
Epoch   3 Batch  182/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.890, Loss:  0.090
Epoch   3 Batch  183/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.885, Loss:  0.088
Epoch   3 Batch  184/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.889, Loss:  0.075
Epoch   3 Batch  185/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.887, Loss:  0.090
Epoch   3 Batch  186/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.883, Loss:  0.100
Epoch   3 Batch  187/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.887, Loss:  0.078
Epoch   3 Batch  188/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.891, Loss:  0.091
Epoch   3 Batch  189/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.887, Loss:  0.095
Epoch   3 Batch  190/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.889, Loss:  0.084
Epoch   3 Batch  191/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.890, Loss:  0.070
Epoch   3 Batch  192/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.886, Loss:  0.094
Epoch   3 Batch  193/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.885, Loss:  0.090
Epoch   3 Batch  194/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.884, Loss:  0.075
Epoch   3 Batch  195/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.887, Loss:  0.074
Epoch   3 Batch  196/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.891, Loss:  0.076
Epoch   3 Batch  197/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.890, Loss:  0.101
Epoch   3 Batch  198/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.884, Loss:  0.079
Epoch   3 Batch  199/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.888, Loss:  0.084
Epoch   3 Batch  200/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.893, Loss:  0.090
Epoch   3 Batch  201/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.893, Loss:  0.091
Epoch   3 Batch  202/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.890, Loss:  0.095
Epoch   3 Batch  203/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.891, Loss:  0.092
Epoch   3 Batch  204/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.893, Loss:  0.107
Epoch   3 Batch  205/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.883, Loss:  0.106
Epoch   3 Batch  206/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.884, Loss:  0.084
Epoch   3 Batch  207/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.885, Loss:  0.077
Epoch   3 Batch  208/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.892, Loss:  0.077
Epoch   3 Batch  209/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.896, Loss:  0.075
Epoch   3 Batch  210/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.892, Loss:  0.103
Epoch   3 Batch  211/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.898, Loss:  0.087
Epoch   3 Batch  212/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.895, Loss:  0.078
Epoch   3 Batch  213/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.891, Loss:  0.075
Epoch   3 Batch  214/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.891, Loss:  0.074
Epoch   3 Batch  215/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.889, Loss:  0.089
Epoch   3 Batch  216/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.879, Loss:  0.093
Epoch   3 Batch  217/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.891, Loss:  0.078
Epoch   3 Batch  218/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.885, Loss:  0.112
Epoch   3 Batch  219/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.884, Loss:  0.077
Epoch   3 Batch  220/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.889, Loss:  0.083
Epoch   3 Batch  221/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.893, Loss:  0.088
Epoch   3 Batch  222/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.893, Loss:  0.093
Epoch   3 Batch  223/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.902, Loss:  0.080
Epoch   3 Batch  224/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.903, Loss:  0.100
Epoch   3 Batch  225/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.914, Loss:  0.110
Epoch   3 Batch  226/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.904, Loss:  0.082
Epoch   3 Batch  227/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.901, Loss:  0.105
Epoch   3 Batch  228/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.900, Loss:  0.084
Epoch   3 Batch  229/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.903, Loss:  0.094
Epoch   3 Batch  230/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.903, Loss:  0.101
Epoch   3 Batch  231/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.902, Loss:  0.097
Epoch   3 Batch  232/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.903, Loss:  0.075
Epoch   3 Batch  233/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.912, Loss:  0.121
Epoch   3 Batch  234/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.909, Loss:  0.102
Epoch   3 Batch  235/1077 - Train Accuracy:  0.883, Validation Accuracy:  0.915, Loss:  0.087
Epoch   3 Batch  236/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.915, Loss:  0.097
Epoch   3 Batch  237/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.906, Loss:  0.070
Epoch   3 Batch  238/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.903, Loss:  0.089
Epoch   3 Batch  239/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.901, Loss:  0.063
Epoch   3 Batch  240/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.905, Loss:  0.079
Epoch   3 Batch  241/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.903, Loss:  0.072
Epoch   3 Batch  242/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.903, Loss:  0.070
Epoch   3 Batch  243/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.911, Loss:  0.086
Epoch   3 Batch  244/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.911, Loss:  0.078
Epoch   3 Batch  245/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.906, Loss:  0.077
Epoch   3 Batch  246/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.898, Loss:  0.082
Epoch   3 Batch  247/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.897, Loss:  0.075
Epoch   3 Batch  248/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.906, Loss:  0.089
Epoch   3 Batch  249/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.917, Loss:  0.088
Epoch   3 Batch  250/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.901, Loss:  0.083
Epoch   3 Batch  251/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.898, Loss:  0.096
Epoch   3 Batch  252/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.903, Loss:  0.087
Epoch   3 Batch  253/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.898, Loss:  0.076
Epoch   3 Batch  254/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.895, Loss:  0.097
Epoch   3 Batch  255/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.895, Loss:  0.096
Epoch   3 Batch  256/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.903, Loss:  0.102
Epoch   3 Batch  257/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.911, Loss:  0.074
Epoch   3 Batch  258/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.909, Loss:  0.075
Epoch   3 Batch  259/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.915, Loss:  0.083
Epoch   3 Batch  260/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.916, Loss:  0.081
Epoch   3 Batch  261/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.916, Loss:  0.083
Epoch   3 Batch  262/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.916, Loss:  0.074
Epoch   3 Batch  263/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.911, Loss:  0.077
Epoch   3 Batch  264/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.911, Loss:  0.084
Epoch   3 Batch  265/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.916, Loss:  0.079
Epoch   3 Batch  266/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.916, Loss:  0.090
Epoch   3 Batch  267/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.911, Loss:  0.087
Epoch   3 Batch  268/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.903, Loss:  0.107
Epoch   3 Batch  269/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.904, Loss:  0.096
Epoch   3 Batch  270/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.901, Loss:  0.099
Epoch   3 Batch  271/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.906, Loss:  0.082
Epoch   3 Batch  272/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.902, Loss:  0.109
Epoch   3 Batch  273/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.891, Loss:  0.080
Epoch   3 Batch  274/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.887, Loss:  0.092
Epoch   3 Batch  275/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.883, Loss:  0.091
Epoch   3 Batch  276/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.883, Loss:  0.110
Epoch   3 Batch  277/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.882, Loss:  0.079
Epoch   3 Batch  278/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.886, Loss:  0.113
Epoch   3 Batch  279/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.891, Loss:  0.097
Epoch   3 Batch  280/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.901, Loss:  0.098
Epoch   3 Batch  281/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.901, Loss:  0.089
Epoch   3 Batch  282/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.898, Loss:  0.108
Epoch   3 Batch  283/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.901, Loss:  0.103
Epoch   3 Batch  284/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.906, Loss:  0.097
Epoch   3 Batch  285/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.907, Loss:  0.094
Epoch   3 Batch  286/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.907, Loss:  0.086
Epoch   3 Batch  287/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.903, Loss:  0.075
Epoch   3 Batch  288/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.903, Loss:  0.098
Epoch   3 Batch  289/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.903, Loss:  0.094
Epoch   3 Batch  290/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.904, Loss:  0.120
Epoch   3 Batch  291/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.909, Loss:  0.107
Epoch   3 Batch  292/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.908, Loss:  0.108
Epoch   3 Batch  293/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.900, Loss:  0.092
Epoch   3 Batch  294/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.895, Loss:  0.090
Epoch   3 Batch  295/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.890, Loss:  0.098
Epoch   3 Batch  296/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.899, Loss:  0.090
Epoch   3 Batch  297/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.895, Loss:  0.094
Epoch   3 Batch  298/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.898, Loss:  0.104
Epoch   3 Batch  299/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.884, Loss:  0.107
Epoch   3 Batch  300/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.891, Loss:  0.072
Epoch   3 Batch  301/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.891, Loss:  0.079
Epoch   3 Batch  302/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.890, Loss:  0.072
Epoch   3 Batch  303/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.890, Loss:  0.090
Epoch   3 Batch  304/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.877, Loss:  0.088
Epoch   3 Batch  305/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.882, Loss:  0.083
Epoch   3 Batch  306/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.891, Loss:  0.093
Epoch   3 Batch  307/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.890, Loss:  0.077
Epoch   3 Batch  308/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.893, Loss:  0.095
Epoch   3 Batch  309/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.893, Loss:  0.070
Epoch   3 Batch  310/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.904, Loss:  0.078
Epoch   3 Batch  311/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.902, Loss:  0.084
Epoch   3 Batch  312/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.897, Loss:  0.108
Epoch   3 Batch  313/1077 - Train Accuracy:  0.947, Validation Accuracy:  0.898, Loss:  0.066
Epoch   3 Batch  314/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.900, Loss:  0.082
Epoch   3 Batch  315/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.900, Loss:  0.079
Epoch   3 Batch  316/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.892, Loss:  0.079
Epoch   3 Batch  317/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.898, Loss:  0.118
Epoch   3 Batch  318/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.888, Loss:  0.078
Epoch   3 Batch  319/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.892, Loss:  0.104
Epoch   3 Batch  320/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.887, Loss:  0.096
Epoch   3 Batch  321/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.887, Loss:  0.082
Epoch   3 Batch  322/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.879, Loss:  0.081
Epoch   3 Batch  323/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.885, Loss:  0.079
Epoch   3 Batch  324/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.889, Loss:  0.073
Epoch   3 Batch  325/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.902, Loss:  0.082
Epoch   3 Batch  326/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.902, Loss:  0.075
Epoch   3 Batch  327/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.898, Loss:  0.088
Epoch   3 Batch  328/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.906, Loss:  0.086
Epoch   3 Batch  329/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.893, Loss:  0.095
Epoch   3 Batch  330/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.888, Loss:  0.085
Epoch   3 Batch  331/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.884, Loss:  0.103
Epoch   3 Batch  332/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.882, Loss:  0.066
Epoch   3 Batch  333/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.886, Loss:  0.093
Epoch   3 Batch  334/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.887, Loss:  0.084
Epoch   3 Batch  335/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.892, Loss:  0.073
Epoch   3 Batch  336/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.902, Loss:  0.118
Epoch   3 Batch  337/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.902, Loss:  0.084
Epoch   3 Batch  338/1077 - Train Accuracy:  0.878, Validation Accuracy:  0.894, Loss:  0.091
Epoch   3 Batch  339/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.895, Loss:  0.074
Epoch   3 Batch  340/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.892, Loss:  0.085
Epoch   3 Batch  341/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.896, Loss:  0.107
Epoch   3 Batch  342/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.891, Loss:  0.079
Epoch   3 Batch  343/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.891, Loss:  0.082
Epoch   3 Batch  344/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.888, Loss:  0.074
Epoch   3 Batch  345/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.879, Loss:  0.062
Epoch   3 Batch  346/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.884, Loss:  0.084
Epoch   3 Batch  347/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.871, Loss:  0.073
Epoch   3 Batch  348/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.871, Loss:  0.077
Epoch   3 Batch  349/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.884, Loss:  0.077
Epoch   3 Batch  350/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.876, Loss:  0.088
Epoch   3 Batch  351/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.881, Loss:  0.082
Epoch   3 Batch  352/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.877, Loss:  0.072
Epoch   3 Batch  353/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.883, Loss:  0.096
Epoch   3 Batch  354/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.893, Loss:  0.100
Epoch   3 Batch  355/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.897, Loss:  0.080
Epoch   3 Batch  356/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.891, Loss:  0.075
Epoch   3 Batch  357/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.896, Loss:  0.072
Epoch   3 Batch  358/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.900, Loss:  0.096
Epoch   3 Batch  359/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.896, Loss:  0.085
Epoch   3 Batch  360/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.906, Loss:  0.069
Epoch   3 Batch  361/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.904, Loss:  0.070
Epoch   3 Batch  362/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.898, Loss:  0.079
Epoch   3 Batch  363/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.892, Loss:  0.080
Epoch   3 Batch  364/1077 - Train Accuracy:  0.882, Validation Accuracy:  0.891, Loss:  0.087
Epoch   3 Batch  365/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.896, Loss:  0.062
Epoch   3 Batch  366/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.884, Loss:  0.064
Epoch   3 Batch  367/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.885, Loss:  0.061
Epoch   3 Batch  368/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.889, Loss:  0.093
Epoch   3 Batch  369/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.888, Loss:  0.078
Epoch   3 Batch  370/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.893, Loss:  0.085
Epoch   3 Batch  371/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.894, Loss:  0.067
Epoch   3 Batch  372/1077 - Train Accuracy:  0.946, Validation Accuracy:  0.888, Loss:  0.062
Epoch   3 Batch  373/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.887, Loss:  0.073
Epoch   3 Batch  374/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.884, Loss:  0.085
Epoch   3 Batch  375/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.893, Loss:  0.078
Epoch   3 Batch  376/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.887, Loss:  0.092
Epoch   3 Batch  377/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.890, Loss:  0.075
Epoch   3 Batch  378/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.894, Loss:  0.064
Epoch   3 Batch  379/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.887, Loss:  0.099
Epoch   3 Batch  380/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.891, Loss:  0.077
Epoch   3 Batch  381/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.895, Loss:  0.093
Epoch   3 Batch  382/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.895, Loss:  0.113
Epoch   3 Batch  383/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.900, Loss:  0.085
Epoch   3 Batch  384/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.895, Loss:  0.083
Epoch   3 Batch  385/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.895, Loss:  0.068
Epoch   3 Batch  386/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.897, Loss:  0.079
Epoch   3 Batch  387/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.897, Loss:  0.085
Epoch   3 Batch  388/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.904, Loss:  0.086
Epoch   3 Batch  389/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.904, Loss:  0.078
Epoch   3 Batch  390/1077 - Train Accuracy:  0.871, Validation Accuracy:  0.911, Loss:  0.089
Epoch   3 Batch  391/1077 - Train Accuracy:  0.946, Validation Accuracy:  0.911, Loss:  0.075
Epoch   3 Batch  392/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.909, Loss:  0.094
Epoch   3 Batch  393/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.902, Loss:  0.070
Epoch   3 Batch  394/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.902, Loss:  0.077
Epoch   3 Batch  395/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.902, Loss:  0.084
Epoch   3 Batch  396/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.900, Loss:  0.079
Epoch   3 Batch  397/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.896, Loss:  0.069
Epoch   3 Batch  398/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.897, Loss:  0.085
Epoch   3 Batch  399/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.895, Loss:  0.073
Epoch   3 Batch  400/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.889, Loss:  0.106
Epoch   3 Batch  401/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.890, Loss:  0.079
Epoch   3 Batch  402/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.900, Loss:  0.078
Epoch   3 Batch  403/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.901, Loss:  0.096
Epoch   3 Batch  404/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.902, Loss:  0.075
Epoch   3 Batch  405/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.896, Loss:  0.085
Epoch   3 Batch  406/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.892, Loss:  0.081
Epoch   3 Batch  407/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.900, Loss:  0.084
Epoch   3 Batch  408/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.900, Loss:  0.075
Epoch   3 Batch  409/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.905, Loss:  0.092
Epoch   3 Batch  410/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.904, Loss:  0.089
Epoch   3 Batch  411/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.894, Loss:  0.092
Epoch   3 Batch  412/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.894, Loss:  0.065
Epoch   3 Batch  413/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.894, Loss:  0.077
Epoch   3 Batch  414/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.900, Loss:  0.082
Epoch   3 Batch  415/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.887, Loss:  0.098
Epoch   3 Batch  416/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.886, Loss:  0.078
Epoch   3 Batch  417/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.887, Loss:  0.114
Epoch   3 Batch  418/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.886, Loss:  0.079
Epoch   3 Batch  419/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.886, Loss:  0.072
Epoch   3 Batch  420/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.888, Loss:  0.071
Epoch   3 Batch  421/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.890, Loss:  0.092
Epoch   3 Batch  422/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.895, Loss:  0.076
Epoch   3 Batch  423/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.897, Loss:  0.099
Epoch   3 Batch  424/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.904, Loss:  0.084
Epoch   3 Batch  425/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.910, Loss:  0.062
Epoch   3 Batch  426/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.917, Loss:  0.104
Epoch   3 Batch  427/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.921, Loss:  0.069
Epoch   3 Batch  428/1077 - Train Accuracy:  0.944, Validation Accuracy:  0.917, Loss:  0.072
Epoch   3 Batch  429/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.912, Loss:  0.072
Epoch   3 Batch  430/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.911, Loss:  0.071
Epoch   3 Batch  431/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.902, Loss:  0.075
Epoch   3 Batch  432/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.907, Loss:  0.088
Epoch   3 Batch  433/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.907, Loss:  0.086
Epoch   3 Batch  434/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.907, Loss:  0.082
Epoch   3 Batch  435/1077 - Train Accuracy:  0.948, Validation Accuracy:  0.902, Loss:  0.089
Epoch   3 Batch  436/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.895, Loss:  0.082
Epoch   3 Batch  437/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.893, Loss:  0.076
Epoch   3 Batch  438/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.886, Loss:  0.076
Epoch   3 Batch  439/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.886, Loss:  0.113
Epoch   3 Batch  440/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.896, Loss:  0.105
Epoch   3 Batch  441/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.886, Loss:  0.078
Epoch   3 Batch  442/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.874, Loss:  0.088
Epoch   3 Batch  443/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.869, Loss:  0.073
Epoch   3 Batch  444/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.874, Loss:  0.082
Epoch   3 Batch  445/1077 - Train Accuracy:  0.877, Validation Accuracy:  0.888, Loss:  0.088
Epoch   3 Batch  446/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.883, Loss:  0.062
Epoch   3 Batch  447/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.869, Loss:  0.071
Epoch   3 Batch  448/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.859, Loss:  0.106
Epoch   3 Batch  449/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.860, Loss:  0.088
Epoch   3 Batch  450/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.862, Loss:  0.083
Epoch   3 Batch  451/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.867, Loss:  0.083
Epoch   3 Batch  452/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.870, Loss:  0.077
Epoch   3 Batch  453/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.869, Loss:  0.085
Epoch   3 Batch  454/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.882, Loss:  0.094
Epoch   3 Batch  455/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.883, Loss:  0.095
Epoch   3 Batch  456/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.884, Loss:  0.075
Epoch   3 Batch  457/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.895, Loss:  0.054
Epoch   3 Batch  458/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.895, Loss:  0.101
Epoch   3 Batch  459/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.896, Loss:  0.089
Epoch   3 Batch  460/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.896, Loss:  0.082
Epoch   3 Batch  461/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.884, Loss:  0.075
Epoch   3 Batch  462/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.883, Loss:  0.076
Epoch   3 Batch  463/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.886, Loss:  0.080
Epoch   3 Batch  464/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.887, Loss:  0.081
Epoch   3 Batch  465/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.879, Loss:  0.090
Epoch   3 Batch  466/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.887, Loss:  0.074
Epoch   3 Batch  467/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.887, Loss:  0.078
Epoch   3 Batch  468/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.878, Loss:  0.087
Epoch   3 Batch  469/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.878, Loss:  0.080
Epoch   3 Batch  470/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.881, Loss:  0.090
Epoch   3 Batch  471/1077 - Train Accuracy:  0.954, Validation Accuracy:  0.881, Loss:  0.059
Epoch   3 Batch  472/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.881, Loss:  0.072
Epoch   3 Batch  473/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.880, Loss:  0.082
Epoch   3 Batch  474/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.881, Loss:  0.072
Epoch   3 Batch  475/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.881, Loss:  0.066
Epoch   3 Batch  476/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.873, Loss:  0.067
Epoch   3 Batch  477/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.873, Loss:  0.093
Epoch   3 Batch  478/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.871, Loss:  0.086
Epoch   3 Batch  479/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.874, Loss:  0.098
Epoch   3 Batch  480/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.875, Loss:  0.085
Epoch   3 Batch  481/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.879, Loss:  0.079
Epoch   3 Batch  482/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.877, Loss:  0.095
Epoch   3 Batch  483/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.877, Loss:  0.073
Epoch   3 Batch  484/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.881, Loss:  0.089
Epoch   3 Batch  485/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.883, Loss:  0.080
Epoch   3 Batch  486/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.883, Loss:  0.087
Epoch   3 Batch  487/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.897, Loss:  0.078
Epoch   3 Batch  488/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.892, Loss:  0.087
Epoch   3 Batch  489/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.893, Loss:  0.064
Epoch   3 Batch  490/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.893, Loss:  0.089
Epoch   3 Batch  491/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.892, Loss:  0.087
Epoch   3 Batch  492/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.900, Loss:  0.103
Epoch   3 Batch  493/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.891, Loss:  0.072
Epoch   3 Batch  494/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.890, Loss:  0.068
Epoch   3 Batch  495/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.893, Loss:  0.084
Epoch   3 Batch  496/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.891, Loss:  0.080
Epoch   3 Batch  497/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.882, Loss:  0.082
Epoch   3 Batch  498/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.877, Loss:  0.084
Epoch   3 Batch  499/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.881, Loss:  0.072
Epoch   3 Batch  500/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.895, Loss:  0.072
Epoch   3 Batch  501/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.892, Loss:  0.067
Epoch   3 Batch  502/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.883, Loss:  0.095
Epoch   3 Batch  503/1077 - Train Accuracy:  0.944, Validation Accuracy:  0.883, Loss:  0.085
Epoch   3 Batch  504/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.888, Loss:  0.074
Epoch   3 Batch  505/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.894, Loss:  0.063
Epoch   3 Batch  506/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.895, Loss:  0.080
Epoch   3 Batch  507/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.884, Loss:  0.081
Epoch   3 Batch  508/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.881, Loss:  0.067
Epoch   3 Batch  509/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.883, Loss:  0.086
Epoch   3 Batch  510/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.899, Loss:  0.099
Epoch   3 Batch  511/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.905, Loss:  0.085
Epoch   3 Batch  512/1077 - Train Accuracy:  0.949, Validation Accuracy:  0.898, Loss:  0.079
Epoch   3 Batch  513/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.902, Loss:  0.094
Epoch   3 Batch  514/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.903, Loss:  0.073
Epoch   3 Batch  515/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.898, Loss:  0.074
Epoch   3 Batch  516/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.896, Loss:  0.094
Epoch   3 Batch  517/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.900, Loss:  0.086
Epoch   3 Batch  518/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.896, Loss:  0.074
Epoch   3 Batch  519/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.900, Loss:  0.079
Epoch   3 Batch  520/1077 - Train Accuracy:  0.949, Validation Accuracy:  0.906, Loss:  0.075
Epoch   3 Batch  521/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.901, Loss:  0.082
Epoch   3 Batch  522/1077 - Train Accuracy:  0.864, Validation Accuracy:  0.901, Loss:  0.097
Epoch   3 Batch  523/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.910, Loss:  0.089
Epoch   3 Batch  524/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.910, Loss:  0.070
Epoch   3 Batch  525/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.912, Loss:  0.084
Epoch   3 Batch  526/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.920, Loss:  0.086
Epoch   3 Batch  527/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.918, Loss:  0.091
Epoch   3 Batch  528/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.918, Loss:  0.094
Epoch   3 Batch  529/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.909, Loss:  0.078
Epoch   3 Batch  530/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.900, Loss:  0.082
Epoch   3 Batch  531/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.891, Loss:  0.077
Epoch   3 Batch  532/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.888, Loss:  0.088
Epoch   3 Batch  533/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.884, Loss:  0.094
Epoch   3 Batch  534/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.891, Loss:  0.079
Epoch   3 Batch  535/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.897, Loss:  0.086
Epoch   3 Batch  536/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.901, Loss:  0.088
Epoch   3 Batch  537/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.909, Loss:  0.064
Epoch   3 Batch  538/1077 - Train Accuracy:  0.955, Validation Accuracy:  0.898, Loss:  0.063
Epoch   3 Batch  539/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.903, Loss:  0.086
Epoch   3 Batch  540/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.904, Loss:  0.066
Epoch   3 Batch  541/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.908, Loss:  0.065
Epoch   3 Batch  542/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.909, Loss:  0.069
Epoch   3 Batch  543/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.907, Loss:  0.071
Epoch   3 Batch  544/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.916, Loss:  0.050
Epoch   3 Batch  545/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.912, Loss:  0.091
Epoch   3 Batch  546/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.907, Loss:  0.075
Epoch   3 Batch  547/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.902, Loss:  0.074
Epoch   3 Batch  548/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.910, Loss:  0.104
Epoch   3 Batch  549/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.906, Loss:  0.081
Epoch   3 Batch  550/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.902, Loss:  0.078
Epoch   3 Batch  551/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.901, Loss:  0.072
Epoch   3 Batch  552/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.898, Loss:  0.075
Epoch   3 Batch  553/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.889, Loss:  0.084
Epoch   3 Batch  554/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.887, Loss:  0.068
Epoch   3 Batch  555/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.893, Loss:  0.071
Epoch   3 Batch  556/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.902, Loss:  0.067
Epoch   3 Batch  557/1077 - Train Accuracy:  0.889, Validation Accuracy:  0.902, Loss:  0.065
Epoch   3 Batch  558/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.900, Loss:  0.066
Epoch   3 Batch  559/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.892, Loss:  0.073
Epoch   3 Batch  560/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.890, Loss:  0.073
Epoch   3 Batch  561/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.894, Loss:  0.067
Epoch   3 Batch  562/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.894, Loss:  0.066
Epoch   3 Batch  563/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.890, Loss:  0.070
Epoch   3 Batch  564/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.890, Loss:  0.077
Epoch   3 Batch  565/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.886, Loss:  0.068
Epoch   3 Batch  566/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.892, Loss:  0.075
Epoch   3 Batch  567/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.891, Loss:  0.069
Epoch   3 Batch  568/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.896, Loss:  0.074
Epoch   3 Batch  569/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.897, Loss:  0.074
Epoch   3 Batch  570/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.890, Loss:  0.098
Epoch   3 Batch  571/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.886, Loss:  0.057
Epoch   3 Batch  572/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.889, Loss:  0.066
Epoch   3 Batch  573/1077 - Train Accuracy:  0.879, Validation Accuracy:  0.901, Loss:  0.099
Epoch   3 Batch  574/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.906, Loss:  0.096
Epoch   3 Batch  575/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.910, Loss:  0.059
Epoch   3 Batch  576/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.910, Loss:  0.068
Epoch   3 Batch  577/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.906, Loss:  0.077
Epoch   3 Batch  578/1077 - Train Accuracy:  0.946, Validation Accuracy:  0.902, Loss:  0.069
Epoch   3 Batch  579/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.905, Loss:  0.075
Epoch   3 Batch  580/1077 - Train Accuracy:  0.940, Validation Accuracy:  0.905, Loss:  0.056
Epoch   3 Batch  581/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.903, Loss:  0.061
Epoch   3 Batch  582/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.907, Loss:  0.077
Epoch   3 Batch  583/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.907, Loss:  0.077
Epoch   3 Batch  584/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.902, Loss:  0.073
Epoch   3 Batch  585/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.893, Loss:  0.049
Epoch   3 Batch  586/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.898, Loss:  0.073
Epoch   3 Batch  587/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.905, Loss:  0.086
Epoch   3 Batch  588/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.904, Loss:  0.069
Epoch   3 Batch  589/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.909, Loss:  0.071
Epoch   3 Batch  590/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.911, Loss:  0.078
Epoch   3 Batch  591/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.911, Loss:  0.069
Epoch   3 Batch  592/1077 - Train Accuracy:  0.953, Validation Accuracy:  0.910, Loss:  0.072
Epoch   3 Batch  593/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.905, Loss:  0.072
Epoch   3 Batch  594/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.905, Loss:  0.089
Epoch   3 Batch  595/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.904, Loss:  0.077
Epoch   3 Batch  596/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.904, Loss:  0.076
Epoch   3 Batch  597/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.904, Loss:  0.074
Epoch   3 Batch  598/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.903, Loss:  0.078
Epoch   3 Batch  599/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.903, Loss:  0.098
Epoch   3 Batch  600/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.903, Loss:  0.073
Epoch   3 Batch  601/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.904, Loss:  0.074
Epoch   3 Batch  602/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.902, Loss:  0.078
Epoch   3 Batch  603/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.909, Loss:  0.080
Epoch   3 Batch  604/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.904, Loss:  0.083
Epoch   3 Batch  605/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.905, Loss:  0.086
Epoch   3 Batch  606/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.906, Loss:  0.063
Epoch   3 Batch  607/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.911, Loss:  0.084
Epoch   3 Batch  608/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.920, Loss:  0.082
Epoch   3 Batch  609/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.922, Loss:  0.072
Epoch   3 Batch  610/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.912, Loss:  0.090
Epoch   3 Batch  611/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.908, Loss:  0.061
Epoch   3 Batch  612/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.911, Loss:  0.061
Epoch   3 Batch  613/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.904, Loss:  0.074
Epoch   3 Batch  614/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.899, Loss:  0.065
Epoch   3 Batch  615/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.907, Loss:  0.078
Epoch   3 Batch  616/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.909, Loss:  0.080
Epoch   3 Batch  617/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.913, Loss:  0.073
Epoch   3 Batch  618/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.913, Loss:  0.071
Epoch   3 Batch  619/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.915, Loss:  0.055
Epoch   3 Batch  620/1077 - Train Accuracy:  0.950, Validation Accuracy:  0.914, Loss:  0.064
Epoch   3 Batch  621/1077 - Train Accuracy:  0.948, Validation Accuracy:  0.911, Loss:  0.060
Epoch   3 Batch  622/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.908, Loss:  0.078
Epoch   3 Batch  623/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.912, Loss:  0.074
Epoch   3 Batch  624/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.915, Loss:  0.077
Epoch   3 Batch  625/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.915, Loss:  0.073
Epoch   3 Batch  626/1077 - Train Accuracy:  0.884, Validation Accuracy:  0.911, Loss:  0.071
Epoch   3 Batch  627/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.917, Loss:  0.069
Epoch   3 Batch  628/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.912, Loss:  0.078
Epoch   3 Batch  629/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.917, Loss:  0.090
Epoch   3 Batch  630/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.909, Loss:  0.072
Epoch   3 Batch  631/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.915, Loss:  0.067
Epoch   3 Batch  632/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.913, Loss:  0.047
Epoch   3 Batch  633/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.918, Loss:  0.078
Epoch   3 Batch  634/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.919, Loss:  0.052
Epoch   3 Batch  635/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.913, Loss:  0.087
Epoch   3 Batch  636/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.917, Loss:  0.067
Epoch   3 Batch  637/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.925, Loss:  0.082
Epoch   3 Batch  638/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.925, Loss:  0.066
Epoch   3 Batch  639/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.923, Loss:  0.084
Epoch   3 Batch  640/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.918, Loss:  0.070
Epoch   3 Batch  641/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.913, Loss:  0.060
Epoch   3 Batch  642/1077 - Train Accuracy:  0.896, Validation Accuracy:  0.914, Loss:  0.067
Epoch   3 Batch  643/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.914, Loss:  0.061
Epoch   3 Batch  644/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.918, Loss:  0.074
Epoch   3 Batch  645/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.918, Loss:  0.074
Epoch   3 Batch  646/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.917, Loss:  0.081
Epoch   3 Batch  647/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.913, Loss:  0.076
Epoch   3 Batch  648/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.909, Loss:  0.056
Epoch   3 Batch  649/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.913, Loss:  0.070
Epoch   3 Batch  650/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.908, Loss:  0.066
Epoch   3 Batch  651/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.909, Loss:  0.068
Epoch   3 Batch  652/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.906, Loss:  0.075
Epoch   3 Batch  653/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.907, Loss:  0.081
Epoch   3 Batch  654/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.924, Loss:  0.057
Epoch   3 Batch  655/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.928, Loss:  0.089
Epoch   3 Batch  656/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.918, Loss:  0.082
Epoch   3 Batch  657/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.919, Loss:  0.087
Epoch   3 Batch  658/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.910, Loss:  0.059
Epoch   3 Batch  659/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.909, Loss:  0.085
Epoch   3 Batch  660/1077 - Train Accuracy:  0.947, Validation Accuracy:  0.904, Loss:  0.088
Epoch   3 Batch  661/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.897, Loss:  0.066
Epoch   3 Batch  662/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.893, Loss:  0.067
Epoch   3 Batch  663/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.893, Loss:  0.075
Epoch   3 Batch  664/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.885, Loss:  0.071
Epoch   3 Batch  665/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.893, Loss:  0.061
Epoch   3 Batch  666/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.900, Loss:  0.078
Epoch   3 Batch  667/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.899, Loss:  0.077
Epoch   3 Batch  668/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.900, Loss:  0.082
Epoch   3 Batch  669/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.904, Loss:  0.077
Epoch   3 Batch  670/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.905, Loss:  0.086
Epoch   3 Batch  671/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.905, Loss:  0.081
Epoch   3 Batch  672/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.909, Loss:  0.078
Epoch   3 Batch  673/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.907, Loss:  0.066
Epoch   3 Batch  674/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.909, Loss:  0.074
Epoch   3 Batch  675/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.909, Loss:  0.092
Epoch   3 Batch  676/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.913, Loss:  0.065
Epoch   3 Batch  677/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.911, Loss:  0.092
Epoch   3 Batch  678/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.910, Loss:  0.072
Epoch   3 Batch  679/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.920, Loss:  0.085
Epoch   3 Batch  680/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.912, Loss:  0.070
Epoch   3 Batch  681/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.911, Loss:  0.077
Epoch   3 Batch  682/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.912, Loss:  0.074
Epoch   3 Batch  683/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.921, Loss:  0.062
Epoch   3 Batch  684/1077 - Train Accuracy:  0.946, Validation Accuracy:  0.919, Loss:  0.076
Epoch   3 Batch  685/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.917, Loss:  0.077
Epoch   3 Batch  686/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.912, Loss:  0.079
Epoch   3 Batch  687/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.912, Loss:  0.099
Epoch   3 Batch  688/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.915, Loss:  0.072
Epoch   3 Batch  689/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.910, Loss:  0.049
Epoch   3 Batch  690/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.909, Loss:  0.069
Epoch   3 Batch  691/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.907, Loss:  0.097
Epoch   3 Batch  692/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.903, Loss:  0.063
Epoch   3 Batch  693/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.893, Loss:  0.092
Epoch   3 Batch  694/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.900, Loss:  0.078
Epoch   3 Batch  695/1077 - Train Accuracy:  0.951, Validation Accuracy:  0.901, Loss:  0.074
Epoch   3 Batch  696/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.901, Loss:  0.076
Epoch   3 Batch  697/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.897, Loss:  0.072
Epoch   3 Batch  698/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.898, Loss:  0.057
Epoch   3 Batch  699/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.897, Loss:  0.060
Epoch   3 Batch  700/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.896, Loss:  0.059
Epoch   3 Batch  701/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.897, Loss:  0.066
Epoch   3 Batch  702/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.905, Loss:  0.080
Epoch   3 Batch  703/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.902, Loss:  0.070
Epoch   3 Batch  704/1077 - Train Accuracy:  0.899, Validation Accuracy:  0.904, Loss:  0.097
Epoch   3 Batch  705/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.901, Loss:  0.085
Epoch   3 Batch  706/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.901, Loss:  0.115
Epoch   3 Batch  707/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.895, Loss:  0.082
Epoch   3 Batch  708/1077 - Train Accuracy:  0.887, Validation Accuracy:  0.900, Loss:  0.077
Epoch   3 Batch  709/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.900, Loss:  0.072
Epoch   3 Batch  710/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.900, Loss:  0.057
Epoch   3 Batch  711/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.895, Loss:  0.077
Epoch   3 Batch  712/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.902, Loss:  0.058
Epoch   3 Batch  713/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.897, Loss:  0.051
Epoch   3 Batch  714/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.895, Loss:  0.074
Epoch   3 Batch  715/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.901, Loss:  0.077
Epoch   3 Batch  716/1077 - Train Accuracy:  0.950, Validation Accuracy:  0.911, Loss:  0.050
Epoch   3 Batch  717/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.909, Loss:  0.062
Epoch   3 Batch  718/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.906, Loss:  0.074
Epoch   3 Batch  719/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.907, Loss:  0.073
Epoch   3 Batch  720/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.918, Loss:  0.074
Epoch   3 Batch  721/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.919, Loss:  0.093
Epoch   3 Batch  722/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.919, Loss:  0.059
Epoch   3 Batch  723/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.913, Loss:  0.079
Epoch   3 Batch  724/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.913, Loss:  0.075
Epoch   3 Batch  725/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.916, Loss:  0.055
Epoch   3 Batch  726/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.915, Loss:  0.072
Epoch   3 Batch  727/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.915, Loss:  0.076
Epoch   3 Batch  728/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.909, Loss:  0.081
Epoch   3 Batch  729/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.912, Loss:  0.083
Epoch   3 Batch  730/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.911, Loss:  0.080
Epoch   3 Batch  731/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.914, Loss:  0.084
Epoch   3 Batch  732/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.903, Loss:  0.080
Epoch   3 Batch  733/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.900, Loss:  0.074
Epoch   3 Batch  734/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.895, Loss:  0.070
Epoch   3 Batch  735/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.895, Loss:  0.076
Epoch   3 Batch  736/1077 - Train Accuracy:  0.954, Validation Accuracy:  0.901, Loss:  0.077
Epoch   3 Batch  737/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.901, Loss:  0.086
Epoch   3 Batch  738/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.911, Loss:  0.052
Epoch   3 Batch  739/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.910, Loss:  0.067
Epoch   3 Batch  740/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.910, Loss:  0.060
Epoch   3 Batch  741/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.905, Loss:  0.097
Epoch   3 Batch  742/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.906, Loss:  0.067
Epoch   3 Batch  743/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.900, Loss:  0.080
Epoch   3 Batch  744/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.895, Loss:  0.077
Epoch   3 Batch  745/1077 - Train Accuracy:  0.949, Validation Accuracy:  0.901, Loss:  0.094
Epoch   3 Batch  746/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.903, Loss:  0.079
Epoch   3 Batch  747/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.903, Loss:  0.063
Epoch   3 Batch  748/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.902, Loss:  0.068
Epoch   3 Batch  749/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.904, Loss:  0.081
Epoch   3 Batch  750/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.899, Loss:  0.075
Epoch   3 Batch  751/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.900, Loss:  0.078
Epoch   3 Batch  752/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.901, Loss:  0.094
Epoch   3 Batch  753/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.901, Loss:  0.089
Epoch   3 Batch  754/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.900, Loss:  0.089
Epoch   3 Batch  755/1077 - Train Accuracy:  0.944, Validation Accuracy:  0.888, Loss:  0.090
Epoch   3 Batch  756/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.888, Loss:  0.078
Epoch   3 Batch  757/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.895, Loss:  0.076
Epoch   3 Batch  758/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.900, Loss:  0.090
Epoch   3 Batch  759/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.911, Loss:  0.080
Epoch   3 Batch  760/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.904, Loss:  0.108
Epoch   3 Batch  761/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.902, Loss:  0.073
Epoch   3 Batch  762/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.888, Loss:  0.071
Epoch   3 Batch  763/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.881, Loss:  0.065
Epoch   3 Batch  764/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.869, Loss:  0.089
Epoch   3 Batch  765/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.860, Loss:  0.092
Epoch   3 Batch  766/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.874, Loss:  0.091
Epoch   3 Batch  767/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.875, Loss:  0.079
Epoch   3 Batch  768/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.884, Loss:  0.086
Epoch   3 Batch  769/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.883, Loss:  0.089
Epoch   3 Batch  770/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.883, Loss:  0.091
Epoch   3 Batch  771/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.892, Loss:  0.104
Epoch   3 Batch  772/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.896, Loss:  0.070
Epoch   3 Batch  773/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.896, Loss:  0.089
Epoch   3 Batch  774/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.900, Loss:  0.107
Epoch   3 Batch  775/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.893, Loss:  0.090
Epoch   3 Batch  776/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.908, Loss:  0.096
Epoch   3 Batch  777/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.913, Loss:  0.103
Epoch   3 Batch  778/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.914, Loss:  0.085
Epoch   3 Batch  779/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.902, Loss:  0.098
Epoch   3 Batch  780/1077 - Train Accuracy:  0.880, Validation Accuracy:  0.897, Loss:  0.114
Epoch   3 Batch  781/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.904, Loss:  0.072
Epoch   3 Batch  782/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.896, Loss:  0.095
Epoch   3 Batch  783/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.894, Loss:  0.106
Epoch   3 Batch  784/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.898, Loss:  0.075
Epoch   3 Batch  785/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.892, Loss:  0.081
Epoch   3 Batch  786/1077 - Train Accuracy:  0.869, Validation Accuracy:  0.874, Loss:  0.092
Epoch   3 Batch  787/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.874, Loss:  0.068
Epoch   3 Batch  788/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.883, Loss:  0.082
Epoch   3 Batch  789/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.885, Loss:  0.092
Epoch   3 Batch  790/1077 - Train Accuracy:  0.855, Validation Accuracy:  0.889, Loss:  0.092
Epoch   3 Batch  791/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.896, Loss:  0.085
Epoch   3 Batch  792/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.896, Loss:  0.095
Epoch   3 Batch  793/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.899, Loss:  0.098
Epoch   3 Batch  794/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.900, Loss:  0.062
Epoch   3 Batch  795/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.899, Loss:  0.093
Epoch   3 Batch  796/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.890, Loss:  0.082
Epoch   3 Batch  797/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.895, Loss:  0.086
Epoch   3 Batch  798/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.900, Loss:  0.090
Epoch   3 Batch  799/1077 - Train Accuracy:  0.886, Validation Accuracy:  0.909, Loss:  0.102
Epoch   3 Batch  800/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.912, Loss:  0.070
Epoch   3 Batch  801/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.910, Loss:  0.087
Epoch   3 Batch  802/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.912, Loss:  0.077
Epoch   3 Batch  803/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.912, Loss:  0.089
Epoch   3 Batch  804/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.912, Loss:  0.057
Epoch   3 Batch  805/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.912, Loss:  0.079
Epoch   3 Batch  806/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.908, Loss:  0.072
Epoch   3 Batch  807/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.912, Loss:  0.066
Epoch   3 Batch  808/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.909, Loss:  0.121
Epoch   3 Batch  809/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.911, Loss:  0.105
Epoch   3 Batch  810/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.909, Loss:  0.060
Epoch   3 Batch  811/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.903, Loss:  0.069
Epoch   3 Batch  812/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.891, Loss:  0.077
Epoch   3 Batch  813/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.888, Loss:  0.085
Epoch   3 Batch  814/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.884, Loss:  0.084
Epoch   3 Batch  815/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.892, Loss:  0.069
Epoch   3 Batch  816/1077 - Train Accuracy:  0.947, Validation Accuracy:  0.895, Loss:  0.092
Epoch   3 Batch  817/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.899, Loss:  0.078
Epoch   3 Batch  818/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.897, Loss:  0.078
Epoch   3 Batch  819/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.897, Loss:  0.082
Epoch   3 Batch  820/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.897, Loss:  0.063
Epoch   3 Batch  821/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.898, Loss:  0.077
Epoch   3 Batch  822/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.919, Loss:  0.078
Epoch   3 Batch  823/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.923, Loss:  0.090
Epoch   3 Batch  824/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.920, Loss:  0.080
Epoch   3 Batch  825/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.920, Loss:  0.062
Epoch   3 Batch  826/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.904, Loss:  0.061
Epoch   3 Batch  827/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.904, Loss:  0.071
Epoch   3 Batch  828/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.904, Loss:  0.073
Epoch   3 Batch  829/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.902, Loss:  0.091
Epoch   3 Batch  830/1077 - Train Accuracy:  0.885, Validation Accuracy:  0.902, Loss:  0.079
Epoch   3 Batch  831/1077 - Train Accuracy:  0.866, Validation Accuracy:  0.907, Loss:  0.070
Epoch   3 Batch  832/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.913, Loss:  0.062
Epoch   3 Batch  833/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.912, Loss:  0.070
Epoch   3 Batch  834/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.918, Loss:  0.072
Epoch   3 Batch  835/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.915, Loss:  0.071
Epoch   3 Batch  836/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.921, Loss:  0.078
Epoch   3 Batch  837/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.923, Loss:  0.093
Epoch   3 Batch  838/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.923, Loss:  0.068
Epoch   3 Batch  839/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.923, Loss:  0.061
Epoch   3 Batch  840/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.917, Loss:  0.061
Epoch   3 Batch  841/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.922, Loss:  0.085
Epoch   3 Batch  842/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.921, Loss:  0.050
Epoch   3 Batch  843/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.915, Loss:  0.058
Epoch   3 Batch  844/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.915, Loss:  0.057
Epoch   3 Batch  845/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.914, Loss:  0.065
Epoch   3 Batch  846/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.910, Loss:  0.086
Epoch   3 Batch  847/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.911, Loss:  0.079
Epoch   3 Batch  848/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.916, Loss:  0.057
Epoch   3 Batch  849/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.917, Loss:  0.068
Epoch   3 Batch  850/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.914, Loss:  0.114
Epoch   3 Batch  851/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.919, Loss:  0.075
Epoch   3 Batch  852/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.919, Loss:  0.091
Epoch   3 Batch  853/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.911, Loss:  0.064
Epoch   3 Batch  854/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.913, Loss:  0.079
Epoch   3 Batch  855/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.913, Loss:  0.066
Epoch   3 Batch  856/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.913, Loss:  0.081
Epoch   3 Batch  857/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.912, Loss:  0.067
Epoch   3 Batch  858/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.909, Loss:  0.058
Epoch   3 Batch  859/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.912, Loss:  0.073
Epoch   3 Batch  860/1077 - Train Accuracy:  0.944, Validation Accuracy:  0.912, Loss:  0.063
Epoch   3 Batch  861/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.919, Loss:  0.064
Epoch   3 Batch  862/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.922, Loss:  0.075
Epoch   3 Batch  863/1077 - Train Accuracy:  0.952, Validation Accuracy:  0.917, Loss:  0.060
Epoch   3 Batch  864/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.908, Loss:  0.071
Epoch   3 Batch  865/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.913, Loss:  0.069
Epoch   3 Batch  866/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.913, Loss:  0.072
Epoch   3 Batch  867/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.913, Loss:  0.120
Epoch   3 Batch  868/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.901, Loss:  0.073
Epoch   3 Batch  869/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.905, Loss:  0.071
Epoch   3 Batch  870/1077 - Train Accuracy:  0.875, Validation Accuracy:  0.901, Loss:  0.079
Epoch   3 Batch  871/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.905, Loss:  0.068
Epoch   3 Batch  872/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.911, Loss:  0.069
Epoch   3 Batch  873/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.914, Loss:  0.076
Epoch   3 Batch  874/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.912, Loss:  0.082
Epoch   3 Batch  875/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.905, Loss:  0.066
Epoch   3 Batch  876/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.898, Loss:  0.070
Epoch   3 Batch  877/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.901, Loss:  0.062
Epoch   3 Batch  878/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.901, Loss:  0.072
Epoch   3 Batch  879/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.900, Loss:  0.058
Epoch   3 Batch  880/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.908, Loss:  0.072
Epoch   3 Batch  881/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.908, Loss:  0.085
Epoch   3 Batch  882/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.907, Loss:  0.080
Epoch   3 Batch  883/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.902, Loss:  0.100
Epoch   3 Batch  884/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.903, Loss:  0.072
Epoch   3 Batch  885/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.911, Loss:  0.060
Epoch   3 Batch  886/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.910, Loss:  0.068
Epoch   3 Batch  887/1077 - Train Accuracy:  0.893, Validation Accuracy:  0.902, Loss:  0.089
Epoch   3 Batch  888/1077 - Train Accuracy:  0.946, Validation Accuracy:  0.894, Loss:  0.059
Epoch   3 Batch  889/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.888, Loss:  0.059
Epoch   3 Batch  890/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.888, Loss:  0.070
Epoch   3 Batch  891/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.897, Loss:  0.063
Epoch   3 Batch  892/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.892, Loss:  0.062
Epoch   3 Batch  893/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.898, Loss:  0.066
Epoch   3 Batch  894/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.903, Loss:  0.081
Epoch   3 Batch  895/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.899, Loss:  0.060
Epoch   3 Batch  896/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.895, Loss:  0.075
Epoch   3 Batch  897/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.908, Loss:  0.057
Epoch   3 Batch  898/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.911, Loss:  0.056
Epoch   3 Batch  899/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.911, Loss:  0.079
Epoch   3 Batch  900/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.913, Loss:  0.078
Epoch   3 Batch  901/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.923, Loss:  0.098
Epoch   3 Batch  902/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.929, Loss:  0.075
Epoch   3 Batch  903/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.925, Loss:  0.078
Epoch   3 Batch  904/1077 - Train Accuracy:  0.897, Validation Accuracy:  0.920, Loss:  0.063
Epoch   3 Batch  905/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.913, Loss:  0.056
Epoch   3 Batch  906/1077 - Train Accuracy:  0.952, Validation Accuracy:  0.914, Loss:  0.070
Epoch   3 Batch  907/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.913, Loss:  0.076
Epoch   3 Batch  908/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.914, Loss:  0.081
Epoch   3 Batch  909/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.909, Loss:  0.074
Epoch   3 Batch  910/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.917, Loss:  0.087
Epoch   3 Batch  911/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.920, Loss:  0.085
Epoch   3 Batch  912/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.920, Loss:  0.068
Epoch   3 Batch  913/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.920, Loss:  0.090
Epoch   3 Batch  914/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.920, Loss:  0.097
Epoch   3 Batch  915/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.920, Loss:  0.061
Epoch   3 Batch  916/1077 - Train Accuracy:  0.940, Validation Accuracy:  0.920, Loss:  0.093
Epoch   3 Batch  917/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.922, Loss:  0.070
Epoch   3 Batch  918/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.927, Loss:  0.066
Epoch   3 Batch  919/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.929, Loss:  0.057
Epoch   3 Batch  920/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.933, Loss:  0.065
Epoch   3 Batch  921/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.915, Loss:  0.085
Epoch   3 Batch  922/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.909, Loss:  0.077
Epoch   3 Batch  923/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.913, Loss:  0.057
Epoch   3 Batch  924/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.909, Loss:  0.099
Epoch   3 Batch  925/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.911, Loss:  0.071
Epoch   3 Batch  926/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.917, Loss:  0.074
Epoch   3 Batch  927/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.915, Loss:  0.104
Epoch   3 Batch  928/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.914, Loss:  0.081
Epoch   3 Batch  929/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.912, Loss:  0.068
Epoch   3 Batch  930/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.910, Loss:  0.060
Epoch   3 Batch  931/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.908, Loss:  0.068
Epoch   3 Batch  932/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.912, Loss:  0.068
Epoch   3 Batch  933/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.913, Loss:  0.073
Epoch   3 Batch  934/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.911, Loss:  0.064
Epoch   3 Batch  935/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.909, Loss:  0.080
Epoch   3 Batch  936/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.906, Loss:  0.075
Epoch   3 Batch  937/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.901, Loss:  0.092
Epoch   3 Batch  938/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.901, Loss:  0.084
Epoch   3 Batch  939/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.901, Loss:  0.088
Epoch   3 Batch  940/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.896, Loss:  0.061
Epoch   3 Batch  941/1077 - Train Accuracy:  0.894, Validation Accuracy:  0.889, Loss:  0.073
Epoch   3 Batch  942/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.891, Loss:  0.081
Epoch   3 Batch  943/1077 - Train Accuracy:  0.923, Validation Accuracy:  0.897, Loss:  0.077
Epoch   3 Batch  944/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.895, Loss:  0.064
Epoch   3 Batch  945/1077 - Train Accuracy:  0.948, Validation Accuracy:  0.900, Loss:  0.066
Epoch   3 Batch  946/1077 - Train Accuracy:  0.958, Validation Accuracy:  0.901, Loss:  0.073
Epoch   3 Batch  947/1077 - Train Accuracy:  0.906, Validation Accuracy:  0.892, Loss:  0.079
Epoch   3 Batch  948/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.893, Loss:  0.097
Epoch   3 Batch  949/1077 - Train Accuracy:  0.952, Validation Accuracy:  0.882, Loss:  0.060
Epoch   3 Batch  950/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.888, Loss:  0.061
Epoch   3 Batch  951/1077 - Train Accuracy:  0.904, Validation Accuracy:  0.890, Loss:  0.093
Epoch   3 Batch  952/1077 - Train Accuracy:  0.949, Validation Accuracy:  0.890, Loss:  0.065
Epoch   3 Batch  953/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.891, Loss:  0.071
Epoch   3 Batch  954/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.895, Loss:  0.071
Epoch   3 Batch  955/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.905, Loss:  0.065
Epoch   3 Batch  956/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.914, Loss:  0.084
Epoch   3 Batch  957/1077 - Train Accuracy:  0.944, Validation Accuracy:  0.917, Loss:  0.050
Epoch   3 Batch  958/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.916, Loss:  0.072
Epoch   3 Batch  959/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.912, Loss:  0.061
Epoch   3 Batch  960/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.914, Loss:  0.071
Epoch   3 Batch  961/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.909, Loss:  0.059
Epoch   3 Batch  962/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.909, Loss:  0.064
Epoch   3 Batch  963/1077 - Train Accuracy:  0.947, Validation Accuracy:  0.914, Loss:  0.095
Epoch   3 Batch  964/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.912, Loss:  0.062
Epoch   3 Batch  965/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.901, Loss:  0.097
Epoch   3 Batch  966/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.900, Loss:  0.055
Epoch   3 Batch  967/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.906, Loss:  0.074
Epoch   3 Batch  968/1077 - Train Accuracy:  0.881, Validation Accuracy:  0.900, Loss:  0.083
Epoch   3 Batch  969/1077 - Train Accuracy:  0.905, Validation Accuracy:  0.896, Loss:  0.091
Epoch   3 Batch  970/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.896, Loss:  0.085
Epoch   3 Batch  971/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.890, Loss:  0.069
Epoch   3 Batch  972/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.896, Loss:  0.072
Epoch   3 Batch  973/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.896, Loss:  0.057
Epoch   3 Batch  974/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.896, Loss:  0.050
Epoch   3 Batch  975/1077 - Train Accuracy:  0.926, Validation Accuracy:  0.895, Loss:  0.060
Epoch   3 Batch  976/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.895, Loss:  0.056
Epoch   3 Batch  977/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.896, Loss:  0.047
Epoch   3 Batch  978/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.891, Loss:  0.063
Epoch   3 Batch  979/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.896, Loss:  0.080
Epoch   3 Batch  980/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.900, Loss:  0.079
Epoch   3 Batch  981/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.905, Loss:  0.060
Epoch   3 Batch  982/1077 - Train Accuracy:  0.941, Validation Accuracy:  0.907, Loss:  0.066
Epoch   3 Batch  983/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.910, Loss:  0.073
Epoch   3 Batch  984/1077 - Train Accuracy:  0.892, Validation Accuracy:  0.897, Loss:  0.077
Epoch   3 Batch  985/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.891, Loss:  0.056
Epoch   3 Batch  986/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.895, Loss:  0.082
Epoch   3 Batch  987/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.904, Loss:  0.051
Epoch   3 Batch  988/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.900, Loss:  0.071
Epoch   3 Batch  989/1077 - Train Accuracy:  0.898, Validation Accuracy:  0.897, Loss:  0.077
Epoch   3 Batch  990/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.902, Loss:  0.072
Epoch   3 Batch  991/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.906, Loss:  0.069
Epoch   3 Batch  992/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.910, Loss:  0.073
Epoch   3 Batch  993/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.913, Loss:  0.057
Epoch   3 Batch  994/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.921, Loss:  0.055
Epoch   3 Batch  995/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.920, Loss:  0.075
Epoch   3 Batch  996/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.922, Loss:  0.054
Epoch   3 Batch  997/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.923, Loss:  0.066
Epoch   3 Batch  998/1077 - Train Accuracy:  0.912, Validation Accuracy:  0.922, Loss:  0.069
Epoch   3 Batch  999/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.921, Loss:  0.064
Epoch   3 Batch 1000/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.922, Loss:  0.055
Epoch   3 Batch 1001/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.917, Loss:  0.055
Epoch   3 Batch 1002/1077 - Train Accuracy:  0.964, Validation Accuracy:  0.913, Loss:  0.049
Epoch   3 Batch 1003/1077 - Train Accuracy:  0.951, Validation Accuracy:  0.907, Loss:  0.072
Epoch   3 Batch 1004/1077 - Train Accuracy:  0.957, Validation Accuracy:  0.907, Loss:  0.079
Epoch   3 Batch 1005/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.907, Loss:  0.057
Epoch   3 Batch 1006/1077 - Train Accuracy:  0.931, Validation Accuracy:  0.907, Loss:  0.051
Epoch   3 Batch 1007/1077 - Train Accuracy:  0.960, Validation Accuracy:  0.906, Loss:  0.054
Epoch   3 Batch 1008/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.906, Loss:  0.080
Epoch   3 Batch 1009/1077 - Train Accuracy:  0.957, Validation Accuracy:  0.910, Loss:  0.048
Epoch   3 Batch 1010/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.906, Loss:  0.054
Epoch   3 Batch 1011/1077 - Train Accuracy:  0.950, Validation Accuracy:  0.911, Loss:  0.049
Epoch   3 Batch 1012/1077 - Train Accuracy:  0.946, Validation Accuracy:  0.911, Loss:  0.049
Epoch   3 Batch 1013/1077 - Train Accuracy:  0.953, Validation Accuracy:  0.910, Loss:  0.045
Epoch   3 Batch 1014/1077 - Train Accuracy:  0.918, Validation Accuracy:  0.909, Loss:  0.061
Epoch   3 Batch 1015/1077 - Train Accuracy:  0.890, Validation Accuracy:  0.909, Loss:  0.093
Epoch   3 Batch 1016/1077 - Train Accuracy:  0.903, Validation Accuracy:  0.909, Loss:  0.057
Epoch   3 Batch 1017/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.915, Loss:  0.068
Epoch   3 Batch 1018/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.916, Loss:  0.063
Epoch   3 Batch 1019/1077 - Train Accuracy:  0.910, Validation Accuracy:  0.919, Loss:  0.092
Epoch   3 Batch 1020/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.913, Loss:  0.050
Epoch   3 Batch 1021/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.913, Loss:  0.066
Epoch   3 Batch 1022/1077 - Train Accuracy:  0.937, Validation Accuracy:  0.917, Loss:  0.054
Epoch   3 Batch 1023/1077 - Train Accuracy:  0.911, Validation Accuracy:  0.913, Loss:  0.061
Epoch   3 Batch 1024/1077 - Train Accuracy:  0.909, Validation Accuracy:  0.913, Loss:  0.075
Epoch   3 Batch 1025/1077 - Train Accuracy:  0.913, Validation Accuracy:  0.917, Loss:  0.064
Epoch   3 Batch 1026/1077 - Train Accuracy:  0.961, Validation Accuracy:  0.912, Loss:  0.068
Epoch   3 Batch 1027/1077 - Train Accuracy:  0.900, Validation Accuracy:  0.912, Loss:  0.065
Epoch   3 Batch 1028/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.910, Loss:  0.064
Epoch   3 Batch 1029/1077 - Train Accuracy:  0.895, Validation Accuracy:  0.911, Loss:  0.056
Epoch   3 Batch 1030/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.907, Loss:  0.064
Epoch   3 Batch 1031/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.903, Loss:  0.062
Epoch   3 Batch 1032/1077 - Train Accuracy:  0.920, Validation Accuracy:  0.903, Loss:  0.073
Epoch   3 Batch 1033/1077 - Train Accuracy:  0.876, Validation Accuracy:  0.908, Loss:  0.069
Epoch   3 Batch 1034/1077 - Train Accuracy:  0.908, Validation Accuracy:  0.908, Loss:  0.069
Epoch   3 Batch 1035/1077 - Train Accuracy:  0.955, Validation Accuracy:  0.909, Loss:  0.045
Epoch   3 Batch 1036/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.913, Loss:  0.073
Epoch   3 Batch 1037/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.922, Loss:  0.068
Epoch   3 Batch 1038/1077 - Train Accuracy:  0.925, Validation Accuracy:  0.923, Loss:  0.084
Epoch   3 Batch 1039/1077 - Train Accuracy:  0.928, Validation Accuracy:  0.919, Loss:  0.067
Epoch   3 Batch 1040/1077 - Train Accuracy:  0.936, Validation Accuracy:  0.921, Loss:  0.072
Epoch   3 Batch 1041/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.916, Loss:  0.078
Epoch   3 Batch 1042/1077 - Train Accuracy:  0.901, Validation Accuracy:  0.917, Loss:  0.050
Epoch   3 Batch 1043/1077 - Train Accuracy:  0.947, Validation Accuracy:  0.912, Loss:  0.085
Epoch   3 Batch 1044/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.908, Loss:  0.085
Epoch   3 Batch 1045/1077 - Train Accuracy:  0.921, Validation Accuracy:  0.904, Loss:  0.061
Epoch   3 Batch 1046/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.913, Loss:  0.055
Epoch   3 Batch 1047/1077 - Train Accuracy:  0.957, Validation Accuracy:  0.912, Loss:  0.050
Epoch   3 Batch 1048/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.904, Loss:  0.057
Epoch   3 Batch 1049/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.895, Loss:  0.069
Epoch   3 Batch 1050/1077 - Train Accuracy:  0.942, Validation Accuracy:  0.887, Loss:  0.052
Epoch   3 Batch 1051/1077 - Train Accuracy:  0.932, Validation Accuracy:  0.873, Loss:  0.070
Epoch   3 Batch 1052/1077 - Train Accuracy:  0.922, Validation Accuracy:  0.877, Loss:  0.067
Epoch   3 Batch 1053/1077 - Train Accuracy:  0.917, Validation Accuracy:  0.885, Loss:  0.078
Epoch   3 Batch 1054/1077 - Train Accuracy:  0.938, Validation Accuracy:  0.893, Loss:  0.052
Epoch   3 Batch 1055/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.893, Loss:  0.081
Epoch   3 Batch 1056/1077 - Train Accuracy:  0.935, Validation Accuracy:  0.896, Loss:  0.065
Epoch   3 Batch 1057/1077 - Train Accuracy:  0.934, Validation Accuracy:  0.890, Loss:  0.071
Epoch   3 Batch 1058/1077 - Train Accuracy:  0.927, Validation Accuracy:  0.902, Loss:  0.071
Epoch   3 Batch 1059/1077 - Train Accuracy:  0.891, Validation Accuracy:  0.908, Loss:  0.079
Epoch   3 Batch 1060/1077 - Train Accuracy:  0.939, Validation Accuracy:  0.913, Loss:  0.051
Epoch   3 Batch 1061/1077 - Train Accuracy:  0.919, Validation Accuracy:  0.909, Loss:  0.079
Epoch   3 Batch 1062/1077 - Train Accuracy:  0.902, Validation Accuracy:  0.912, Loss:  0.068
Epoch   3 Batch 1063/1077 - Train Accuracy:  0.933, Validation Accuracy:  0.907, Loss:  0.062
Epoch   3 Batch 1064/1077 - Train Accuracy:  0.954, Validation Accuracy:  0.916, Loss:  0.054
Epoch   3 Batch 1065/1077 - Train Accuracy:  0.924, Validation Accuracy:  0.920, Loss:  0.051
Epoch   3 Batch 1066/1077 - Train Accuracy:  0.916, Validation Accuracy:  0.920, Loss:  0.060
Epoch   3 Batch 1067/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.909, Loss:  0.061
Epoch   3 Batch 1068/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.909, Loss:  0.054
Epoch   3 Batch 1069/1077 - Train Accuracy:  0.930, Validation Accuracy:  0.916, Loss:  0.047
Epoch   3 Batch 1070/1077 - Train Accuracy:  0.914, Validation Accuracy:  0.920, Loss:  0.055
Epoch   3 Batch 1071/1077 - Train Accuracy:  0.915, Validation Accuracy:  0.926, Loss:  0.052
Epoch   3 Batch 1072/1077 - Train Accuracy:  0.943, Validation Accuracy:  0.921, Loss:  0.059
Epoch   3 Batch 1073/1077 - Train Accuracy:  0.929, Validation Accuracy:  0.917, Loss:  0.067
Epoch   3 Batch 1074/1077 - Train Accuracy:  0.945, Validation Accuracy:  0.913, Loss:  0.072
Epoch   3 Batch 1075/1077 - Train Accuracy:  0.907, Validation Accuracy:  0.915, Loss:  0.080
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">out_list</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="c1">#ensure that any words not in vocabulary are replaced by &#39;&lt;UNK&gt;&#39; word (which exists in our vocab).</span>
    <span class="n">out_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_to_int</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;&lt;UNK&gt;&#39;</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">out_list</span> <span class="p">]</span>
    <span class="c1">#convert all the words to integer IDs.</span>
    <span class="n">out_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">out_list</span> <span class="p">]</span>
    
    <span class="k">return</span> <span class="n">out_list</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;logits:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">],</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">translate_logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">translate_logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]))</span>

<span class="c1">#show the sentence excluding the special flags (e.g. &lt;PAD&gt; or &lt;UNK&gt;)</span>
<span class="n">sent</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">translate_logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Input
  Word Ids:      [84, 152, 119, 177, 213, 163, 39]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [335, 31, 155, 19, 197, 81, 278, 1]
  French Words: [&#39;il&#39;, &#39;a&#39;, &#39;vu&#39;, &#39;une&#39;, &#39;voiture&#39;, &#39;rouge&#39;, &#39;.&#39;, &#39;&lt;EOS&gt;&#39;]
  French Sentence: il a vu une voiture rouge .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Plotting-the-Training">Plotting the Training<a class="anchor-link" href="#Plotting-the-Training">&#182;</a></h2><p>This will plot the training &amp; accuracy, and on a separate graph the loss vs batch steps (all epochs).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># plot loss</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Steps&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_acc_list</span><span class="p">))</span>
<span class="c1"># plot train and validation accuracy</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="s1">&#39;b:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">valid_acc_list</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Steps&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_acc_list</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">  Best Validation Accuracy was </span><span class="si">{:.2f}</span><span class="s1"> at step </span><span class="si">{}</span><span class="s1"> with loss </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_acc_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">i</span><span class="p">,</span><span class="n">loss_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAagAAAEkCAYAAAB6wKVjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XlcVOXiBvDnzADDJgwgiyBIAooQXpcS1BTT3LJSK6+a
1dUyy+qWlV2zW2n1u0FZ3TLLW66VZpLizTRxuZq5IZaZ5jqKmLFvIzsDM/P7Y3R0EhCGGc4czvP9
fPw0c86Zc955Qx7fc95F0Gq1RhARETkYhdgFICIiaggDioiIHBIDioiIHBIDioiIHBIDioiIHBID
ioiIHBIDioiIHJKoAZWXl4cnnngCERERCAwMRHx8PPbu3StmkYiIyEE4iXVhrVaLkSNHIiEhASkp
KfDz88OFCxfg7+8vVpGIiMiBiBZQCxcuRFBQED799FPztvDwcLGKQ0REDka0W3ybN29G3759MW3a
NERGRuK2227DZ599BqORMy8REZGIAZWVlYVly5YhPDwc69evxxNPPIHXX38dS5YsEatIRETkQASx
Jov19/dH7969sW3bNvO2N954A5s2bUJGRoYYRSIiIgciWgsqMDAQ3bt3t9jWrVs3/PHHH3a7pkaj
sdu52zvWnfVYd63D+rOe1OtOtIBKSEjA2bNnLbadPXsWoaGhIpWIiIgciWgB9eSTT+LQoUN49913
kZmZif/+97/47LPPMH36dLtcb8nJCpTW2eXURERkB6IFVJ8+fbB69Wps2LAB/fv3x5tvvomXX37Z
bgG17FQlinWCXc5NRES2J9o4KAAYOXIkRo4c2SbXUggAO7ATEUmHbObiUwgCDEwoIiLJkE1AKQVA
b+QtPiIiqZBVQBnELgQRETWbrAJKz1t8RESSIaOA4jMoIiIpkU1ACXz8REQkKbIJKIDdzImIpERW
AUVERNIhq4BiC4qISDpkE1B8BEVEJC2yCSgAbEIREUmIbAJK4Fx8RESSIp+AErsARETUIrIJKIAt
KCIiKZFNQLEFRUQkLbIJKIAtKCIiKZFNQAmc64iISFJkE1AAW1BERFIim4Bi+4mISFpkE1AA2IQi
IpIQ2QQUB+oSEUmLfAJK7AIQEVGLyCagALagiIikRDYBxRYUEZG0yCagzpXVo7SOMUVEJBWyCagL
FXrMO6MSuxhERNRMsgkoIiKSFgYUERE5JNECKikpCWq12uJPt27dxCoOERE5GCcxLx4VFYVNmzaZ
3yuVShFLQ0REjkTUgHJyckJgYKCYRSAiIgcl6jOorKwsREdHo2fPnnjkkUeQlZUlZnGIiMiBCFqt
VpQJFrZv346KigpERUWhqKgICxYsgEajQXp6Onx9fRv9nEajsep6t+51BwAcuq3Kqs8TEZFtRUVF
NblftID6s4qKCvTq1QuzZs3C008/bfPzq1dkAwC000Jsfm450Gg0N/xhooax7lqH9Wc9qdedw3Qz
9/T0RHR0NDIzM8UuChEROQCHCaiamhpoNBp2miAiIgAi9uJ75ZVXMGrUKHTu3Nn8DKqqqgqTJ08W
q0hERORARAuonJwcTJ8+HcXFxejYsSNuueUWbN++HWFhYWIViYiIHIhoAbV8+XKxLk1ERBLgMM+g
iIiIriWrgHISHKJHPRERNYOoUx21pbHhrghDmdjFICKiZpJNCyrITQknLqhLRCQZsgkogeFERCQp
8gkosQtAREQtIpuAAgB2kSAikg7ZBBRv8RERSYtsAgoAjGxCERFJhmwCSoDAW3xERBIio4AiIiIp
kU1AERGRtMgmoNhJgohIWmQTUAC7mRMRSYlsAooNKCIiaZFNQAFsQRERSYlsAkoAx0EREUmJfAKK
9/iIiCRFNgG1/Y8afF8om+WviIgkTza/sY+X1kNGeUxEJHmy+Y2dEOCCQJVB7GIQEVEzySag7r3J
DYN89WIXg4iImkk2AaVUAAb24iMikgz5BJQgQG9kVz4iIqmQTUApBLagiIikRDYBpRQAdpEgIpIO
2QSUQhDYgiIikhDZBBRbUERE0uIwAfX+++9DrVbjxRdftMv5lQKgZwuKiEgyHCKgDh06hJUrVyI2
NtZu11AKAieLJSKSENED6tKlS3jsscewaNEiqNVqu11HEAAO0yUikg7RA2rWrFkYO3YsBg8ebNfr
KNnNnIhIUkSdLPbzzz9HZmYmPvvss2Z/RqPRWHWt/GIlDEYnqz9P1tc9se5ai/VnPUeuu6ioqCb3
ixZQGo0Gb7zxBtLS0uDs7Nzsz93oCzXmvGsN9HkFVn9e7jQaDevOSqy71mH9WU/qdSdaQGVkZKC4
uBgJCQnmbXq9Hvv378fy5cuRk5MDlUpls+spBK6oS0QkJaIF1JgxY9C7d2+LbU899RQiIiLw/PPP
w8XFxabXYzdzIiJpES2g1Gr1db323N3d4ePjg5iYGJtfTyEIHKhLRCQhovfiaytcboOISFocasn3
zZs32+3cCnCqIyIiKZFPC4rjoIiIJEU+AaXgbOZERFIim4DiLT4iImmRT0AJ4JLvREQSIpuA4i0+
IiJpkU1AKQCcrZLN1yUikjzZ/MYuquFiG0REUiKbgOLtPSIiaZFPQIldACIiahHZBJSnE3vwERFJ
iWwCqo+/bWdHJyIi+5JNQAkAFOCDKCIiqZBNQCkEMJ6IiCRENgElADBCgJHL6hIRSYJ8AkowdZJg
PBERSYNsAuqKC+UcsEtEJAWyC6iCagYUEZEU2CygjEYjqqqqbHU6u1EqOB6KiEgKWhxQmzZtwhtv
vGGx7aOPPkJISAg6d+6MBx54wKGDyp0DdomIJKHFAfXBBx8gLy/P/P7IkSOYN28e+vbti6lTp2L7
9u348MMPbVpIW+nqzgmPiIikwqmlHzh37hzuv/9+8/tvvvkGvr6+WLduHVQqFZycnJCamoq5c+fa
tKC2oABQx1ljiYgkocUtqJqaGri7u5vf79y5E8OGDYNKpQIAxMXFITs723YltKGzVQr863CZ2MUg
IqJmaHFAhYSE4JdffgFgak2dOnUKQ4cONe8vKSmBq6ur7UpoYwcLdGIXgYiImqHFt/gmTpyIpKQk
5Obm4tSpU/Dx8cGoUaPM+w8fPozIyEibFtKWqut5i4+ISApa3IJ6/vnn8fzzzyMnJwedO3fGqlWr
4O3tDQAoLS3F/v37MXr0aJsX1FZ07CdBRCQJLW5BKZVKvPLKK3jllVeu2+fj4wONRmOTghERkbzZ
bKBuRkYGtm/fjsrKSlud0uaGd6zHTR2UYheDiIiaocUBtWDBAotu5gAwefJkjBo1ChMnTkS/fv3w
+++/26yAtlRSJ+B8uR4XyuvFLgoREd1AiwNq3bp16N69u/n9li1bkJaWhmeffRZLly6FTqfDO++8
c8PzLFmyBAMGDEBoaChCQ0MxfPhwbN26taXFaRHny5NIpF2sset1iIio9Vr8DConJwdRUVHm9xs3
bkRERATmzZsHANBoNFi1atUNzxMcHIzXX38dERERMBgMWLNmDaZMmYIffvgBN998c0uL1SzjguqR
rlVCpeR0R0REjq7FLShBEKDXX50RfPfu3Rg2bJj5fXBwMAoLC294njFjxmD48OHo2rUrIiMj8eqr
r8LT0xOHDh1qaZGabaCPqdzOspvDnYhIelr8qzoyMhKbN28GAOzYsQN5eXkYPny4eX92djbUanWL
zqnX67F+/XpUVlaiX79+LS1Ss6kuf1snzmhOROTwWnyL7+9//zseffRRdOnSBVVVVYiOjsaQIUPM
+3fv3o2ePXs261zHjx/HiBEjUFNTAw8PD6xatQqxsbFNfqY13dgvL6qLvLw8aAxcF6qlOITAeqy7
1mH9Wc+R6+7ax0UNaXFAjR8/Hj4+Pti2bRu8vLwwffp0ODmZTlNaWgo/Pz9MnDix2YXbs2cPysrK
8O2332LmzJnYtGkTYmJimvyMtTQaDdydBPS6KQRRwSqrzyNHGo2mVXUvZ6y71mH9WU/qddfigAKA
IUOGWLSarvDx8WlWB4krXFxc0LVrVwBAr169cPjwYXzyySdYtGiRNcVqllgfJ85oTkQkAVYFFABo
tVr88MMP5jFPYWFhGDJkSIufP13LYDBAp7PvZK6HCuswa78Wv/01yK7XISKi1rEqoD788EMkJyej
trYWRuPV1oirqyvmzp2LZ5555obnmD9/PkaMGIGQkBBUVFRg3bp12Lt3L1JSUqwpUov8UcnnT0RE
jq7FAfXFF19g/vz5SExMxMyZM82Ddk+fPo3//Oc/mD9/Pnx8fPDQQw81eZ78/HzMmDEDBQUF8PLy
QmxsLNatW2fRZd2eDuTXon8gn0MRETmqFgfUf/7zHyQmJmLDhg0QhKvdtcPDwzFixAiMGzcOixcv
vmFALV68uOWltaGLFXr0DxS1CERE1IQWj4PKzMzEmDFjLMLpCkEQcNdddyEzM9MmhbMnPftJEBE5
tBYHlLe3N7Kyshrdn5WVZV4fyhFN7WZart5gZEIRETmyFgfUqFGjsGTJEqxdu9aig4TRaERKSgqW
Ll3q0AsWDu9sWo7+7CXOaE5E5Mha/Axq3rx5OHToEGbOnIlXX33VPI4pMzMTRUVFiI6ONk8c64iO
ldQBAP59rALzbnHclh4Rkdy1OKB8fX2xa9curFixAtu3b8fFixcBAHFxcRg5ciTuvvtuFBcXw8fH
x+aFtQU+eyIikgarxkGpVCo88cQTeOKJJ67b9+677+Ktt95CSUlJqwtnD94unCiWiEgKZLfwBBtQ
RETSILuASuzEwblERFIgu4Dq6edifv3lmUoRS0JERE2RXUBd6+/7tGIXgYiIGtGsThI///xzs0+Y
k5NjdWGIiIiuaFZA3XHHHQ1ObdQQo9HY7GPFEuGlxLky04zmBqMRCkFAUY0erkoBns6yblQSETmM
ZgXUxx9/bO9ytKllib4Y8l0hAOCFA1r8e4APItfkYWiwCqkjO4pcOiIiApoZUA888IC9y9Gmrh2s
+2txnfl1bhXXiSIichSyvJ/Vy8/Z/PpwUR2OFptW8XXsG5NERPIiy4BSKiyj6M7vi0wvmFBERA5D
lgEFAE7XhFFFvemeH/OJiMhxyDagYnycr9umcPDeh0REciLbgApyv/6rK5hPREQOQ7YB5eF0/Vf/
tbgOK05x+iMiIkcg24Bq7G7ecwc4/RERkSOQb0A1se+7C9VtVg4iImqYfAOqiYR6aKdjLrZIRCQn
8g0osQtARERNkm1ATejqjjFhro3uNxq59i4RkZhkG1AjQl2xepgf7u7ScEh9caaqjUtERETXkm1A
XRGtvn7ALmA5iSwREbU92QfU3N4dGty+N6+2jUtCRETXEi2g3n//fdx+++0IDQ1FREQEJk6ciBMn
TrR5Oa6d3mjDCD/z6zOX6nEgnyFFRCQW0QJq7969ePTRR7F161Zs3LgRTk5OGDduHEpLS0UpT3yA
C24PsXwe9fpPZaKUhYiImrlgoT2kpqZavP/0008RFhaG9PR0jB49uk3LsnFUR4R6KK/bzrljiYjE
I1pA/VlFRQUMBgPUanWbX3twJ1WD2/UGYH1mFXxViutaV0REZF+CVqt1iAE/U6dOxblz5/DDDz9A
qby+NXOFRqOxazlu3et+3TY/ZyPS4jn9ERGRLUVFRTW53yFaUC+//DLS09ORlpbWZDgBN/5CTdFo
NDf8fIZ/HfptKLDYVlwntOq67UFz6o4axrprHdaf9aRed6J3M587dy7Wr1+PjRs3Ijw8XOzioJva
Geuv6c1HRETiEDWg5syZYw6nbt26iVkUC7ENrLZ7hU7vEHdEiYjaPdECavbs2fjqq6+wZMkSqNVq
5OfnIz8/HxUVFWIVySzIXYkvh/pet319ZhUCvsgRoURERPIjWkAtXboU5eXlGDt2LLp3727+89FH
H4lVJAuBbpZVo6014NHdpjFaNfVsRRER2ZtonSS0WsdeubZfgGXX8/Cvcs2vU89X4YEoj7YuEhGR
rIjeSUKK2H4iIrI/BpQVXjvEKZCIiOyNAdWEhQMbntWiuNbQxiUhIpIfBlQTlE3Mxbf9jxrUGYzs
dk5EZCcMqCaMCXPDv/p5N7jvyT2liE3JQ+LGggb328Oe3FpM+V9xm12PiEhMDKgmqFUKPBXr2eC+
whoDCqoNOKmtx+YLbTNP35aL1dj8e02bXIuISGwMKBuYsrOkTa7j2tQ9RyKidoYB1Qzfj+5ofv2P
Xg0vEX+8pM7u5WA8EZGcMKBaqHMDCxsCwMBvC1BUo29w34Xyegz4b749i0VE1O4woJohPsAFKXf4
oehvwXBqohkTuSbP/Dqv6mpYHSmuw4nS+laXQ2AbiohkhAHVDEqFgBGhrnBSCBgd5tbksY/8UIIy
nQHRa/OgN5i6oBtt1ROd+UREMsKAaiEfVdNVlnr+ak+7SzrTgF6DzRKKiEg+GFBW2HJnxyb3z9xj
mvW8tPZyC8pG162o4wwWRCQfDCgr9A9U4bcJgXgg0r3J4y5U1MNoNNosoMp0bIkRkXwwoKzU2dMJ
nwzywX9HNr48/L3biuGzMgeXH0WhpJFefs0lXH4GdUpr/y7tRERiY0C1ku8NnkkBwIwfTbf8xm1t
3TRFV/pIcP4/IpIDBlQr9fRzafaxR0vqoF6RbfW1FMKV/7I7HxG1f6KtqNueLByoxqECHdydBHx6
svKGxxdU6xHg1vCA36YwlohITtiCsoGHu3ngo9t88K9+3ujiaQqeF3o2PMksAHT7Og8/FepafB3j
n/5LRNSesQVlQ04KAb9OCDK/f+9oRaPH3r+tCFlTglt0/iudLZrx2IuISPL4q04kWp0R+VV6nNbW
oUzXvPFNVwJq7bkqO5aMiMgxMKDsqHSqqYX07M2m230xassGa/e1eYjfUICw1bkY+t2NFz68MiPF
KW3r5/UjInJ0vMVnR4IgQDstBAAwPNQV8QEu8P88p8FjDxfdeGzTlWdP7GVORHLAFlQbuS1IBWeF
gIsPdrL6HFem9OPcfkQkBwyoNtbBWQGXRmo9v0qPM03MEhHj4wwAGBnqao+iERE5FAaUCMI8G76z
2n1tHvptKECt3og6w/WtJH830/+uFw5csmv5iIgcAQNKBGvu8MX/3erV6P7AL3Iw6Nsbd5ogImrP
GFAiiPJ2xpOxjQ/kBUw99X7MrbXY1kCjioio3RI1oPbt24dJkyahR48eUKvVWL16tZjFaVMKQcCy
RJ8mj7knrQhbL9ZAvSIbPdbmcgYJIpIVUQOqsrISMTExSE5Ohptb00upt0f3dXXHK3288MXtvo0e
M3GHaQb03CoDKuqMuL+rqZ6WnGx8lgoiovZA1IAaMWIEXnvtNYwdOxYKhTzvNs7+SwfcE968cP73
0XJ4OZvq6cX0qx0l7kkrQmZZPQ7k1zb2USIiyZHcQF2NRiPq5+2n6dV5AaCwxoDyMi0AU3fzyNUX
saFvDX7Mdcere7KxucAJh26z3zRIjlt3jo911zqsP+s5ct1FRUU1uV9yAXWjL9QUjUbTqs/b09FO
9XASBPxcpMNDO0saPa5Y8ARgaikV6RRYVtwRQBVqnD0A1Nrt+zly3Tk61l3rsP6sJ/W6k+d9NQcU
5umEYA8l1JdH8fbzb3ghxJ05lrfxVp4xtZj+l23aftiKZTyIiBwRA8rB+Lma/pc82K3xW36hno0v
dnh3WhFKavQ2LxcRUVtjQDmYGB9nZD/YCVMi3XH4vsAGjzl2zZpTf1ZZb0TXNXn2Kh4RUZsRNaAq
Kipw9OhRHD16FAaDAX/88QeOHj2Kixcvilks0Xk4K6BUCOjqZXpE+LcmWlONUa/IhnpFNo4U6fD9
79WoqW94FFVelR57ctn7j4gcj6gB9csvv2Dw4MEYPHgwqqurkZSUhMGDB+Ott94Ss1gO5fEeHnjx
Lx1wdEIgHov2wNd3mMZMnfhr462oaw35rhAP/K8EQV/mQL0iGwfya5GaebWn35yDWtydVgQA0NY2
b+FEIqK2IGovvkGDBkGr1YpZBIf3doLa/HpB/6uvgz1Mz6GGBqtwf1c3PLm3efU4+ntTGA0JVlnc
CjylrUPChgLz+lVERGKTXDdzumrHXf7o7KFEkLsS8QEqzPvpEo6W1OH3iht3kvjzc6qEDabJaZ/a
W4qUc1V4tY8XHo32gIczH1MSkTj420fCbvF3QZC7qSUV4e2EVcP88MzNTU9CeyOrNVWoMwCv/VSG
kFW52JldgxcPsJVLRG2PLah2Zmp3Dwzv7IqfCnXwUSlw77biVp3vyufv7Qe4VtQj9PJaVkU1eviq
FFAIQqvLTETUEAZUO+OkENClgxO6dLj6v/a9/t44WlyHQwU6nNDWW3Xe0RnuQEY+unk7IbdKj/K6
q70CS6cGQ2BQEZGNMaDauadjPTE23A2PRl+99Xfn94XYn2/djBNnLl0fcOsyqxHn5wyj0dRt/fYQ
LklPRK3HgGrn/q+f93Xbvr/TH5V1BvxcVId70ooQ4KbAbUEqpJ6vxvG/BiE2pWUDfR/7sdTi/bU9
AdUrslH0t2A4KQTUGYxwVrClRUTNw04SMuXhrMDgTioAgL+rAsuH+EI7LQQhHkrcEaKyOPYWf+cW
nfvKIGH1imwApumXtLUG+H+eg/T8WpzW1tnmSxBRu8YWlMz9fG8gPJwtWzUpw/3wW0kdBm8sxMHx
AaioM2LYpkKrr3EgX4fwr3IBAKMuj8P65b5A3OTFHz8iahxbUDIX4e1k7qp+hUIQ0NPPBUV/C0Z3
tTP6+rvg0G1V2H2Pv/mYjaM6Yt1wP8T4WBcyvdfn4+dCHb48Uwn1imw88sPVJUZ+K6nD/dtMk95q
aw3Q6bnYPZEc8Z+w1CinPz0v+oufy3UzTdzR2RVfaSrx5F4tSqYGw3dlTrPPf22rLPV8NarqizGt
u4d5mfsrg4kHBbng/q7u6OSuxIhQdsAgkgu2oKjVJke6I//hYCgEAVkPdEKAm3U/VmkXa8zhdK09
eTo8u1+Lv+4oxpCNBTAYTS2qx38swf+ya1pVdiJyXGxBUasJggDV5buEapUCv00Iwus/l6GLpxL/
OHgJ/7vLH3/xc4aTQsCxkjrU6Y0wAlY91zpSXGfRSlt7rhoA8Eh3D1TrjZgc6Y7MsnrM2q/lvIJE
EseAIptzUQr41+Xu7TNiLKdeivO92iNwx13+eO/XcjzfswN+KtRhbsYlq6+5/HQlAGDN2asztfff
kI+Vt/tiw/lq9A9UYezWImwa3RF+KgV6+Djjp0Idevs5Q8mu70QOiQFFornF3wVr7vADANwa4IKZ
sZ74pUiH09p6TIp0x/itRdiVY/1aVSe19Yi/PAkuUA4AuGuLqRfhuuF+uH97Mb6+wxejQt2QWVZv
Xn8LAAqq9SisNiDWt2Vd7InIdhhQ5FB6d3RB744uAIANIzsCAGr1Roz6vhC77g7AF2cq8cw+LT4b
7IOcSj0+P1OJ8+UtX+L+/u2mZ12TdlztPbjzLn+sP1+N4ho9zpXV41BhHbaP8Yebk4CbGVREbY4B
RQ5PpRSw6+4AAMBDUe6Y0NUdbk6m23KzenYwH6dekY33+ntjd04toryd8N7RihZdZ2gDz8SGb766
bfc9/viLn4v5/SWdAV+cqcTfb+5w3eeIqPUYUCQpgiDArZGf2iudIq7MOzjuJncsPFaOXh1doNMb
MbiTqlUDjhM3FuLMpCCcuVSPw4U6vPZTGQBgUoQ71mVWY0YPD5TUGlBZb8TvFXrzTB03UlFngLuT
wJnhif6EAUXtVpyvM5Yk+lpsO/7XIHx8vByfHK9E9oOdcKFCjzd/LsNPhTp0Vzthb17Tk+h2+/r6
eQqjLm87UVqHdZnVqL48sPjohECoFAK+zVNidlTj5+y8Khfz+3pZtAaJiAFFMhPiocQbt3hjbm8v
eDgrEOOjMHfUAAC9wYjyOiMMRiN+yKnFI7tLmzibpS81VRbve36Tf/mVCr/WFWNKlDsm7SiBt4uA
C1OCAQDaWgMAYOmpStTojcgsr8eng3y4fAkROFCXZMhJIaBDI0vZKxUC1CoFfF2VuLerO17p44XT
E4MQrXbCqqGWrbGkBmaKb8x3F2rMHTIu6YxQr8jGP9K15jkK/6jUI/lIOVLOVcNnZQ4O5pt6L+ZW
6RG7Ng+VdQZrviqRpAlarVY2E51pNBpERTVxr4UaxbozMRqN0OpMLSw/VyW0tQaoVQrsya3FpB3F
qKy33V+niw92QlxKHrQ6I/p0dMazcR1wSWfA7cEquCoF+LspUas3orreiKp6I4I9lDc+qQTxZ896
Uq873uIjagFBEOCjunr7Ta0ytcQGdVIh+6FgaC7VwWAE4jcUQDstBFnl9biQlYUKrxBM2VnS2Gkb
FLoq1/z6cFEd/rbL8vNDg1XYec04sYKHg+GiFGA0GiEIAi7pDDAYAR+VAjX1RigE0yBqIqlgQBHZ
UJS3abzUlR6F4R2cUOdqRFQXN2inhcBoNGJ/vg6dPZT4b1Y1NJfqMSXKHV7OCnRyVyAlsxovHWze
jBo7/zSIOeCLhifqTR3hh3u3mcZ9RXgpsXiQDzq5K1FvANZlVuHJWE94OCtwvKQO4R2U5tcxPk6o
0QM1eiN8VAr8L7sG920rxoUpneDtwqcDZH+8xUfNwrqznrV199qhS7j3JjfU6o1Ypam6rhOGLU2P
9sDSU5WY0cMDA4NU+NuuEvTt6Iyfi0yLS/4+pRPCVudafObEX4MavK1YqzdCZcOWGn/2rCf1umNA
UbOw7qxnr7rTG4z49GQlRoW64rsL1Zh3eVxWW/v6Dl/UGwCd3ogvNVXYlVOLjwaqEeSuRJinEp09
lMip0sNXpcAjP5Rid66p5Tcq1BVrhvmaeyyW1hrgo1Ig6ZcyTOjqhsjLrdG9v53FfYfdUKsH9o0N
4PRTLSD1v7cMKGoW1p312rLutLUGeLsI5l/6xsvd5decrYKfqwL33uRuMTuGIyj6WzC+OluFZ/Zp
8U68N/5x+RankwD8uc/JuHA3nCurx303uWFChDt8VAJyKw3wcBbMC29+crwCl3QGPNLdA/5uCvMA
6JIaPXxdTcf8VKhDR1cFwjtcfcpRZzDCWSGgos6AzqtysX9cAGJ8pB2GUv97y4CiZmHdWU8Kdbfl
92r4uymH1A66AAAPY0lEQVRxi78LUjOrsODXcjx9syfOaOuh1Rng76rE8dI6fDHUF9su1mBEqCvO
XqpH//8W3PjkbahrByUym5ibcWSoK7ZetFxD7KVeHZB8pLzRz2wf448wTyXSC3T45lwVNv1eg9Kp
wSiuNWDYd4W4UKHH8BAVevo540hxHQ4X6bD2Dj/06eiCijojvs2qRnygC0prDThRWgcfFwUEAbgz
zA0qpYCqegP0RlgMfciu1CPEQwmD0disGUY2X6hGeZ0RkyLdAQD1BiMOFerw0t58PN/XH+fL6rE9
uwabR/tDbzBibsYlZJbVY2p3D4wOdTXP6J9TqXeo3qCiB9TSpUuxcOFC5OfnIzo6GklJSRgwYIBd
riWFXxSOinVnvfZed7V6I2r1Riw7VYmefs6ID3CBwQj8M+MSenV0RpCbElN2lmB8uBs2ZFWLXVzJ
eCrWEx8fr0D/QBccyDfNcDKyswpb/6hFjNoJJ7T1di/Dw93cMShIha5eThi2qRDJ8d7Yl1eLW/1d
EB/ggvjA5k3nZS1RAyo1NRUzZszAe++9h4SEBCxduhRfffUV0tPTERoaavPrtfdfFPbEurMe686k
3mBEXpUeHV2VKK8zwN/t6r/UtbWm23TOCgE6vdGiO/yV+jtcqEN+tallEeSuhEIAEjYUoKjm6iBm
VyVQc7kBldhJhbwqPcbe5IZ3jpTjjhAVdmQ3vXzLXyPckHKuGtO6u2PFaft1SmkvRoW64utrZmKx
NVEDatiwYYiNjcXChQvN2/r06YOxY8di3rx5Nr8ef1FYj3VnPdZd69i6/oxGIzIKdOgX4IKKemOj
s4pce7zBCPNtsKzyergpBQS6W94Ky63Sw0+lQEG1HrlVptDcdKEaD3fzQIC7AsU1BuRV6dHLzwWp
56vwc1Eduno5YWRnFQqqDXBWCOjT0RlzDl7CkWIdZsZ44tHLU22dmxyE+7cX45fLvSoBoHdHZzwV
64npu0sRH+CCgwVX55H8/HZfxPk6Q5d3HkJAOFZpqlBVb0SgmwJv/WK6ndnd2wlhnkpsz66FQgB6
+zmjvM6IIcEqfHaysll1+UCkOz4Z5NOsY60hWkDpdDp06tQJy5Ytw7hx48zbZ8+ejRMnTuD7778X
o1hEROQgRBttV1xcDL1eD39/f4vt/v7+KChwrAevRETU9jgcnIiIHJJoAeXn5welUonCQssxGYWF
hQgICBCpVERE5ChECygXFxf06tULu3btsti+a9cuxMfHi1QqIiJyFKJOFvvUU0/h8ccfR9++fREf
H4/ly5cjLy8P06ZNE7NYRETkAER9BnXvvfciKSkJCxYswKBBg5Ceno6UlBSEhYXZ9DpLly5Fz549
ERgYiMTEROzfv9+m55eCffv2YdKkSejRowfUajVWr15tsd9oNCIpKQnR0dEICgrCmDFjcPLkSYtj
tFotZsyYgbCwMISFhWHGjBnQarUWxxw/fhx33nkngoKC0KNHD7z99tswGqU9Wcn777+P22+/HaGh
oYiIiMDEiRNx4sQJi2NYfw1bsmQJBgwYgNDQUISGhmL48OHYunWreT/rrfnef/99qNVqvPjii+Zt
7b3+RO8kMX36dBw7dgwFBQXYvXs3Bg4caNPzp6am4qWXXsILL7yAH3/8Ef369cOECRNw8eJFm17H
0VVWViImJgbJyclwc3O7bv+HH36Ijz/+GG+//TZ27twJf39/jB8/HuXlV6eAmT59Oo4ePYp169Zh
3bp1OHr0KB5//HHz/rKyMowfPx4BAQHYuXMnkpOT8dFHH2HRokVt8h3tZe/evXj00UexdetWbNy4
EU5OThg3bhxKS68uB8/6a1hwcDBef/117N69G7t27cLgwYMxZcoU/PbbbwBYb8116NAhrFy5ErGx
sRbb23v9iT7Vkb219WBgKQgJCcE777yDKVOmADD9Kyw6OhqPPfYYZs+eDQCorq5GVFQU3nzzTUyb
Ng2nT59GfHw80tLSkJCQAAA4cOAARo8ejUOHDiEqKgrLli3D/PnzcebMGXMILliwAMuXL8eJEyfM
E5hKXUVFBcLCwrB69WqMHj2a9ddC4eHhmDdvHqZOncp6a4ZLly4hMTERCxcuxNtvv42YmBgsWLBA
Fj93oreg7Emn0+HIkSMYOnSoxfahQ4fi4MGDIpXK8Vy4cAH5+fkW9eTm5oYBAwaY6ykjIwOenp4W
HVgSEhLg4eFhcUz//v0tWmjDhg1Dbm4uLly40Ebfxv4qKipgMBigVqsBsP6aS6/XY/369aisrES/
fv1Yb800a9YsjB07FoMHD7bYLof6a9cBxcHAzZOfnw8ATdZTQUEB/Pz8LP41JQgCOnbsaHFMQ+e4
sq+9eOmllxAXF4d+/foBYP3dyPHjxxESEoKAgAA899xzWLVqFWJjY1lvzfD5558jMzMTr7zyynX7
5FB/XPKdqAVefvllpKenIy0tDUql4yxL4MiioqKwZ88elJWV4dtvv8XMmTOxadMmsYvl8DQaDd54
4w2kpaXB2Vna61JZq123oDgYuHkCAwMBoMl6CggIQHFxsUXPHqPRiKKiIotjGjrHlX1SN3fuXKxf
vx4bN25EeHi4eTvrr2kuLi7o2rUrevXqhXnz5iEuLg6ffPIJ6+0GMjIyUFxcjISEBPj5+cHPzw/7
9u3D0qVL4efnB19fXwDtu/7adUBxMHDzdOnSBYGBgRb1VFNTgwMHDpjrqV+/fqioqEBGRob5mIyM
DFRWVlocc+DAAdTUXF0QbteuXejUqRO6dOnSRt/GPubMmWMOp27dulnsY/21jMFggE6nY73dwJgx
Y7B//37s2bPH/Kd379647777sGfPHkRGRrb7+lO+9NJL80UtgZ116NABSUlJCAoKgqurKxYsWID9
+/dj0aJF8Pb2Frt4baaiogKnTp1Cfn4+vvzyS8TExMDLyws6nQ7e3t7Q6/X44IMPEBERAb1ej3/+
85/Iz8/HBx98AJVKhY4dO+Knn37CunXrEBcXh+zsbDz33HPo06ePuctqREQEVqxYgWPHjiEqKgoH
DhzAa6+9hlmzZkn6HwSzZ8/G119/jZUrV6Jz586orKxEZaVpOQIXFxcIgsD6a8T8+fPh4uICg8GA
7OxsLF68GCkpKZg/f765rlhvDXN1dYW/v7/Fn2+++QZhYWGYMmWKLH7u2n03c8A0UPfDDz9Efn4+
evTogbfeesvm460c3Z49e3D33Xdft33y5MlYvHgxjEYjkpOTsXLlSmi1WvTt2xfvvvsuYmJizMdq
tVr84x//wJYtWwAAo0ePxjvvvGPuzQaYHojPnj0bhw8fhlqtxrRp0zBnzhxJd/W99vtda86cOZg7
dy4AsP4aMXPmTOzZswcFBQXw8vJCbGwsnnnmGQwbNgwA662lxowZY+5mDrT/+pNFQBERkfS062dQ
REQkXQwoIiJySAwoIiJySAwoIiJySAwoIiJySAwoIiJySAwoIiJySAwoolY4deoUHnnkEfOKzdHR
0bjzzjuRlJRkPmbp0qXXrWBMRDfGgbpEVsrIyMDdd9+NoKAgTJ48GcHBwcjNzcWRI0ewc+dO83II
/fv3h6+vLzZv3ixyiYmkhcttEFnp3Xffhbu7O3bt2mWeWfoKsdfRIWoPeIuPyErnz59HdHT0deEE
XF2mIC4uDidPnsS+ffugVquhVqsRFxdnPq62thbJycno06cPAgIC0KNHD8ydOxdVVVUW51Or1Xju
ueeQmpqK+Ph4BAYGYuDAgdixY4fFcfX19ViwYAH69u2LoKAghIeHY9iwYdi4caMdaoDIvtiCIrJS
WFgY0tPTcezYMYvQuVZSUhLmzJkDDw8PvPDCCwAADw8PAKaJPh988EHs27cPDz/8MKKjo3H69Gks
W7YMp06dQmpqqsVknQcPHsSGDRvw+OOPw9PTE59//jkmTZqE7777Dv379wcAJCcn47333sNDDz2E
vn37orKyEkePHsXhw4dxzz332LlGiGyLz6CIrLR7926MHz8eANC7d2/0798fgwYNQmJiIlxdXc3H
NfYM6ptvvsGMGTPw3Xff4bbbbjNvT0lJwYwZM5CamoqhQ4cCuDqj+rZt28xLzZeUlKBPnz6Ijo5G
WloaAGDQoEEIDg7G2rVr7ffFidoIb/ERWSkxMRFbtmzByJEjcfLkSSxatAgTJ05Et27dsGrVqht+
fsOGDYiMjESPHj1QXFxs/jNw4EAIgoA9e/ZYHN+7d29zOAGAr68vJkyYgPT0dGi1WgCAl5cXTp48
ibNnz9r2yxKJgLf4iFohPj4ea9asQV1dHU6dOoWtW7di4cKFePrppxEaGorExMRGP3vu3DloNBpE
REQ0uP/Py3A3dNyVbb///jvUajVefvllTJkyBbfccguio6MxdOhQTJgwAb17927FtyQSBwOKyAac
nZ0RFxeHuLg43HrrrRg7dixSUlKaDCiDwYDo6GgkJyc3uD8oKKjF5Rg4cCCOHDmCLVu2YNeuXfj6
66+xePFizJ8/H88++2yLz0ckJgYUkY317dsXAJCXlwcAja5KetNNN+HIkSNITExs1sql586da3Rb
WFiYeZtarcbkyZMxefJkVFdXY8KECUhKSsLTTz8NpVLZ4u9DJBY+gyKy0u7du2EwGK7bvn37dgBA
VFQUAMDd3d38jOha48ePR0FBAZYtW3bdvtraWpSXl1ts++WXX5CRkWF+X1JSgm+++Qbx8fHmThQl
JSUWn3Fzc0O3bt1QU1OD6urqFn5DInGxFx+Rlfr374+Kigrcdddd6N69OwwGA3799VesXbvWPIC3
S5cuePHFF7F06VLMmTMHkZGR8PDwwOjRo2EwGPDAAw8gLS0N48ePR0JCAoxGI86ePYsNGzZg5cqV
GDRoEABTqygmJga5ubmYMWOGuZt5VlYWvv32WwwcOBAAEBkZiQEDBqBPnz7w9fXFb7/9huXLl2PY
sGHs2UeSw4AistKOHTuwceNGHDx4EDk5OaitrUVQUBASExPxwgsvIDw8HICps8MzzzyDffv2oays
DKGhoTh27BgA08DaxYsXY82aNTh37hxcXV0RHh6OkSNHYubMmfDx8QFgCqhp06Zh0KBBSE5ORlZW
FiIjIzFv3jyMHDnSXKb33nsPW7ZswdmzZ1FTU4OQkBCMHz8es2bNgqenZ5vXEVFrMKCIJOBKQP37
3/8WuyhEbYbPoIiIyCExoIiIyCExoIiIyCFxHBSRBDTUTZ2ovWMLioiIHBIDioiIHBIDioiIHBID
ioiIHBIDioiIHBIDioiIHNL/A8tkX10h6wAMAAAAAElFTkSuQmCC
"
>
</div>

</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbUAAAEkCAYAAACokK87AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>
  Best Validation Accuracy was 0.93 at step 4148 with loss 0.06
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
